{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32284490",
   "metadata": {},
   "source": [
    "## My final submission consists of:<br />\n",
    "    1. L0 Model, 10th LGBM Classifier, submission csv named as \"FINAL_SUBMISSION1\" \n",
    "    2. L2 Meta-Model Average, submission csv named as \"FINAL_SUBMISSION2\"\n",
    "#### For getting to it quicker you can press ctrl + f and paste the submission csv name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0102bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from scipy import stats\n",
    "import datetime\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from scipy.stats import mode,boxcox,skew\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import QuantileTransformer, KBinsDiscretizer, PowerTransformer\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostRegressor,CatBoostClassifier\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, HistGradientBoostingRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from keras.models import Model\n",
    "\n",
    "import optuna\n",
    "import gc\n",
    "\n",
    "import os\n",
    "import random\n",
    "%matplotlib inline \n",
    "# Fixing Seed\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def seed_everything(seed=RANDOM_SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4be587a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test.csv\")\n",
    "submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6397990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_time</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>allot_time</th>\n",
       "      <th>accept_time</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>delivered_time</th>\n",
       "      <th>rider_id</th>\n",
       "      <th>first_mile_distance</th>\n",
       "      <th>last_mile_distance</th>\n",
       "      <th>alloted_orders</th>\n",
       "      <th>delivered_orders</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>undelivered_orders</th>\n",
       "      <th>lifetime_order_count</th>\n",
       "      <th>reassignment_method</th>\n",
       "      <th>reassignment_reason</th>\n",
       "      <th>reassigned_order</th>\n",
       "      <th>session_time</th>\n",
       "      <th>cancelled_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-26 02:21:35</td>\n",
       "      <td>556753</td>\n",
       "      <td>2021-01-26 00:00:00</td>\n",
       "      <td>2021-01-26 02:21:59</td>\n",
       "      <td>2021-01-26 02:22:08</td>\n",
       "      <td>2021-01-26 02:32:51</td>\n",
       "      <td>2021-01-26 02:49:47</td>\n",
       "      <td>11696</td>\n",
       "      <td>1.5666</td>\n",
       "      <td>2.65</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-26 02:33:16</td>\n",
       "      <td>556754</td>\n",
       "      <td>2021-01-26 00:00:00</td>\n",
       "      <td>2021-01-26 02:33:57</td>\n",
       "      <td>2021-01-26 02:34:45</td>\n",
       "      <td>2021-01-26 02:50:25</td>\n",
       "      <td>2021-01-26 03:11:15</td>\n",
       "      <td>18117</td>\n",
       "      <td>2.5207</td>\n",
       "      <td>2.76</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-26 02:39:49</td>\n",
       "      <td>556755</td>\n",
       "      <td>2021-01-26 00:00:00</td>\n",
       "      <td>2021-01-26 02:39:57</td>\n",
       "      <td>2021-01-26 02:40:13</td>\n",
       "      <td>2021-01-26 02:56:00</td>\n",
       "      <td>2021-01-26 03:12:46</td>\n",
       "      <td>18623</td>\n",
       "      <td>2.2074</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.816667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-26 02:47:53</td>\n",
       "      <td>556756</td>\n",
       "      <td>2021-01-26 00:00:00</td>\n",
       "      <td>2021-01-26 02:48:25</td>\n",
       "      <td>2021-01-26 02:49:06</td>\n",
       "      <td>2021-01-26 03:21:51</td>\n",
       "      <td>2021-01-26 03:41:05</td>\n",
       "      <td>15945</td>\n",
       "      <td>2.1894</td>\n",
       "      <td>6.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.533333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-26 03:06:30</td>\n",
       "      <td>556757</td>\n",
       "      <td>2021-01-26 00:00:00</td>\n",
       "      <td>2021-01-26 03:07:21</td>\n",
       "      <td>2021-01-26 03:07:57</td>\n",
       "      <td>2021-01-26 03:31:38</td>\n",
       "      <td>2021-01-26 04:00:15</td>\n",
       "      <td>17589</td>\n",
       "      <td>2.7870</td>\n",
       "      <td>4.01</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            order_time  order_id           order_date           allot_time  \\\n",
       "0  2021-01-26 02:21:35    556753  2021-01-26 00:00:00  2021-01-26 02:21:59   \n",
       "1  2021-01-26 02:33:16    556754  2021-01-26 00:00:00  2021-01-26 02:33:57   \n",
       "2  2021-01-26 02:39:49    556755  2021-01-26 00:00:00  2021-01-26 02:39:57   \n",
       "3  2021-01-26 02:47:53    556756  2021-01-26 00:00:00  2021-01-26 02:48:25   \n",
       "4  2021-01-26 03:06:30    556757  2021-01-26 00:00:00  2021-01-26 03:07:21   \n",
       "\n",
       "           accept_time          pickup_time       delivered_time  rider_id  \\\n",
       "0  2021-01-26 02:22:08  2021-01-26 02:32:51  2021-01-26 02:49:47     11696   \n",
       "1  2021-01-26 02:34:45  2021-01-26 02:50:25  2021-01-26 03:11:15     18117   \n",
       "2  2021-01-26 02:40:13  2021-01-26 02:56:00  2021-01-26 03:12:46     18623   \n",
       "3  2021-01-26 02:49:06  2021-01-26 03:21:51  2021-01-26 03:41:05     15945   \n",
       "4  2021-01-26 03:07:57  2021-01-26 03:31:38  2021-01-26 04:00:15     17589   \n",
       "\n",
       "   first_mile_distance  last_mile_distance  alloted_orders  delivered_orders  \\\n",
       "0               1.5666                2.65            46.0              46.0   \n",
       "1               2.5207                2.76             8.0               8.0   \n",
       "2               2.2074                4.80             1.0               1.0   \n",
       "3               2.1894                6.38             1.0               1.0   \n",
       "4               2.7870                4.01            34.0              34.0   \n",
       "\n",
       "   cancelled  undelivered_orders  lifetime_order_count reassignment_method  \\\n",
       "0          0                 0.0                 621.0                 NaN   \n",
       "1          0                 0.0                 105.0                 NaN   \n",
       "2          0                 0.0                  66.0                 NaN   \n",
       "3          0                 0.0                 127.0                 NaN   \n",
       "4          0                 0.0                  84.0                 NaN   \n",
       "\n",
       "  reassignment_reason  reassigned_order  session_time cancelled_time  \n",
       "0                 NaN               NaN           NaN            NaN  \n",
       "1                 NaN               NaN      3.266667            NaN  \n",
       "2                 NaN               NaN      9.816667            NaN  \n",
       "3                 NaN               NaN     17.533333            NaN  \n",
       "4                 NaN               NaN      1.350000            NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c188587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_time</th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>allot_time</th>\n",
       "      <th>accept_time</th>\n",
       "      <th>rider_id</th>\n",
       "      <th>first_mile_distance</th>\n",
       "      <th>last_mile_distance</th>\n",
       "      <th>alloted_orders</th>\n",
       "      <th>delivered_orders</th>\n",
       "      <th>undelivered_orders</th>\n",
       "      <th>lifetime_order_count</th>\n",
       "      <th>reassignment_method</th>\n",
       "      <th>reassignment_reason</th>\n",
       "      <th>reassigned_order</th>\n",
       "      <th>session_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-06 10:03:24</td>\n",
       "      <td>130231</td>\n",
       "      <td>2021-02-06 00:00:00</td>\n",
       "      <td>2021-02-06 10:03:49</td>\n",
       "      <td>2021-02-06 10:04:15</td>\n",
       "      <td>12884</td>\n",
       "      <td>1.6585</td>\n",
       "      <td>4.54</td>\n",
       "      <td>216.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>747.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>273.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-06 10:03:26</td>\n",
       "      <td>130232</td>\n",
       "      <td>2021-02-06 00:00:00</td>\n",
       "      <td>2021-02-06 10:03:27</td>\n",
       "      <td>2021-02-06 10:03:36</td>\n",
       "      <td>3541</td>\n",
       "      <td>2.0709</td>\n",
       "      <td>5.84</td>\n",
       "      <td>52.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-06 10:03:27</td>\n",
       "      <td>130233</td>\n",
       "      <td>2021-02-06 00:00:00</td>\n",
       "      <td>2021-02-06 10:04:14</td>\n",
       "      <td>2021-02-06 10:05:34</td>\n",
       "      <td>603</td>\n",
       "      <td>1.3884</td>\n",
       "      <td>0.99</td>\n",
       "      <td>289.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2214.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>241.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-06 10:03:29</td>\n",
       "      <td>130234</td>\n",
       "      <td>2021-02-06 00:00:00</td>\n",
       "      <td>2021-02-06 10:03:30</td>\n",
       "      <td>2021-02-06 10:03:53</td>\n",
       "      <td>3414</td>\n",
       "      <td>1.9039</td>\n",
       "      <td>2.59</td>\n",
       "      <td>125.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>291.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-06 10:03:35</td>\n",
       "      <td>130235</td>\n",
       "      <td>2021-02-06 00:00:00</td>\n",
       "      <td>2021-02-06 10:03:43</td>\n",
       "      <td>2021-02-06 10:04:43</td>\n",
       "      <td>1426</td>\n",
       "      <td>0.8275</td>\n",
       "      <td>0.94</td>\n",
       "      <td>352.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7284.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>247.133333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            order_time  order_id           order_date           allot_time  \\\n",
       "0  2021-02-06 10:03:24    130231  2021-02-06 00:00:00  2021-02-06 10:03:49   \n",
       "1  2021-02-06 10:03:26    130232  2021-02-06 00:00:00  2021-02-06 10:03:27   \n",
       "2  2021-02-06 10:03:27    130233  2021-02-06 00:00:00  2021-02-06 10:04:14   \n",
       "3  2021-02-06 10:03:29    130234  2021-02-06 00:00:00  2021-02-06 10:03:30   \n",
       "4  2021-02-06 10:03:35    130235  2021-02-06 00:00:00  2021-02-06 10:03:43   \n",
       "\n",
       "           accept_time  rider_id  first_mile_distance  last_mile_distance  \\\n",
       "0  2021-02-06 10:04:15     12884               1.6585                4.54   \n",
       "1  2021-02-06 10:03:36      3541               2.0709                5.84   \n",
       "2  2021-02-06 10:05:34       603               1.3884                0.99   \n",
       "3  2021-02-06 10:03:53      3414               1.9039                2.59   \n",
       "4  2021-02-06 10:04:43      1426               0.8275                0.94   \n",
       "\n",
       "   alloted_orders  delivered_orders  undelivered_orders  lifetime_order_count  \\\n",
       "0           216.0             215.0                 1.0                 747.0   \n",
       "1            52.0              52.0                 0.0                  75.0   \n",
       "2           289.0             289.0                 0.0                2214.0   \n",
       "3           125.0             122.0                 3.0                1020.0   \n",
       "4           352.0             350.0                 2.0                7284.0   \n",
       "\n",
       "  reassignment_method reassignment_reason  reassigned_order  session_time  \n",
       "0                 NaN                 NaN               NaN    273.400000  \n",
       "1                 NaN                 NaN               NaN    252.100000  \n",
       "2                 NaN                 NaN               NaN    241.383333  \n",
       "3                 NaN                 NaN               NaN    291.933333  \n",
       "4                 NaN                 NaN               NaN    247.133333  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98b32863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['reassignment_method', 'reassigned_order', 'order_id', 'reassignment_reason', 'first_mile_distance', 'accept_time', 'lifetime_order_count', 'session_time', 'allot_time', 'undelivered_orders', 'delivered_orders', 'rider_id', 'order_time', 'last_mile_distance', 'order_date', 'alloted_orders']\n"
     ]
    }
   ],
   "source": [
    "tr_cols = train.columns\n",
    "te_cols = test.columns\n",
    "train_target = train.cancelled\n",
    "common_col = list(set(tr_cols).intersection(te_cols))\n",
    "print(common_col)\n",
    "train = train[common_col]\n",
    "train['cancelled'] = train_target.values\n",
    "test = test[common_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e37cc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_columns = ['order_date', 'accept_time', 'allot_time', 'order_time']\n",
    "train['accept_time'] = train['accept_time'].fillna(value=-1)\n",
    "test['accept_time'] = test['accept_time'].fillna(value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44eaea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accept_time_feat(row):\n",
    "    if row['accept_time'] == -1:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c742793",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Accept_time_f1'] = train.apply(lambda row: Accept_time_feat(row), axis=1)\n",
    "test['Accept_time_f1'] = test.apply(lambda row: Accept_time_feat(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3699369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_processing(df):\n",
    "    \n",
    "    df['order_time']=pd.to_datetime(df['order_time'])\n",
    "    df['order_date']=pd.to_datetime(df['order_date'])\n",
    "    df['allot_time']=pd.to_datetime(df['allot_time'])\n",
    "    df['accept_time']=pd.to_datetime(df['accept_time'])\n",
    "    \n",
    "    df['order_day_of_week']=df['order_date'].dt.weekday\n",
    "    df['order_time_hour']=df['order_time'].dt.hour\n",
    "    df['diff_allot_and_order']=(df['allot_time'] - df['order_time'])/np.timedelta64(1,'s')\n",
    "    df['diff_accept_and_allot']=(df['accept_time'] - df['allot_time'])/np.timedelta64(1,'s')\n",
    "    df['diff_accept_and_order']=(df['accept_time'] - df['order_time'])/np.timedelta64(1,'s')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aef41ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = date_processing(train)\n",
    "test = date_processing(test)\n",
    "train.drop(date_columns, inplace=True, axis=1)\n",
    "test.drop(date_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "265c2309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reassignment_method', 'reassignment_reason']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = [col for col in train.select_dtypes('object').columns]\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62f2d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['reassigned_order'] = train['reassigned_order'].fillna(value=0)\n",
    "test['reassigned_order'] = test['reassigned_order'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b13980fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[cat_cols] = train[cat_cols].fillna(value=\"NONE\")\n",
    "test[cat_cols] = test[cat_cols].fillna(value=\"NONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66c487fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        reassignment_method  reassigned_order  order_id  reassignment_reason  \\\n",
       " 0                         0               0.0    556753                    1   \n",
       " 1                         0               0.0    556754                    1   \n",
       " 2                         0               0.0    556755                    1   \n",
       " 3                         0               0.0    556756                    1   \n",
       " 4                         0               0.0    556757                    1   \n",
       " ...                     ...               ...       ...                  ...   \n",
       " 449995                    0               0.0    130226                    1   \n",
       " 449996                    0               0.0    130227                    1   \n",
       " 449997                    0               0.0    130228                    1   \n",
       " 449998                    0               0.0    130229                    1   \n",
       " 449999                    0               0.0    130230                    1   \n",
       " \n",
       "         first_mile_distance  lifetime_order_count  session_time  \\\n",
       " 0                    1.5666                 621.0           NaN   \n",
       " 1                    2.5207                 105.0      3.266667   \n",
       " 2                    2.2074                  66.0      9.816667   \n",
       " 3                    2.1894                 127.0     17.533333   \n",
       " 4                    2.7870                  84.0      1.350000   \n",
       " ...                     ...                   ...           ...   \n",
       " 449995               0.5789                 127.0    369.516667   \n",
       " 449996               1.9863                 105.0    239.133333   \n",
       " 449997               1.5944                1488.0    204.150000   \n",
       " 449998               2.8939                 105.0     65.583333   \n",
       " 449999               1.8925                 108.0    212.000000   \n",
       " \n",
       "         undelivered_orders  delivered_orders  rider_id  last_mile_distance  \\\n",
       " 0                      0.0              46.0     11696                2.65   \n",
       " 1                      0.0               8.0     18117                2.76   \n",
       " 2                      0.0               1.0     18623                4.80   \n",
       " 3                      0.0               1.0     15945                6.38   \n",
       " 4                      0.0              34.0     17589                4.01   \n",
       " ...                    ...               ...       ...                 ...   \n",
       " 449995                 0.0               4.0      1006                0.19   \n",
       " 449996                 0.0              81.0       279                1.19   \n",
       " 449997                 0.0              28.0      3161                1.61   \n",
       " 449998                 0.0              72.0      9396                4.68   \n",
       " 449999                 0.0              30.0      2078                0.09   \n",
       " \n",
       "         alloted_orders  cancelled  Accept_time_f1  order_day_of_week  \\\n",
       " 0                 46.0          0               1                  1   \n",
       " 1                  8.0          0               1                  1   \n",
       " 2                  1.0          0               1                  1   \n",
       " 3                  1.0          0               1                  1   \n",
       " 4                 34.0          0               1                  1   \n",
       " ...                ...        ...             ...                ...   \n",
       " 449995             4.0          0               1                  5   \n",
       " 449996            81.0          0               1                  5   \n",
       " 449997            28.0          0               1                  5   \n",
       " 449998            72.0          0               1                  5   \n",
       " 449999            30.0          0               1                  5   \n",
       " \n",
       "         order_time_hour  diff_allot_and_order  diff_accept_and_allot  \\\n",
       " 0                     2                  24.0                    9.0   \n",
       " 1                     2                  41.0                   48.0   \n",
       " 2                     2                   8.0                   16.0   \n",
       " 3                     2                  32.0                   41.0   \n",
       " 4                     3                  51.0                   36.0   \n",
       " ...                 ...                   ...                    ...   \n",
       " 449995               10                  28.0                   30.0   \n",
       " 449996               10                   1.0                   76.0   \n",
       " 449997               10                  48.0                   33.0   \n",
       " 449998               10                   0.0                  142.0   \n",
       " 449999               10                  21.0                   89.0   \n",
       " \n",
       "         diff_accept_and_order  \n",
       " 0                        33.0  \n",
       " 1                        89.0  \n",
       " 2                        24.0  \n",
       " 3                        73.0  \n",
       " 4                        87.0  \n",
       " ...                       ...  \n",
       " 449995                   58.0  \n",
       " 449996                   77.0  \n",
       " 449997                   81.0  \n",
       " 449998                  142.0  \n",
       " 449999                  110.0  \n",
       " \n",
       " [450000 rows x 19 columns],\n",
       "         reassignment_method  reassigned_order  order_id  reassignment_reason  \\\n",
       " 0                         0               0.0    130231                    1   \n",
       " 1                         0               0.0    130232                    1   \n",
       " 2                         0               0.0    130233                    1   \n",
       " 3                         0               0.0    130234                    1   \n",
       " 4                         0               0.0    130235                    1   \n",
       " ...                     ...               ...       ...                  ...   \n",
       " 144839                    0               0.0     41184                    1   \n",
       " 144840                    0               0.0     41185                    1   \n",
       " 144841                    0               0.0     41186                    1   \n",
       " 144842                    0               0.0     41187                    1   \n",
       " 144843                    0               0.0     41188                    1   \n",
       " \n",
       "         first_mile_distance  lifetime_order_count  session_time  \\\n",
       " 0                  1.658500                 747.0    273.400000   \n",
       " 1                  2.070900                  75.0    252.100000   \n",
       " 2                  1.388400                2214.0    241.383333   \n",
       " 3                  1.903900                1020.0    291.933333   \n",
       " 4                  0.827500                7284.0    247.133333   \n",
       " ...                     ...                   ...           ...   \n",
       " 144839             1.417000                 413.0    179.266667   \n",
       " 144840             0.775600                 284.0    244.400000   \n",
       " 144841             2.049400                 119.0    259.000000   \n",
       " 144842             0.080494                1759.0    814.283333   \n",
       " 144843             1.702100                  43.0    161.533333   \n",
       " \n",
       "         undelivered_orders  delivered_orders  rider_id  last_mile_distance  \\\n",
       " 0                      1.0             215.0     12884                4.54   \n",
       " 1                      0.0              52.0      3541                5.84   \n",
       " 2                      0.0             289.0       603                0.99   \n",
       " 3                      3.0             122.0      3414                2.59   \n",
       " 4                      2.0             350.0      1426                0.94   \n",
       " ...                    ...               ...       ...                 ...   \n",
       " 144839                 0.0              52.0      7141                3.96   \n",
       " 144840                 2.0              93.0      8113                1.61   \n",
       " 144841                 0.0              77.0      5040                1.26   \n",
       " 144842                 3.0             228.0      2946                5.50   \n",
       " 144843                 0.0              28.0      8488                4.13   \n",
       " \n",
       "         alloted_orders  Accept_time_f1  order_day_of_week  order_time_hour  \\\n",
       " 0                216.0               1                  5               10   \n",
       " 1                 52.0               1                  5               10   \n",
       " 2                289.0               1                  5               10   \n",
       " 3                125.0               1                  5               10   \n",
       " 4                352.0               1                  5               10   \n",
       " ...                ...             ...                ...              ...   \n",
       " 144839            52.0               1                  1               20   \n",
       " 144840            95.0               1                  1               20   \n",
       " 144841            77.0               1                  1               20   \n",
       " 144842           231.0               1                  1               20   \n",
       " 144843            28.0               1                  1               20   \n",
       " \n",
       "         diff_allot_and_order  diff_accept_and_allot  diff_accept_and_order  \n",
       " 0                       25.0                   26.0                   51.0  \n",
       " 1                        1.0                    9.0                   10.0  \n",
       " 2                       47.0                   80.0                  127.0  \n",
       " 3                        1.0                   23.0                   24.0  \n",
       " 4                        8.0                   60.0                   68.0  \n",
       " ...                      ...                    ...                    ...  \n",
       " 144839                   1.0                    9.0                   10.0  \n",
       " 144840                  23.0                   34.0                   57.0  \n",
       " 144841                  38.0                   67.0                  105.0  \n",
       " 144842                  22.0                   24.0                   46.0  \n",
       " 144843                   5.0                   78.0                   83.0  \n",
       " \n",
       " [144844 rows x 18 columns])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_encode(train, test, object_cols):\n",
    "    for cols in object_cols:\n",
    "        Le = LabelEncoder()\n",
    "        train[[cols]] = Le.fit_transform(train[[cols]])\n",
    "        test[[cols]] = Le.transform(test[[cols]])\n",
    "    return train, test\n",
    "label_encode(train, test, cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c121fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = ['delivered_orders', 'undelivered_orders', 'first_mile_distance', 'session_time', 'last_mile_distance',\n",
    "               'alloted_orders', 'lifetime_order_count']\n",
    "null_cols_same = ['undelivered_orders', 'delivered_orders', 'lifetime_order_count', 'alloted_orders']\n",
    "train[null_cols_same] = train[null_cols_same].fillna(value=-1)\n",
    "test[null_cols_same] = test[null_cols_same].fillna(value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "366859b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reassignment_method</th>\n",
       "      <th>reassigned_order</th>\n",
       "      <th>order_id</th>\n",
       "      <th>reassignment_reason</th>\n",
       "      <th>first_mile_distance</th>\n",
       "      <th>lifetime_order_count</th>\n",
       "      <th>session_time</th>\n",
       "      <th>undelivered_orders</th>\n",
       "      <th>delivered_orders</th>\n",
       "      <th>rider_id</th>\n",
       "      <th>last_mile_distance</th>\n",
       "      <th>alloted_orders</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>Accept_time_f1</th>\n",
       "      <th>order_day_of_week</th>\n",
       "      <th>order_time_hour</th>\n",
       "      <th>diff_allot_and_order</th>\n",
       "      <th>diff_accept_and_allot</th>\n",
       "      <th>diff_accept_and_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>556753</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5666</td>\n",
       "      <td>621.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>11696</td>\n",
       "      <td>2.65</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>556754</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5207</td>\n",
       "      <td>105.0</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18117</td>\n",
       "      <td>2.76</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>556755</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2074</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9.816667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18623</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>556756</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1894</td>\n",
       "      <td>127.0</td>\n",
       "      <td>17.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15945</td>\n",
       "      <td>6.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>556757</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7870</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17589</td>\n",
       "      <td>4.01</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>51.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reassignment_method  reassigned_order  order_id  reassignment_reason  \\\n",
       "0                    0               0.0    556753                    1   \n",
       "1                    0               0.0    556754                    1   \n",
       "2                    0               0.0    556755                    1   \n",
       "3                    0               0.0    556756                    1   \n",
       "4                    0               0.0    556757                    1   \n",
       "\n",
       "   first_mile_distance  lifetime_order_count  session_time  \\\n",
       "0               1.5666                 621.0           NaN   \n",
       "1               2.5207                 105.0      3.266667   \n",
       "2               2.2074                  66.0      9.816667   \n",
       "3               2.1894                 127.0     17.533333   \n",
       "4               2.7870                  84.0      1.350000   \n",
       "\n",
       "   undelivered_orders  delivered_orders  rider_id  last_mile_distance  \\\n",
       "0                 0.0              46.0     11696                2.65   \n",
       "1                 0.0               8.0     18117                2.76   \n",
       "2                 0.0               1.0     18623                4.80   \n",
       "3                 0.0               1.0     15945                6.38   \n",
       "4                 0.0              34.0     17589                4.01   \n",
       "\n",
       "   alloted_orders  cancelled  Accept_time_f1  order_day_of_week  \\\n",
       "0            46.0          0               1                  1   \n",
       "1             8.0          0               1                  1   \n",
       "2             1.0          0               1                  1   \n",
       "3             1.0          0               1                  1   \n",
       "4            34.0          0               1                  1   \n",
       "\n",
       "   order_time_hour  diff_allot_and_order  diff_accept_and_allot  \\\n",
       "0                2                  24.0                    9.0   \n",
       "1                2                  41.0                   48.0   \n",
       "2                2                   8.0                   16.0   \n",
       "3                2                  32.0                   41.0   \n",
       "4                3                  51.0                   36.0   \n",
       "\n",
       "   diff_accept_and_order  \n",
       "0                   33.0  \n",
       "1                   89.0  \n",
       "2                   24.0  \n",
       "3                   73.0  \n",
       "4                   87.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e90146e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    181\n",
       "0      1\n",
       "Name: cancelled, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['diff_accept_and_allot'] < 0].cancelled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a851ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    157\n",
       "Name: cancelled, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['diff_accept_and_order'] < 0].cancelled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d56ce17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reassignment_method</th>\n",
       "      <th>reassigned_order</th>\n",
       "      <th>order_id</th>\n",
       "      <th>reassignment_reason</th>\n",
       "      <th>first_mile_distance</th>\n",
       "      <th>lifetime_order_count</th>\n",
       "      <th>session_time</th>\n",
       "      <th>undelivered_orders</th>\n",
       "      <th>delivered_orders</th>\n",
       "      <th>rider_id</th>\n",
       "      <th>last_mile_distance</th>\n",
       "      <th>alloted_orders</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>Accept_time_f1</th>\n",
       "      <th>order_day_of_week</th>\n",
       "      <th>order_time_hour</th>\n",
       "      <th>diff_allot_and_order</th>\n",
       "      <th>diff_accept_and_allot</th>\n",
       "      <th>diff_accept_and_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>556753</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5666</td>\n",
       "      <td>621.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>11696</td>\n",
       "      <td>2.65</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>556754</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5207</td>\n",
       "      <td>105.0</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>18117</td>\n",
       "      <td>2.76</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>556755</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2074</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9.816667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18623</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>556756</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1894</td>\n",
       "      <td>127.0</td>\n",
       "      <td>17.533333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15945</td>\n",
       "      <td>6.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>556757</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7870</td>\n",
       "      <td>84.0</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>17589</td>\n",
       "      <td>4.01</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>51.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reassignment_method  reassigned_order  order_id  reassignment_reason  \\\n",
       "0                    0               0.0    556753                    1   \n",
       "1                    0               0.0    556754                    1   \n",
       "2                    0               0.0    556755                    1   \n",
       "3                    0               0.0    556756                    1   \n",
       "4                    0               0.0    556757                    1   \n",
       "\n",
       "   first_mile_distance  lifetime_order_count  session_time  \\\n",
       "0               1.5666                 621.0           NaN   \n",
       "1               2.5207                 105.0      3.266667   \n",
       "2               2.2074                  66.0      9.816667   \n",
       "3               2.1894                 127.0     17.533333   \n",
       "4               2.7870                  84.0      1.350000   \n",
       "\n",
       "   undelivered_orders  delivered_orders  rider_id  last_mile_distance  \\\n",
       "0                 0.0              46.0     11696                2.65   \n",
       "1                 0.0               8.0     18117                2.76   \n",
       "2                 0.0               1.0     18623                4.80   \n",
       "3                 0.0               1.0     15945                6.38   \n",
       "4                 0.0              34.0     17589                4.01   \n",
       "\n",
       "   alloted_orders  cancelled  Accept_time_f1  order_day_of_week  \\\n",
       "0            46.0          0               1                  1   \n",
       "1             8.0          0               1                  1   \n",
       "2             1.0          0               1                  1   \n",
       "3             1.0          0               1                  1   \n",
       "4            34.0          0               1                  1   \n",
       "\n",
       "   order_time_hour  diff_allot_and_order  diff_accept_and_allot  \\\n",
       "0                2                  24.0                    9.0   \n",
       "1                2                  41.0                   48.0   \n",
       "2                2                   8.0                   16.0   \n",
       "3                2                  32.0                   41.0   \n",
       "4                3                  51.0                   36.0   \n",
       "\n",
       "   diff_accept_and_order  \n",
       "0                   33.0  \n",
       "1                   89.0  \n",
       "2                   24.0  \n",
       "3                   73.0  \n",
       "4                   87.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83b6d1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "it_imputer = IterativeImputer(max_iter=1000)#best\n",
    "train_ = pd.DataFrame(it_imputer.fit_transform(train[['session_time']]))\n",
    "test_ = pd.DataFrame(it_imputer.transform(test[['session_time']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c607e9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['session_time'] = train_.values\n",
    "test['session_time'] = test_.values\n",
    "del train_\n",
    "gc.collect()\n",
    "del test_\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029286c3",
   "metadata": {},
   "source": [
    "# *Modeling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e14d65b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['cancelled']\n",
    "not_features = ['order_id','kfold', 'cancelled']\n",
    "cols = list(train.columns)\n",
    "features = [feat for feat in cols if feat not in not_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8d69512",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"kfold\"] = -1\n",
    "train_targets = train[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8949218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize stratified k-fold\n",
    "kf = model_selection.StratifiedKFold(n_splits=20, shuffle=True, random_state=RANDOM_SEED)\n",
    "for fold, (train_indicies, valid_indicies) in enumerate(kf.split(X=train, y=train_targets)):\n",
    "    train.loc[valid_indicies, \"kfold\"] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "52e79f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_20Folds.csv\", index=False)\n",
    "#test.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_20Folds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68e080a",
   "metadata": {},
   "source": [
    "Let's create a dict to track the diff b/w CV score & Public lb to see if they co-relate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c76cf9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6458e52b",
   "metadata": {},
   "source": [
    "# 1. L0 Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca67db19",
   "metadata": {},
   "source": [
    "### 1. LGBM-CLF, cv - 0.7596915073267636, public-lb - 0.76176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e95fc835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0020684926732363884\n"
     ]
    }
   ],
   "source": [
    "diff = 0.76176 - 0.7596915073267636\n",
    "print(diff)\n",
    "score_dict.update({'L0_LGBMCLF': diff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a25e4ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING ACCURACY :  0.8708263709120287  VALIDATION ACCURACY:  0.7757480457941339\n",
      "ROC-AUC is:  0.7757480457941339\n",
      "0 0.7757480457941339\n",
      "TRAINING ACCURACY :  0.8604905000347223  VALIDATION ACCURACY:  0.7743216484504705\n",
      "ROC-AUC is:  0.7743216484504705\n",
      "1 0.7743216484504705\n",
      "TRAINING ACCURACY :  0.866425047662998  VALIDATION ACCURACY:  0.7571777273675617\n",
      "ROC-AUC is:  0.7571777273675617\n",
      "2 0.7571777273675617\n",
      "TRAINING ACCURACY :  0.8621001500434712  VALIDATION ACCURACY:  0.7503078279347369\n",
      "ROC-AUC is:  0.7503078279347369\n",
      "3 0.7503078279347369\n",
      "TRAINING ACCURACY :  0.8688915014247164  VALIDATION ACCURACY:  0.7725220906491459\n",
      "ROC-AUC is:  0.7725220906491459\n",
      "4 0.7725220906491459\n",
      "TRAINING ACCURACY :  0.8602298217466734  VALIDATION ACCURACY:  0.7251634498712092\n",
      "ROC-AUC is:  0.7251634498712092\n",
      "5 0.7251634498712092\n",
      "TRAINING ACCURACY :  0.8653739013206162  VALIDATION ACCURACY:  0.750258813216711\n",
      "ROC-AUC is:  0.750258813216711\n",
      "6 0.750258813216711\n",
      "TRAINING ACCURACY :  0.8617546808484434  VALIDATION ACCURACY:  0.7474262965943471\n",
      "ROC-AUC is:  0.7474262965943471\n",
      "7 0.7474262965943471\n",
      "TRAINING ACCURACY :  0.8637286170565304  VALIDATION ACCURACY:  0.7613791242784111\n",
      "ROC-AUC is:  0.7613791242784111\n",
      "8 0.7613791242784111\n",
      "TRAINING ACCURACY :  0.8650244534584268  VALIDATION ACCURACY:  0.7876853837421712\n",
      "ROC-AUC is:  0.7876853837421712\n",
      "9 0.7876853837421712\n",
      "TRAINING ACCURACY :  0.8594284231239226  VALIDATION ACCURACY:  0.7865215210791715\n",
      "ROC-AUC is:  0.7865215210791715\n",
      "10 0.7865215210791715\n",
      "TRAINING ACCURACY :  0.8576054272879632  VALIDATION ACCURACY:  0.7620706711260584\n",
      "ROC-AUC is:  0.7620706711260584\n",
      "11 0.7620706711260584\n",
      "TRAINING ACCURACY :  0.8620681960968155  VALIDATION ACCURACY:  0.7460966108519103\n",
      "ROC-AUC is:  0.7460966108519103\n",
      "12 0.7460966108519103\n",
      "TRAINING ACCURACY :  0.8619679027468472  VALIDATION ACCURACY:  0.7612211401081839\n",
      "ROC-AUC is:  0.7612211401081839\n",
      "13 0.7612211401081839\n",
      "TRAINING ACCURACY :  0.8641075928022349  VALIDATION ACCURACY:  0.7578421395294829\n",
      "ROC-AUC is:  0.7578421395294829\n",
      "14 0.7578421395294829\n",
      "TRAINING ACCURACY :  0.865695673490957  VALIDATION ACCURACY:  0.7901775538778567\n",
      "ROC-AUC is:  0.7901775538778567\n",
      "15 0.7901775538778567\n",
      "TRAINING ACCURACY :  0.8618372956627433  VALIDATION ACCURACY:  0.7588247597202044\n",
      "ROC-AUC is:  0.7588247597202044\n",
      "16 0.7588247597202044\n",
      "TRAINING ACCURACY :  0.8584134538397796  VALIDATION ACCURACY:  0.7434235428113842\n",
      "ROC-AUC is:  0.7434235428113842\n",
      "17 0.7434235428113842\n",
      "TRAINING ACCURACY :  0.8593710693966632  VALIDATION ACCURACY:  0.7416942449829689\n",
      "ROC-AUC is:  0.7416942449829689\n",
      "18 0.7416942449829689\n",
      "TRAINING ACCURACY :  0.8662466404748702  VALIDATION ACCURACY:  0.7439834648977953\n",
      "ROC-AUC is:  0.7439834648977953\n",
      "19 0.7439834648977953\n",
      "0.7596923028441956 0.016778684518310882\n",
      "Wall time: 45.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_20Folds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_20Folds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[features]\n",
    "    xvalid = xvalid[features]\n",
    "    xtest = xtest[features]\n",
    "    \n",
    "    model = LGBMClassifier()\n",
    "    model.fit(xtrain, ytrain, eval_set=[(xvalid, yvalid), (xtrain, ytrain)], verbose=False)\n",
    "    preds_train = model.predict_proba(xtrain)[:, 1]\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    test_preds = model.predict_proba(xtest)[:,1]\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    roc_t = roc_auc_score(ytrain, preds_train)\n",
    "    print(\"TRAINING ACCURACY : \" , roc_t , \" VALIDATION ACCURACY: \" , roc)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))#7574\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"pred_1\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds1.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"pred_1\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c188f771",
   "metadata": {},
   "source": [
    "### 2. LGBM-CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "1df0417d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7923071734919757\n",
      "0 0.7923071734919757\n",
      "ROC-AUC is:  0.7781616629773105\n",
      "1 0.7781616629773105\n",
      "ROC-AUC is:  0.7695241816566424\n",
      "2 0.7695241816566424\n",
      "ROC-AUC is:  0.764931786845759\n",
      "3 0.764931786845759\n",
      "ROC-AUC is:  0.7762625424700904\n",
      "4 0.7762625424700904\n",
      "ROC-AUC is:  0.733055680891961\n",
      "5 0.733055680891961\n",
      "ROC-AUC is:  0.7517155582018336\n",
      "6 0.7517155582018336\n",
      "ROC-AUC is:  0.7550339149114833\n",
      "7 0.7550339149114833\n",
      "ROC-AUC is:  0.7522834053393137\n",
      "8 0.7522834053393137\n",
      "ROC-AUC is:  0.7948746971898286\n",
      "9 0.7948746971898286\n",
      "ROC-AUC is:  0.7941040721152081\n",
      "10 0.7941040721152081\n",
      "ROC-AUC is:  0.7645617214175711\n",
      "11 0.7645617214175711\n",
      "ROC-AUC is:  0.7594952018122869\n",
      "12 0.7594952018122869\n",
      "ROC-AUC is:  0.758099531405513\n",
      "13 0.758099531405513\n",
      "ROC-AUC is:  0.7658579841185421\n",
      "14 0.7658579841185421\n",
      "ROC-AUC is:  0.8082976662964289\n",
      "15 0.8082976662964289\n",
      "ROC-AUC is:  0.7665466021429683\n",
      "16 0.7665466021429683\n",
      "ROC-AUC is:  0.7516916107649069\n",
      "17 0.7516916107649069\n",
      "ROC-AUC is:  0.7423948367258583\n",
      "18 0.7423948367258583\n",
      "ROC-AUC is:  0.7534728521345694\n",
      "19 0.7534728521345694\n",
      "0.7666336341455025\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_20Folds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_20Folds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[features]\n",
    "    xvalid = xvalid[features]\n",
    "    xtest = xtest[features]\n",
    "    \n",
    "    param = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'lambda_l1': 0.5806043684908021,\n",
    "        'lambda_l2': 7.106418698435042,\n",
    "        'bagging_fraction': 0.45,\n",
    "        'feature_fraction': 0.5,\n",
    "        'learning_rate': 0.018,\n",
    "        'max_depth': 8,\n",
    "        'num_leaves': 775,\n",
    "        'min_child_samples': 75,\n",
    "        'min_data_in_leaf': 520,\n",
    "        'max_bin': 331,\n",
    "        'min_gain_to_split': 0.01084372652774491,\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "    }\n",
    "    \n",
    "    model = LGBMClassifier(**param, random_state=RANDOM_SEED, n_estimators=5000)\n",
    "    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=False)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    test_preds = model.predict_proba(xtest)[:,1]\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"pred_2\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds2.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"pred_2\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0adcd2",
   "metadata": {},
   "source": [
    "### 3. XGB-CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "b98f7c0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:14:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:14:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.784625069175429\n",
      "0 0.784625069175429\n",
      "[19:17:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:17:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.7636275594908687\n",
      "1 0.7636275594908687\n",
      "[19:21:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:21:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.7694252908019962\n",
      "2 0.7694252908019962\n",
      "[19:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.7604381967476623\n",
      "3 0.7604381967476623\n",
      "[19:30:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:30:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.7721540064837255\n",
      "4 0.7721540064837255\n",
      "[19:33:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:33:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.726057430088559\n",
      "5 0.726057430088559\n",
      "[19:35:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:35:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.7491804032782836\n",
      "6 0.7491804032782836\n",
      "[19:39:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:39:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.7507400016435867\n",
      "7 0.7507400016435867\n",
      "[19:44:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:44:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.7481796071552185\n",
      "8 0.7481796071552185\n",
      "[19:47:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:47:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.7907671949057771\n",
      "9 0.7907671949057771\n",
      "[19:50:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:50:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.7944195236045062\n",
      "10 0.7944195236045062\n",
      "[19:54:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:54:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.7602349019593655\n",
      "11 0.7602349019593655\n",
      "[19:58:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:58:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.7502669105514992\n",
      "12 0.7502669105514992\n",
      "[20:01:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:01:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.7569042269638147\n",
      "13 0.7569042269638147\n",
      "[20:04:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:04:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.7634708209095236\n",
      "14 0.7634708209095236\n",
      "[20:07:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:07:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.8066246191022329\n",
      "15 0.8066246191022329\n",
      "[20:10:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:10:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.7634778845419984\n",
      "16 0.7634778845419984\n",
      "[20:14:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:14:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.7567985309022722\n",
      "17 0.7567985309022722\n",
      "[20:17:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:17:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.7412573334718495\n",
      "18 0.7412573334718495\n",
      "[20:21:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:21:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ROC-AUC is:  0.74635563942327\n",
      "19 0.74635563942327\n",
      "0.762750257560072\n",
      "Wall time: 1h 10min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_20Folds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_20Folds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "\n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "    \n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[features]\n",
    "    xvalid = xvalid[features]\n",
    "    xtest = xtest[features]\n",
    "    \n",
    "    param = {\n",
    "        \n",
    "        \"metric\": \"auc\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        'learning_rate': 0.01098685543556639,\n",
    "        'reg_lambda': 0.0015620122636105737,\n",
    "        'reg_alpha': 0.1719093206502173,\n",
    "        'subsample': 0.4997703785123122,\n",
    "        'colsample_bytree': 0.9017632656309243,\n",
    "        'max_depth': 6,\n",
    "        'min_child_weight': 34,\n",
    "        'random_state':RANDOM_SEED, \n",
    "        'n_estimators':5000\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(**param)\n",
    "    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=False)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    test_preds = model.predict_proba(xtest)[:,1]\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"pred_3\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds3.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"pred_3\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510081da",
   "metadata": {},
   "source": [
    "### 4. Catboost-CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "dd4f13c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7869268815716657\n",
      "0 0.7869268815716657\n",
      "ROC-AUC is:  0.7605739831211953\n",
      "1 0.7605739831211953\n",
      "ROC-AUC is:  0.7657256702224304\n",
      "2 0.7657256702224304\n",
      "ROC-AUC is:  0.7638949834254449\n",
      "3 0.7638949834254449\n",
      "ROC-AUC is:  0.7752450348262924\n",
      "4 0.7752450348262924\n",
      "ROC-AUC is:  0.7157001636178479\n",
      "5 0.7157001636178479\n",
      "ROC-AUC is:  0.7421877516957456\n",
      "6 0.7421877516957456\n",
      "ROC-AUC is:  0.7439169633823015\n",
      "7 0.7439169633823015\n",
      "ROC-AUC is:  0.7378344866866895\n",
      "8 0.7378344866866895\n",
      "ROC-AUC is:  0.790404968386799\n",
      "9 0.790404968386799\n",
      "ROC-AUC is:  0.7848047138203759\n",
      "10 0.7848047138203759\n",
      "ROC-AUC is:  0.7543008476875821\n",
      "11 0.7543008476875821\n",
      "ROC-AUC is:  0.752918615410882\n",
      "12 0.752918615410882\n",
      "ROC-AUC is:  0.7641385926039632\n",
      "13 0.7641385926039632\n",
      "ROC-AUC is:  0.7580755839685864\n",
      "14 0.7580755839685864\n",
      "ROC-AUC is:  0.804774981096169\n",
      "15 0.804774981096169\n",
      "ROC-AUC is:  0.7494827612049453\n",
      "16 0.7494827612049453\n",
      "ROC-AUC is:  0.7491089055349419\n",
      "17 0.7491089055349419\n",
      "ROC-AUC is:  0.7314369030692172\n",
      "18 0.7314369030692172\n",
      "ROC-AUC is:  0.7436468225110732\n",
      "19 0.7436468225110732\n",
      "0.7587549806922074\n",
      "Wall time: 4min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_20Folds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_20Folds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "\n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "    \n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[features]\n",
    "    xvalid = xvalid[features]\n",
    "    xtest = xtest[features]\n",
    "    \n",
    "       \n",
    "    param = {   \n",
    "            'iterations': 260,\n",
    "            'depth': 8,\n",
    "            'learning_rate': 0.17572035142788606,\n",
    "            'random_strength': 78,\n",
    "            'bagging_temperature': 12.79633128785124,\n",
    "            'od_type': 'Iter'\n",
    "    }\n",
    "    \n",
    "    model = CatBoostClassifier(loss_function=\"Logloss\", eval_metric=\"AUC\",\n",
    "                               random_state=RANDOM_SEED, \n",
    "                               l2_leaf_reg=50,\n",
    "                                border_count=64,**param)\n",
    "    \n",
    "    model.fit(xtrain, ytrain, verbose=False)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    test_preds = model.predict_proba(xtest)[:,1]\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"pred_4\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds4.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"pred_4\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68cb610",
   "metadata": {},
   "source": [
    "### 5. Naive Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "40d5f779",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7247490661317101\n",
      "0 0.7247490661317101\n",
      "ROC-AUC is:  0.7277185943552851\n",
      "1 0.7277185943552851\n",
      "ROC-AUC is:  0.687054032825906\n",
      "2 0.687054032825906\n",
      "ROC-AUC is:  0.7029870034330976\n",
      "3 0.7029870034330976\n",
      "ROC-AUC is:  0.7250956562278238\n",
      "4 0.7250956562278238\n",
      "ROC-AUC is:  0.7104732478702718\n",
      "5 0.7104732478702718\n",
      "ROC-AUC is:  0.7151095750294735\n",
      "6 0.7151095750294735\n",
      "ROC-AUC is:  0.6909405812404738\n",
      "7 0.6909405812404738\n",
      "ROC-AUC is:  0.7089909187528932\n",
      "8 0.7089909187528932\n",
      "ROC-AUC is:  0.7248208636961853\n",
      "9 0.7248208636961853\n",
      "ROC-AUC is:  0.7406623516486431\n",
      "10 0.7406623516486431\n",
      "ROC-AUC is:  0.6945986814437858\n",
      "11 0.6945986814437858\n",
      "ROC-AUC is:  0.683030863422254\n",
      "12 0.683030863422254\n",
      "ROC-AUC is:  0.7083644951509886\n",
      "13 0.7083644951509886\n",
      "ROC-AUC is:  0.6942527357362434\n",
      "14 0.6942527357362434\n",
      "ROC-AUC is:  0.7521171515505795\n",
      "15 0.7521171515505795\n",
      "ROC-AUC is:  0.7079070818773205\n",
      "16 0.7079070818773205\n",
      "ROC-AUC is:  0.6961583659509483\n",
      "17 0.6961583659509483\n",
      "ROC-AUC is:  0.6689428791607164\n",
      "18 0.6689428791607164\n",
      "ROC-AUC is:  0.6920114968371294\n",
      "19 0.6920114968371294\n",
      "0.7077992821170864\n",
      "Wall time: 8.41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_20Folds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_20Folds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "\n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "    \n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[features]\n",
    "    xvalid = xvalid[features]\n",
    "    xtest = xtest[features]\n",
    "    \n",
    "    model = GaussianNB()\n",
    "    \n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    test_preds = model.predict_proba(xtest)[:,1]\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"pred_5\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds5.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"pred_5\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65706b58",
   "metadata": {},
   "source": [
    "### 6. Lgbm-Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "4a0e27c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.78805720807969\n",
      "0 0.78805720807969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7776337679856115\n",
      "1 0.7776337679856115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7646801664743119\n",
      "2 0.7646801664743119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7633143872927663\n",
      "3 0.7633143872927663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7744844022073679\n",
      "4 0.7744844022073679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7294919921666039\n",
      "5 0.7294919921666039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.756484199257147\n",
      "6 0.756484199257147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.744019989046201\n",
      "7 0.744019989046201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7509733599408309\n",
      "8 0.7509733599408309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7860057036247977\n",
      "9 0.7860057036247977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7860801301913607\n",
      "10 0.7860801301913607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7694936874383979\n",
      "11 0.7694936874383979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7585702105255361\n",
      "12 0.7585702105255361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.764707473443757\n",
      "13 0.764707473443757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7669607722031934\n",
      "14 0.7669607722031934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.8064828296015819\n",
      "15 0.8064828296015819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7591508066582144\n",
      "16 0.7591508066582144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7457989907275179\n",
      "17 0.7457989907275179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7357534716461486\n",
      "18 0.7357534716461486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7538952918133017\n",
      "19 0.7538952918133017\n",
      "0.764101942016217\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_20Folds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_20Folds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "\n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "    \n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[features]\n",
    "    xvalid = xvalid[features]\n",
    "    xtest = xtest[features]\n",
    "    \n",
    "    params_lgb = {  \n",
    "                \"task\": \"train\",\n",
    "                \"objective\": \"regression\",\n",
    "                \"metric\": \"auc\",\n",
    "                \"verbosity\": -1,\n",
    "                \"boosting_type\": \"gbdt\",\n",
    "                'learning_rate': 0.01243326765467829,\n",
    "                'lambda_l1': 0.44583405781585317,\n",
    "                'lambda_l2': 1.945205216342612e-07,\n",
    "                'num_leaves': 135,\n",
    "                'feature_fraction': 0.45977662840830263,\n",
    "                'bagging_fraction': 0.5398639147101038,\n",
    "                'bagging_freq': 4,\n",
    "                'min_child_samples': 95,\n",
    "                'n_estimators': 5000,\n",
    "                'random_state':RANDOM_SEED,\n",
    "             }\n",
    "    lgb_train = lgb.Dataset(xtrain, ytrain)\n",
    "    lgb_val = lgb.Dataset(xvalid, yvalid)\n",
    "    \n",
    "    model = lgb.train(params=params_lgb,\n",
    "                      train_set=lgb_train,\n",
    "                      valid_sets=lgb_val,\n",
    "                      early_stopping_rounds=300,\n",
    "                      verbose_eval=False)\n",
    "    \n",
    "    preds_valid = model.predict(xvalid,num_iteration=model.best_iteration)\n",
    "    test_preds = model.predict(xtest,num_iteration=model.best_iteration)\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"pred_6\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds6.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"pred_6\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e88bf4",
   "metadata": {},
   "source": [
    "### 7. LGBM - clf 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "c85861a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7912446389042612\n",
      "0 0.7912446389042612\n",
      "ROC-AUC is:  0.7761901632540121\n",
      "1 0.7761901632540121\n",
      "ROC-AUC is:  0.7645345005899856\n",
      "2 0.7645345005899856\n",
      "ROC-AUC is:  0.7732498170777616\n",
      "3 0.7732498170777616\n",
      "ROC-AUC is:  0.7782155507074916\n",
      "4 0.7782155507074916\n",
      "ROC-AUC is:  0.7354311288080947\n",
      "5 0.7354311288080947\n",
      "ROC-AUC is:  0.7492343280822978\n",
      "6 0.7492343280822978\n",
      "ROC-AUC is:  0.7572214012903018\n",
      "7 0.7572214012903018\n",
      "ROC-AUC is:  0.7505541936527578\n",
      "8 0.7505541936527578\n",
      "ROC-AUC is:  0.7935413934892949\n",
      "9 0.7935413934892949\n",
      "ROC-AUC is:  0.7912121176098255\n",
      "10 0.7912121176098255\n",
      "ROC-AUC is:  0.7616211829034596\n",
      "11 0.7616211829034596\n",
      "ROC-AUC is:  0.7591232412631911\n",
      "12 0.7591232412631911\n",
      "ROC-AUC is:  0.7559654529795522\n",
      "13 0.7559654529795522\n",
      "ROC-AUC is:  0.7604186425455678\n",
      "14 0.7604186425455678\n",
      "ROC-AUC is:  0.8139642500946268\n",
      "15 0.8139642500946268\n",
      "ROC-AUC is:  0.7685245915196095\n",
      "16 0.7685245915196095\n",
      "ROC-AUC is:  0.7576040434299689\n",
      "17 0.7576040434299689\n",
      "ROC-AUC is:  0.7414095461374939\n",
      "18 0.7414095461374939\n",
      "ROC-AUC is:  0.7543048102131167\n",
      "19 0.7543048102131167\n",
      "0.7666782497276335\n",
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_20Folds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_20Folds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[features]\n",
    "    xvalid = xvalid[features]\n",
    "    xtest = xtest[features]\n",
    "    \n",
    "    param = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'lambda_l1': 0.004120454129529359,\n",
    "        'lambda_l2': 0.3054014755871697,\n",
    "        'bagging_fraction': 0.6,\n",
    "        'feature_fraction': 0.6,\n",
    "        'learning_rate': 0.0199,\n",
    "        'max_depth': 7,\n",
    "        'num_leaves': 685,\n",
    "        'min_child_samples': 45,\n",
    "        'min_data_in_leaf': 500,\n",
    "        'max_bin': 288,\n",
    "        'min_gain_to_split': 0.02084372652774491,\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "    }\n",
    "    \n",
    "    model = LGBMClassifier(**param, random_state=RANDOM_SEED, n_estimators=5000)\n",
    "    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=False)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    test_preds = model.predict_proba(xtest)[:,1]\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"pred_7\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds7.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"pred_7\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c0986d",
   "metadata": {},
   "source": [
    "### 8. CatBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "d1e53650",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7314410971223022\n",
      "0 0.7314410971223022\n",
      "ROC-AUC is:  0.7328245192307693\n",
      "1 0.7328245192307693\n",
      "ROC-AUC is:  0.714832887376927\n",
      "2 0.714832887376927\n",
      "ROC-AUC is:  0.7009042655553678\n",
      "3 0.7009042655553678\n",
      "ROC-AUC is:  0.7346087324759463\n",
      "4 0.7346087324759463\n",
      "ROC-AUC is:  0.7036276404418111\n",
      "5 0.7036276404418111\n",
      "ROC-AUC is:  0.7236520048053374\n",
      "6 0.7236520048053374\n",
      "ROC-AUC is:  0.6892422083396001\n",
      "7 0.6892422083396001\n",
      "ROC-AUC is:  0.7113756699898474\n",
      "8 0.7113756699898474\n",
      "ROC-AUC is:  0.7428785232666577\n",
      "9 0.7428785232666577\n",
      "ROC-AUC is:  0.7553913174863323\n",
      "10 0.7553913174863323\n",
      "ROC-AUC is:  0.7181702814375146\n",
      "11 0.7181702814375146\n",
      "ROC-AUC is:  0.7019831062030926\n",
      "12 0.7019831062030926\n",
      "ROC-AUC is:  0.7327696899185943\n",
      "13 0.7327696899185943\n",
      "ROC-AUC is:  0.7110582372377819\n",
      "14 0.7110582372377819\n",
      "ROC-AUC is:  0.7609752912413197\n",
      "15 0.7609752912413197\n",
      "ROC-AUC is:  0.7429751744329582\n",
      "16 0.7429751744329582\n",
      "ROC-AUC is:  0.7141817410613608\n",
      "17 0.7141817410613608\n",
      "ROC-AUC is:  0.6912874745084703\n",
      "18 0.6912874745084703\n",
      "ROC-AUC is:  0.7008524081559803\n",
      "19 0.7008524081559803\n",
      "0.7207516135143985\n",
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_20Folds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_20Folds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "\n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "    \n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[features]\n",
    "    xvalid = xvalid[features]\n",
    "    xtest = xtest[features]\n",
    "    \n",
    "       \n",
    "    param = {   \n",
    "            'random_state':RANDOM_SEED,\n",
    "            'learning_rate': 0.023897097025582358,\n",
    "            'iterations': 27,\n",
    "            'l2_leaf_reg': 2.328838945916324,\n",
    "            'depth': 6,\n",
    "    }\n",
    "    \n",
    "    model = CatBoostRegressor(\n",
    "        **param\n",
    "    )\n",
    "    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=False)\n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"pred_8\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds8.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"pred_8\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds8.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3a9c2a",
   "metadata": {},
   "source": [
    "### 9. LGBM Clf - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "f04c9d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7944249792473712\n",
      "0 0.7944249792473712\n",
      "ROC-AUC is:  0.7762674667957942\n",
      "1 0.7762674667957942\n",
      "ROC-AUC is:  0.768639504760113\n",
      "2 0.768639504760113\n",
      "ROC-AUC is:  0.7664914713529216\n",
      "3 0.7664914713529216\n",
      "ROC-AUC is:  0.7802786482412675\n",
      "4 0.7802786482412675\n",
      "ROC-AUC is:  0.7299661169610048\n",
      "5 0.7299661169610048\n",
      "ROC-AUC is:  0.7478705301635197\n",
      "6 0.7478705301635197\n",
      "ROC-AUC is:  0.7538622133392736\n",
      "7 0.7538622133392736\n",
      "ROC-AUC is:  0.7503417678273593\n",
      "8 0.7503417678273593\n",
      "ROC-AUC is:  0.794781663981625\n",
      "9 0.794781663981625\n",
      "ROC-AUC is:  0.7904258147167854\n",
      "10 0.7904258147167854\n",
      "ROC-AUC is:  0.7664563254742669\n",
      "11 0.7664563254742669\n",
      "ROC-AUC is:  0.7548914362759566\n",
      "12 0.7548914362759566\n",
      "ROC-AUC is:  0.7592991429401836\n",
      "13 0.7592991429401836\n",
      "ROC-AUC is:  0.7690521242668681\n",
      "14 0.7690521242668681\n",
      "ROC-AUC is:  0.8152119287868694\n",
      "15 0.8152119287868694\n",
      "ROC-AUC is:  0.7662368360163938\n",
      "16 0.7662368360163938\n",
      "ROC-AUC is:  0.7508687837234611\n",
      "17 0.7508687837234611\n",
      "ROC-AUC is:  0.7450237139924873\n",
      "18 0.7450237139924873\n",
      "ROC-AUC is:  0.7558057459721358\n",
      "19 0.7558057459721358\n",
      "0.766809810741783\n",
      "Wall time: 3min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_20Folds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_20Folds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[features]\n",
    "    xvalid = xvalid[features]\n",
    "    xtest = xtest[features]\n",
    "    \n",
    "    param = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'lambda_l1': 2.013079655498328,\n",
    "        'lambda_l2': 6.704712390093808,\n",
    "        'bagging_fraction': 0.45,\n",
    "        'feature_fraction': 0.6,\n",
    "        'learning_rate': 0.0199,\n",
    "        'max_depth': 10,\n",
    "        'num_leaves': 790,\n",
    "        'min_child_samples': 65,\n",
    "        'min_data_in_leaf': 480,\n",
    "        'max_bin': 336,\n",
    "        'min_gain_to_split': 0.01084372652774491,\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "    }\n",
    "    \n",
    "    model = LGBMClassifier(**param, random_state=RANDOM_SEED, n_estimators=5000)\n",
    "    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=False)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    test_preds = model.predict_proba(xtest)[:,1]\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"pred_9\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds9.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"pred_9\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds9.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce3c7b3",
   "metadata": {},
   "source": [
    "### 10. LGBM Clf - 3, CV - 0.7688429025270969 , public-lb - 0.77032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "979a1612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0014770974729031439\n"
     ]
    }
   ],
   "source": [
    "diff = 0.77032 - 0.7688429025270969\n",
    "print(diff)\n",
    "score_dict.update({'L0_LGBMCLF_TUNED': diff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "595f58e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7864198256779191\n",
      "0 0.7864198256779191\n",
      "ROC-AUC is:  0.7781665052573326\n",
      "1 0.7781665052573326\n",
      "ROC-AUC is:  0.7716032154344159\n",
      "2 0.7716032154344159\n",
      "ROC-AUC is:  0.7661849786170061\n",
      "3 0.7661849786170061\n",
      "ROC-AUC is:  0.776917048318175\n",
      "4 0.776917048318175\n",
      "ROC-AUC is:  0.7359895003410357\n",
      "5 0.7359895003410357\n",
      "ROC-AUC is:  0.7588837668939261\n",
      "6 0.7588837668939261\n",
      "ROC-AUC is:  0.7565400191820693\n",
      "7 0.7565400191820693\n",
      "ROC-AUC is:  0.7651755683079964\n",
      "8 0.7651755683079964\n",
      "ROC-AUC is:  0.7971953588833535\n",
      "9 0.7971953588833535\n",
      "ROC-AUC is:  0.7921300452641015\n",
      "10 0.7921300452641015\n",
      "ROC-AUC is:  0.7675430911730609\n",
      "11 0.7675430911730609\n",
      "ROC-AUC is:  0.7540749837321098\n",
      "12 0.7540749837321098\n",
      "ROC-AUC is:  0.764575331831364\n",
      "13 0.764575331831364\n",
      "ROC-AUC is:  0.762831131461264\n",
      "14 0.762831131461264\n",
      "ROC-AUC is:  0.8077858113675899\n",
      "15 0.8077858113675899\n",
      "ROC-AUC is:  0.7664950893110185\n",
      "16 0.7664950893110185\n",
      "ROC-AUC is:  0.7522782368277467\n",
      "17 0.7522782368277467\n",
      "ROC-AUC is:  0.7400760701532411\n",
      "18 0.7400760701532411\n",
      "ROC-AUC is:  0.7536327314257046\n",
      "19 0.7536327314257046\n",
      "0.7677249154730217 0.01770552748116343\n",
      "Wall time: 4min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_20Folds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_20Folds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[features]\n",
    "    xvalid = xvalid[features]\n",
    "    xtest = xtest[features]\n",
    "    \n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        'learning_rate': 0.010652195229674963,\n",
    "        'lambda_l1': 1.919242522820974e-06,\n",
    "        'lambda_l2': 0.023974154523133086,\n",
    "        'num_leaves': 21,\n",
    "        'feature_fraction': 0.819493399510842,\n",
    "        'bagging_fraction': 0.9243051254494783,\n",
    "        'bagging_freq': 3,\n",
    "        'min_child_samples': 80\n",
    "    }\n",
    "    \n",
    "    model = LGBMClassifier(**param, random_state=RANDOM_SEED, n_estimators=10000)\n",
    "    model.fit(xtrain, ytrain, early_stopping_rounds=500, eval_set=[(xvalid, yvalid)], verbose=False)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    test_preds = model.predict_proba(xtest)[:,1]\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"pred_10\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds10.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"pred_10\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734ed1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\FINAL_SUBMISSION1.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65b42e1",
   "metadata": {},
   "source": [
    "### 11. LGBM Clf - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "b1fb81ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7955257332595463\n",
      "0 0.7955257332595463\n",
      "ROC-AUC is:  0.7735181758439402\n",
      "1 0.7735181758439402\n",
      "ROC-AUC is:  0.7639365038016986\n",
      "2 0.7639365038016986\n",
      "ROC-AUC is:  0.7742085759734159\n",
      "3 0.7742085759734159\n",
      "ROC-AUC is:  0.7768722545512622\n",
      "4 0.7768722545512622\n",
      "ROC-AUC is:  0.7293359031172844\n",
      "5 0.7293359031172844\n",
      "ROC-AUC is:  0.7520318711097259\n",
      "6 0.7520318711097259\n",
      "ROC-AUC is:  0.7377359403994811\n",
      "7 0.7377359403994811\n",
      "ROC-AUC is:  0.7535131665247911\n",
      "8 0.7535131665247911\n",
      "ROC-AUC is:  0.7958052015555842\n",
      "9 0.7958052015555842\n",
      "ROC-AUC is:  0.794367149353962\n",
      "10 0.794367149353962\n",
      "ROC-AUC is:  0.7583045490309988\n",
      "11 0.7583045490309988\n",
      "ROC-AUC is:  0.7516194238866896\n",
      "12 0.7516194238866896\n",
      "ROC-AUC is:  0.7670572510857752\n",
      "13 0.7670572510857752\n",
      "ROC-AUC is:  0.7672271228326061\n",
      "14 0.7672271228326061\n",
      "ROC-AUC is:  0.8117772805669651\n",
      "15 0.8117772805669651\n",
      "ROC-AUC is:  0.7577503123073115\n",
      "16 0.7577503123073115\n",
      "ROC-AUC is:  0.7537357570896042\n",
      "17 0.7537357570896042\n",
      "ROC-AUC is:  0.7402802263601326\n",
      "18 0.7402802263601326\n",
      "ROC-AUC is:  0.7531732507474098\n",
      "19 0.7531732507474098\n",
      "0.7653887824699093\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_20Folds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_20Folds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[features]\n",
    "    xvalid = xvalid[features]\n",
    "    xtest = xtest[features]\n",
    "    \n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        'learning_rate': 0.04394129972546718,\n",
    "        'lambda_l1': 3.332009828221393e-08,\n",
    "        'lambda_l2': 2.8764308768784934,\n",
    "        'num_leaves': 96,\n",
    "        'feature_fraction': 0.5517245233128265,\n",
    "        'bagging_fraction': 0.5205133833553873,\n",
    "        'bagging_freq': 5,\n",
    "        'min_child_samples': 27\n",
    "    }\n",
    "    \n",
    "    model = LGBMClassifier(**param, random_state=RANDOM_SEED, n_estimators=10000)\n",
    "    model.fit(xtrain, ytrain, early_stopping_rounds=500, eval_set=[(xvalid, yvalid)], verbose=False)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    test_preds = model.predict_proba(xtest)[:,1]\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"pred_11\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds11.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"pred_11\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds11.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736a78b5",
   "metadata": {},
   "source": [
    "### 12. LGBM Clf - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "d520c1fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7986787493082456\n",
      "0 0.7986787493082456\n",
      "ROC-AUC is:  0.7774878942999448\n",
      "1 0.7774878942999448\n",
      "ROC-AUC is:  0.7701397513842566\n",
      "2 0.7701397513842566\n",
      "ROC-AUC is:  0.7623244450439918\n",
      "3 0.7623244450439918\n",
      "ROC-AUC is:  0.7759339974181563\n",
      "4 0.7759339974181563\n",
      "ROC-AUC is:  0.737595873736019\n",
      "5 0.737595873736019\n",
      "ROC-AUC is:  0.7578536825386487\n",
      "6 0.7578536825386487\n",
      "ROC-AUC is:  0.7535526194964183\n",
      "7 0.7535526194964183\n",
      "ROC-AUC is:  0.7566731944967757\n",
      "8 0.7566731944967757\n",
      "ROC-AUC is:  0.8005035508535883\n",
      "9 0.8005035508535883\n",
      "ROC-AUC is:  0.7920215065211972\n",
      "10 0.7920215065211972\n",
      "ROC-AUC is:  0.7645474218689028\n",
      "11 0.7645474218689028\n",
      "ROC-AUC is:  0.7590319308921765\n",
      "12 0.7590319308921765\n",
      "ROC-AUC is:  0.7652488750303865\n",
      "13 0.7652488750303865\n",
      "ROC-AUC is:  0.7652246691678818\n",
      "14 0.7652246691678818\n",
      "ROC-AUC is:  0.8104345012618922\n",
      "15 0.8104345012618922\n",
      "ROC-AUC is:  0.7630501040679805\n",
      "16 0.7630501040679805\n",
      "ROC-AUC is:  0.7552776963737208\n",
      "17 0.7552776963737208\n",
      "ROC-AUC is:  0.7356699140424842\n",
      "18 0.7356699140424842\n",
      "ROC-AUC is:  0.7535569265893904\n",
      "19 0.7535569265893904\n",
      "0.7677403652196029\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_20Folds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_20Folds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[features]\n",
    "    xvalid = xvalid[features]\n",
    "    xtest = xtest[features]\n",
    "    \n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        'learning_rate': 0.033393159236481285,\n",
    "        'lambda_l1': 3.346640904962391e-08,\n",
    "        'lambda_l2': 3.908099023297473e-08,\n",
    "        'num_leaves': 16,\n",
    "        'feature_fraction': 0.43480396855094344,\n",
    "        'bagging_fraction': 0.9883525790842624,\n",
    "        'bagging_freq': 5,\n",
    "        'min_child_samples': 25\n",
    "    }\n",
    "    \n",
    "    model = LGBMClassifier(**param, random_state=RANDOM_SEED, n_estimators=10000)\n",
    "    model.fit(xtrain, ytrain, early_stopping_rounds=500, eval_set=[(xvalid, yvalid)], verbose=False)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    test_preds = model.predict_proba(xtest)[:,1]\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"pred_12\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds12.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"pred_12\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds12.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cfa1e9",
   "metadata": {},
   "source": [
    "Getting oof preds of validation & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "2dc8b608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lifetime_order_count</th>\n",
       "      <th>rider_id</th>\n",
       "      <th>first_mile_distance</th>\n",
       "      <th>last_mile_distance</th>\n",
       "      <th>alloted_orders</th>\n",
       "      <th>reassigned_order</th>\n",
       "      <th>reassignment_reason</th>\n",
       "      <th>delivered_orders</th>\n",
       "      <th>order_id</th>\n",
       "      <th>reassignment_method</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>pred_8</th>\n",
       "      <th>pred_9</th>\n",
       "      <th>pred_10</th>\n",
       "      <th>pred_11</th>\n",
       "      <th>pred_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>621.0</td>\n",
       "      <td>11696</td>\n",
       "      <td>1.5666</td>\n",
       "      <td>2.65</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>556753</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006742</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>1.116932e-13</td>\n",
       "      <td>0.005490</td>\n",
       "      <td>0.004331</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.004369</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.005685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105.0</td>\n",
       "      <td>18117</td>\n",
       "      <td>2.5207</td>\n",
       "      <td>2.76</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>556754</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011698</td>\n",
       "      <td>0.017587</td>\n",
       "      <td>2.632376e-13</td>\n",
       "      <td>0.015991</td>\n",
       "      <td>0.017396</td>\n",
       "      <td>0.012325</td>\n",
       "      <td>0.014709</td>\n",
       "      <td>0.017112</td>\n",
       "      <td>0.020315</td>\n",
       "      <td>0.016773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.0</td>\n",
       "      <td>18623</td>\n",
       "      <td>2.2074</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>556755</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103087</td>\n",
       "      <td>0.020978</td>\n",
       "      <td>2.805588e-13</td>\n",
       "      <td>0.091615</td>\n",
       "      <td>0.066154</td>\n",
       "      <td>0.021493</td>\n",
       "      <td>0.098316</td>\n",
       "      <td>0.081646</td>\n",
       "      <td>0.046981</td>\n",
       "      <td>0.075391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127.0</td>\n",
       "      <td>15945</td>\n",
       "      <td>2.1894</td>\n",
       "      <td>6.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>556756</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075729</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>1.928160e-13</td>\n",
       "      <td>0.065025</td>\n",
       "      <td>0.045732</td>\n",
       "      <td>0.025672</td>\n",
       "      <td>0.104228</td>\n",
       "      <td>0.065323</td>\n",
       "      <td>0.042542</td>\n",
       "      <td>0.045629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.0</td>\n",
       "      <td>17589</td>\n",
       "      <td>2.7870</td>\n",
       "      <td>4.01</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>556757</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011196</td>\n",
       "      <td>0.010543</td>\n",
       "      <td>2.393230e-13</td>\n",
       "      <td>0.017169</td>\n",
       "      <td>0.016855</td>\n",
       "      <td>0.011861</td>\n",
       "      <td>0.021343</td>\n",
       "      <td>0.017120</td>\n",
       "      <td>0.014491</td>\n",
       "      <td>0.013588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lifetime_order_count  rider_id  first_mile_distance  last_mile_distance  \\\n",
       "0                 621.0     11696               1.5666                2.65   \n",
       "1                 105.0     18117               2.5207                2.76   \n",
       "2                  66.0     18623               2.2074                4.80   \n",
       "3                 127.0     15945               2.1894                6.38   \n",
       "4                  84.0     17589               2.7870                4.01   \n",
       "\n",
       "   alloted_orders  reassigned_order  reassignment_reason  delivered_orders  \\\n",
       "0            46.0               0.0                    1              46.0   \n",
       "1             8.0               0.0                    1               8.0   \n",
       "2             1.0               0.0                    1               1.0   \n",
       "3             1.0               0.0                    1               1.0   \n",
       "4            34.0               0.0                    1              34.0   \n",
       "\n",
       "   order_id  reassignment_method  ...    pred_3    pred_4        pred_5  \\\n",
       "0    556753                    0  ...  0.006742  0.003334  1.116932e-13   \n",
       "1    556754                    0  ...  0.011698  0.017587  2.632376e-13   \n",
       "2    556755                    0  ...  0.103087  0.020978  2.805588e-13   \n",
       "3    556756                    0  ...  0.075729  0.024250  1.928160e-13   \n",
       "4    556757                    0  ...  0.011196  0.010543  2.393230e-13   \n",
       "\n",
       "     pred_6    pred_7    pred_8    pred_9   pred_10   pred_11   pred_12  \n",
       "0  0.005490  0.004331  0.009546  0.005139  0.004369  0.005222  0.005685  \n",
       "1  0.015991  0.017396  0.012325  0.014709  0.017112  0.020315  0.016773  \n",
       "2  0.091615  0.066154  0.021493  0.098316  0.081646  0.046981  0.075391  \n",
       "3  0.065025  0.045732  0.025672  0.104228  0.065323  0.042542  0.045629  \n",
       "4  0.017169  0.016855  0.011861  0.021343  0.017120  0.014491  0.013588  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_20Folds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_20Folds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "df1 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds1.csv\")\n",
    "df2 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds2.csv\")\n",
    "df3 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds3.csv\")\n",
    "df4 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds4.csv\")\n",
    "df5 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds5.csv\")\n",
    "df6 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds6.csv\")\n",
    "df7 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds7.csv\")\n",
    "df8 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds8.csv\")\n",
    "df9 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds9.csv\")\n",
    "df10 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds10.csv\")\n",
    "df11 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds11.csv\")\n",
    "df12 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds12.csv\")\n",
    "\n",
    "df_test1 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds1.csv\")\n",
    "df_test2 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds2.csv\")\n",
    "df_test3 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds3.csv\")\n",
    "df_test4 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds4.csv\")\n",
    "df_test5 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds5.csv\")\n",
    "df_test6 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds6.csv\")\n",
    "df_test7 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds7.csv\")\n",
    "df_test8 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds8.csv\")\n",
    "df_test9 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds9.csv\")\n",
    "df_test10 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds10.csv\")\n",
    "df_test11 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds11.csv\")\n",
    "df_test12 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds12.csv\")\n",
    "\n",
    "train = train.merge(df1, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df2, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df3, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df4, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df5, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df6, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df7, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df8, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df9, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df10, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df11, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df12, on=\"order_id\", how=\"left\")\n",
    "\n",
    "test = test.merge(df_test1, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test2, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test3, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test4, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test5, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test6, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test7, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test8, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test9, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test10, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test11, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test12, on=\"order_id\", how=\"left\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "d04e94c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lifetime_order_count</th>\n",
       "      <th>rider_id</th>\n",
       "      <th>first_mile_distance</th>\n",
       "      <th>last_mile_distance</th>\n",
       "      <th>alloted_orders</th>\n",
       "      <th>reassigned_order</th>\n",
       "      <th>reassignment_reason</th>\n",
       "      <th>delivered_orders</th>\n",
       "      <th>order_id</th>\n",
       "      <th>reassignment_method</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>pred_8</th>\n",
       "      <th>pred_9</th>\n",
       "      <th>pred_10</th>\n",
       "      <th>pred_11</th>\n",
       "      <th>pred_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>747.0</td>\n",
       "      <td>12884</td>\n",
       "      <td>1.6585</td>\n",
       "      <td>4.54</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>215.0</td>\n",
       "      <td>130231</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>0.005912</td>\n",
       "      <td>1.247497e-13</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>0.005410</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.005528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75.0</td>\n",
       "      <td>3541</td>\n",
       "      <td>2.0709</td>\n",
       "      <td>5.84</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>130232</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.006257</td>\n",
       "      <td>6.479355e-14</td>\n",
       "      <td>0.007890</td>\n",
       "      <td>0.006427</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>0.006559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2214.0</td>\n",
       "      <td>603</td>\n",
       "      <td>1.3884</td>\n",
       "      <td>0.99</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>289.0</td>\n",
       "      <td>130233</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.003313</td>\n",
       "      <td>4.365101e-14</td>\n",
       "      <td>0.005146</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>0.004042</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.003977</td>\n",
       "      <td>0.003594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1020.0</td>\n",
       "      <td>3414</td>\n",
       "      <td>1.9039</td>\n",
       "      <td>2.59</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>130234</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005969</td>\n",
       "      <td>0.006257</td>\n",
       "      <td>6.006810e-14</td>\n",
       "      <td>0.006662</td>\n",
       "      <td>0.005931</td>\n",
       "      <td>0.009631</td>\n",
       "      <td>0.006568</td>\n",
       "      <td>0.006064</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>0.006174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7284.0</td>\n",
       "      <td>1426</td>\n",
       "      <td>0.8275</td>\n",
       "      <td>0.94</td>\n",
       "      <td>352.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>350.0</td>\n",
       "      <td>130235</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>2.506175e-15</td>\n",
       "      <td>0.005211</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.009631</td>\n",
       "      <td>0.004417</td>\n",
       "      <td>0.004252</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.003748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   lifetime_order_count  rider_id  first_mile_distance  last_mile_distance  \\\n",
       "0                 747.0     12884               1.6585                4.54   \n",
       "1                  75.0      3541               2.0709                5.84   \n",
       "2                2214.0       603               1.3884                0.99   \n",
       "3                1020.0      3414               1.9039                2.59   \n",
       "4                7284.0      1426               0.8275                0.94   \n",
       "\n",
       "   alloted_orders  reassigned_order  reassignment_reason  delivered_orders  \\\n",
       "0           216.0               0.0                    1             215.0   \n",
       "1            52.0               0.0                    1              52.0   \n",
       "2           289.0               0.0                    1             289.0   \n",
       "3           125.0               0.0                    1             122.0   \n",
       "4           352.0               0.0                    1             350.0   \n",
       "\n",
       "   order_id  reassignment_method  ...    pred_3    pred_4        pred_5  \\\n",
       "0    130231                    0  ...  0.004996  0.005912  1.247497e-13   \n",
       "1    130232                    0  ...  0.005327  0.006257  6.479355e-14   \n",
       "2    130233                    0  ...  0.003306  0.003313  4.365101e-14   \n",
       "3    130234                    0  ...  0.005969  0.006257  6.006810e-14   \n",
       "4    130235                    0  ...  0.002686  0.003180  2.506175e-15   \n",
       "\n",
       "     pred_6    pred_7    pred_8    pred_9   pred_10   pred_11   pred_12  \n",
       "0  0.006389  0.005208  0.009735  0.004678  0.005410  0.005261  0.005528  \n",
       "1  0.007890  0.006427  0.009473  0.006202  0.006726  0.006044  0.006559  \n",
       "2  0.005146  0.003792  0.009473  0.004042  0.003202  0.003977  0.003594  \n",
       "3  0.006662  0.005931  0.009631  0.006568  0.006064  0.005997  0.006174  \n",
       "4  0.005211  0.004717  0.009631  0.004417  0.004252  0.004393  0.003748  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "53f3bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_features = [\"pred_1\", \"pred_2\", \"pred_3\", \"pred_4\", 'pred_6', \n",
    "                  \"pred_7\", \"pred_9\", \"pred_10\", \"pred_11\", \"pred_12\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "df848676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_L0_preds.csv\", index=False)#adding 5,8\n",
    "#test.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_L0_preds.csv\", index=False)#adding 5, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a421268a",
   "metadata": {},
   "source": [
    "## *L1 Models*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93568cc",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression(Solver='Saga'), CV - 0.7668689554420469 , public-lb - 0.76961"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "15cc5c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0027410445579530984\n"
     ]
    }
   ],
   "source": [
    "diff = 0.76961 - 0.7668689554420469\n",
    "print(diff)\n",
    "score_dict.update({\"L1-Model: LogR\":diff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "481aa5bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7937605492529054\n",
      "0 0.7937605492529054\n",
      "ROC-AUC is:  0.773381467902601\n",
      "1 0.773381467902601\n",
      "ROC-AUC is:  0.7710483757177125\n",
      "2 0.7710483757177125\n",
      "ROC-AUC is:  0.7677207156872423\n",
      "3 0.7677207156872423\n",
      "ROC-AUC is:  0.7787904614774466\n",
      "4 0.7787904614774466\n",
      "ROC-AUC is:  0.7307291615519937\n",
      "5 0.7307291615519937\n",
      "ROC-AUC is:  0.7543210048826929\n",
      "6 0.7543210048826929\n",
      "ROC-AUC is:  0.7507910837662393\n",
      "7 0.7507910837662393\n",
      "ROC-AUC is:  0.7528166234492958\n",
      "8 0.7528166234492958\n",
      "ROC-AUC is:  0.795209272171924\n",
      "9 0.795209272171924\n",
      "ROC-AUC is:  0.7905517541152982\n",
      "10 0.7905517541152982\n",
      "ROC-AUC is:  0.7670396781464478\n",
      "11 0.7670396781464478\n",
      "ROC-AUC is:  0.7580972917171673\n",
      "12 0.7580972917171673\n",
      "ROC-AUC is:  0.7641751167523692\n",
      "13 0.7641751167523692\n",
      "ROC-AUC is:  0.7677620637797772\n",
      "14 0.7677620637797772\n",
      "ROC-AUC is:  0.8124979433631058\n",
      "15 0.8124979433631058\n",
      "ROC-AUC is:  0.7618344701474524\n",
      "16 0.7618344701474524\n",
      "ROC-AUC is:  0.7520410021468273\n",
      "17 0.7520410021468273\n",
      "ROC-AUC is:  0.7404308023304474\n",
      "18 0.7404308023304474\n",
      "ROC-AUC is:  0.754380270481993\n",
      "19 0.754380270481993\n",
      "0.7668689554420469\n",
      "Wall time: 1min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_L0_preds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_L0_preds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    xtest = xtest[useful_features]\n",
    "    \n",
    "    model = LogisticRegression(solver='saga',random_state=RANDOM_SEED)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    test_preds = model.predict_proba(xtest)[:,1]\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"pred_1_L0\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds1_L0.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"pred_1_L0\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds1_L0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4818f691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>cancelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130231</td>\n",
       "      <td>0.008331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130232</td>\n",
       "      <td>0.008459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130233</td>\n",
       "      <td>0.008109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130234</td>\n",
       "      <td>0.008401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130235</td>\n",
       "      <td>0.008105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  cancelled\n",
       "0    130231   0.008331\n",
       "1    130232   0.008459\n",
       "2    130233   0.008109\n",
       "3    130234   0.008401\n",
       "4    130235   0.008105"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\L1_Meta_Logistic.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b488d098",
   "metadata": {},
   "source": [
    "### 2. Ridge Regression, CV - 0.7664088581022975, public-lb - 0.77221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "abf829a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005801141897702422\n"
     ]
    }
   ],
   "source": [
    "diff = 0.77221 - 0.7664088581022975\n",
    "print(diff)\n",
    "score_dict.update({\"L1-Model: RidgeR\":diff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3a44328b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7936702753182069\n",
      "0 0.7936702753182069\n",
      "ROC-AUC is:  0.771033653846154\n",
      "1 0.771033653846154\n",
      "ROC-AUC is:  0.7700026135440157\n",
      "2 0.7700026135440157\n",
      "ROC-AUC is:  0.7680961219107161\n",
      "3 0.7680961219107161\n",
      "ROC-AUC is:  0.7769556398712075\n",
      "4 0.7769556398712075\n",
      "ROC-AUC is:  0.733321514670217\n",
      "5 0.733321514670217\n",
      "ROC-AUC is:  0.7559769959887181\n",
      "6 0.7559769959887181\n",
      "ROC-AUC is:  0.7475383671534889\n",
      "7 0.7475383671534889\n",
      "ROC-AUC is:  0.7576695112431494\n",
      "8 0.7576695112431494\n",
      "ROC-AUC is:  0.7984073748457847\n",
      "9 0.7984073748457847\n",
      "ROC-AUC is:  0.794484302282811\n",
      "10 0.794484302282811\n",
      "ROC-AUC is:  0.7625744287201094\n",
      "11 0.7625744287201094\n",
      "ROC-AUC is:  0.7520470320769888\n",
      "12 0.7520470320769888\n",
      "ROC-AUC is:  0.7632788968466739\n",
      "13 0.7632788968466739\n",
      "ROC-AUC is:  0.7623957705036145\n",
      "14 0.7623957705036145\n",
      "ROC-AUC is:  0.8080065068114951\n",
      "15 0.8080065068114951\n",
      "ROC-AUC is:  0.7622948122443417\n",
      "16 0.7622948122443417\n",
      "ROC-AUC is:  0.7543511545334997\n",
      "17 0.7543511545334997\n",
      "ROC-AUC is:  0.7409092342178208\n",
      "18 0.7409092342178208\n",
      "ROC-AUC is:  0.7551629554169361\n",
      "19 0.7551629554169361\n",
      "0.7664088581022975\n",
      "Wall time: 6.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_L0_preds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_L0_preds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    xtest = xtest[useful_features]\n",
    "    \n",
    "    model = Ridge(random_state=RANDOM_SEED, alpha=1.0)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"pred_2_L0\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds2_L0.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"pred_2_L0\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds2_L0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8bc668cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>cancelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130231</td>\n",
       "      <td>0.005108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130232</td>\n",
       "      <td>0.005885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130233</td>\n",
       "      <td>0.002748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130234</td>\n",
       "      <td>0.005570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130235</td>\n",
       "      <td>0.002585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  cancelled\n",
       "0    130231   0.005108\n",
       "1    130232   0.005885\n",
       "2    130233   0.002748\n",
       "3    130234   0.005570\n",
       "4    130235   0.002585"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\L1_Meta_Ridge.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5cfd6a",
   "metadata": {},
   "source": [
    "### 3. Lgbm Clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "825ba2e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.788607152739347\n",
      "0 0.788607152739347\n",
      "ROC-AUC is:  0.7586332664637521\n",
      "1 0.7586332664637521\n",
      "ROC-AUC is:  0.7641609033455603\n",
      "2 0.7641609033455603\n",
      "ROC-AUC is:  0.7608186853408435\n",
      "3 0.7608186853408435\n",
      "ROC-AUC is:  0.7711669930581722\n",
      "4 0.7711669930581722\n",
      "ROC-AUC is:  0.7384930412021683\n",
      "5 0.7384930412021683\n",
      "ROC-AUC is:  0.7641579745223391\n",
      "6 0.7641579745223391\n",
      "ROC-AUC is:  0.7472074962713496\n",
      "7 0.7472074962713496\n",
      "ROC-AUC is:  0.7388289944540147\n",
      "8 0.7388289944540147\n",
      "ROC-AUC is:  0.7954323795878939\n",
      "9 0.7954323795878939\n",
      "ROC-AUC is:  0.8068338576788318\n",
      "10 0.8068338576788318\n",
      "ROC-AUC is:  0.7539668756985027\n",
      "11 0.7539668756985027\n",
      "ROC-AUC is:  0.7463080891168548\n",
      "12 0.7463080891168548\n",
      "ROC-AUC is:  0.7557184842685152\n",
      "13 0.7557184842685152\n",
      "ROC-AUC is:  0.7587680783766877\n",
      "14 0.7587680783766877\n",
      "ROC-AUC is:  0.7882242872148769\n",
      "15 0.7882242872148769\n",
      "ROC-AUC is:  0.7620712741190746\n",
      "16 0.7620712741190746\n",
      "ROC-AUC is:  0.752261525307014\n",
      "17 0.752261525307014\n",
      "ROC-AUC is:  0.7297055378361752\n",
      "18 0.7297055378361752\n",
      "ROC-AUC is:  0.7441255128240247\n",
      "19 0.7441255128240247\n",
      "0.7612745204713\n",
      "Wall time: 24.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_L0_preds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_L0_preds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    xtest = xtest[useful_features]\n",
    "    \n",
    "    model = LGBMClassifier(random_state=RANDOM_SEED)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    test_preds = model.predict_proba(xtest)[:,1]\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"pred_3_L0\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds3_L0.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"pred_3_L0\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds3_L0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02842209",
   "metadata": {},
   "source": [
    "### 4. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e9760b53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7936605907581626\n",
      "0 0.7936605907581626\n",
      "ROC-AUC is:  0.7707944798007748\n",
      "1 0.7707944798007748\n",
      "ROC-AUC is:  0.7698918351127657\n",
      "2 0.7698918351127657\n",
      "ROC-AUC is:  0.7680856126038635\n",
      "3 0.7680856126038635\n",
      "ROC-AUC is:  0.7769835498336687\n",
      "4 0.7769835498336687\n",
      "ROC-AUC is:  0.7332677621499215\n",
      "5 0.7332677621499215\n",
      "ROC-AUC is:  0.7559320299380863\n",
      "6 0.7559320299380863\n",
      "ROC-AUC is:  0.7465522151465298\n",
      "7 0.7465522151465298\n",
      "ROC-AUC is:  0.7576097287926925\n",
      "8 0.7576097287926925\n",
      "ROC-AUC is:  0.7984625056358312\n",
      "9 0.7984625056358312\n",
      "ROC-AUC is:  0.7943988495582387\n",
      "10 0.7943988495582387\n",
      "ROC-AUC is:  0.7602851226634235\n",
      "11 0.7602851226634235\n",
      "ROC-AUC is:  0.7517074608670453\n",
      "12 0.7517074608670453\n",
      "ROC-AUC is:  0.7631846576524379\n",
      "13 0.7631846576524379\n",
      "ROC-AUC is:  0.762253119584369\n",
      "14 0.762253119584369\n",
      "ROC-AUC is:  0.807759107391161\n",
      "15 0.807759107391161\n",
      "ROC-AUC is:  0.762294467676904\n",
      "16 0.762294467676904\n",
      "ROC-AUC is:  0.7544447045928601\n",
      "17 0.7544447045928601\n",
      "ROC-AUC is:  0.7408068976887966\n",
      "18 0.7408068976887966\n",
      "ROC-AUC is:  0.7551097197477973\n",
      "19 0.7551097197477973\n",
      "0.7661742208597665\n",
      "Wall time: 7.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_L0_preds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_L0_preds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    xtest = xtest[useful_features]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"pred_4_L0\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds4_L0.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"pred_4_L0\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds4_L0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee522bfe",
   "metadata": {},
   "source": [
    "### 5. Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ebf64cfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7943706765356946\n",
      "0 0.7943706765356946\n",
      "ROC-AUC is:  0.7744718456004427\n",
      "1 0.7744718456004427\n",
      "ROC-AUC is:  0.7705768351790949\n",
      "2 0.7705768351790949\n",
      "ROC-AUC is:  0.7666558300207481\n",
      "3 0.7666558300207481\n",
      "ROC-AUC is:  0.7770776167441856\n",
      "4 0.7770776167441856\n",
      "ROC-AUC is:  0.732814828252945\n",
      "5 0.732814828252945\n",
      "ROC-AUC is:  0.7553553963309424\n",
      "6 0.7553553963309424\n",
      "ROC-AUC is:  0.7540946240760639\n",
      "7 0.7540946240760639\n",
      "ROC-AUC is:  0.7568366917460077\n",
      "8 0.7568366917460077\n",
      "ROC-AUC is:  0.7978960367681022\n",
      "9 0.7978960367681022\n",
      "ROC-AUC is:  0.7938763130388281\n",
      "10 0.7938763130388281\n",
      "ROC-AUC is:  0.7697603826352483\n",
      "11 0.7697603826352483\n",
      "ROC-AUC is:  0.7556908327316323\n",
      "12 0.7556908327316323\n",
      "ROC-AUC is:  0.7637802424686603\n",
      "13 0.7637802424686603\n",
      "ROC-AUC is:  0.7672464186091225\n",
      "14 0.7672464186091225\n",
      "ROC-AUC is:  0.814092773748923\n",
      "15 0.814092773748923\n",
      "ROC-AUC is:  0.7623359880531579\n",
      "16 0.7623359880531579\n",
      "ROC-AUC is:  0.7531250113061191\n",
      "17 0.7531250113061191\n",
      "ROC-AUC is:  0.7429826687747303\n",
      "18 0.7429826687747303\n",
      "ROC-AUC is:  0.7552260112580519\n",
      "19 0.7552260112580519\n",
      "0.767913351193935\n",
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_L0_preds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_L0_preds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    xtest = xtest[useful_features]\n",
    "    \n",
    "    model = model = Lasso(random_state=RANDOM_SEED, normalize=True, alpha=0.000001)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores))\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"pred_5_L0\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds5_L0.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"pred_5_L0\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds5_L0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ccc09",
   "metadata": {},
   "source": [
    "Getting oof preds from our L1 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b84e54c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_mile_distance</th>\n",
       "      <th>alloted_orders</th>\n",
       "      <th>last_mile_distance</th>\n",
       "      <th>delivered_orders</th>\n",
       "      <th>reassignment_reason</th>\n",
       "      <th>lifetime_order_count</th>\n",
       "      <th>reassigned_order</th>\n",
       "      <th>rider_id</th>\n",
       "      <th>reassignment_method</th>\n",
       "      <th>order_id</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_8</th>\n",
       "      <th>pred_9</th>\n",
       "      <th>pred_10</th>\n",
       "      <th>pred_11</th>\n",
       "      <th>pred_12</th>\n",
       "      <th>pred_1_L0</th>\n",
       "      <th>pred_2_L0</th>\n",
       "      <th>pred_3_L0</th>\n",
       "      <th>pred_4_L0</th>\n",
       "      <th>pred_5_L0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5666</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>621.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11696</td>\n",
       "      <td>0</td>\n",
       "      <td>556753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009546</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.004562</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.005685</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.004988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5207</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.76</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18117</td>\n",
       "      <td>0</td>\n",
       "      <td>556754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012325</td>\n",
       "      <td>0.014709</td>\n",
       "      <td>0.015499</td>\n",
       "      <td>0.020315</td>\n",
       "      <td>0.016773</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.016451</td>\n",
       "      <td>0.016990</td>\n",
       "      <td>0.016478</td>\n",
       "      <td>0.016298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.2074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18623</td>\n",
       "      <td>0</td>\n",
       "      <td>556755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021493</td>\n",
       "      <td>0.098316</td>\n",
       "      <td>0.068902</td>\n",
       "      <td>0.046981</td>\n",
       "      <td>0.075391</td>\n",
       "      <td>0.023031</td>\n",
       "      <td>0.072058</td>\n",
       "      <td>0.039929</td>\n",
       "      <td>0.071940</td>\n",
       "      <td>0.076832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.1894</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15945</td>\n",
       "      <td>0</td>\n",
       "      <td>556756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025672</td>\n",
       "      <td>0.104228</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>0.042542</td>\n",
       "      <td>0.045629</td>\n",
       "      <td>0.018851</td>\n",
       "      <td>0.063044</td>\n",
       "      <td>0.063886</td>\n",
       "      <td>0.065463</td>\n",
       "      <td>0.050825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.7870</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.01</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17589</td>\n",
       "      <td>0</td>\n",
       "      <td>556757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011861</td>\n",
       "      <td>0.021343</td>\n",
       "      <td>0.014832</td>\n",
       "      <td>0.014491</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>0.011165</td>\n",
       "      <td>0.014431</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>0.012369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_mile_distance  alloted_orders  last_mile_distance  delivered_orders  \\\n",
       "0               1.5666            46.0                2.65              46.0   \n",
       "1               2.5207             8.0                2.76               8.0   \n",
       "2               2.2074             1.0                4.80               1.0   \n",
       "3               2.1894             1.0                6.38               1.0   \n",
       "4               2.7870            34.0                4.01              34.0   \n",
       "\n",
       "   reassignment_reason  lifetime_order_count  reassigned_order  rider_id  \\\n",
       "0                    1                 621.0               0.0     11696   \n",
       "1                    1                 105.0               0.0     18117   \n",
       "2                    1                  66.0               0.0     18623   \n",
       "3                    1                 127.0               0.0     15945   \n",
       "4                    1                  84.0               0.0     17589   \n",
       "\n",
       "   reassignment_method  order_id  ...    pred_8    pred_9   pred_10   pred_11  \\\n",
       "0                    0    556753  ...  0.009546  0.005139  0.004562  0.005222   \n",
       "1                    0    556754  ...  0.012325  0.014709  0.015499  0.020315   \n",
       "2                    0    556755  ...  0.021493  0.098316  0.068902  0.046981   \n",
       "3                    0    556756  ...  0.025672  0.104228  0.046500  0.042542   \n",
       "4                    0    556757  ...  0.011861  0.021343  0.014832  0.014491   \n",
       "\n",
       "    pred_12  pred_1_L0  pred_2_L0  pred_3_L0  pred_4_L0  pred_5_L0  \n",
       "0  0.005685   0.008239   0.005294   0.002894   0.005313   0.004988  \n",
       "1  0.016773   0.009686   0.016451   0.016990   0.016478   0.016298  \n",
       "2  0.075391   0.023031   0.072058   0.039929   0.071940   0.076832  \n",
       "3  0.045629   0.018851   0.063044   0.063886   0.065463   0.050825  \n",
       "4  0.013588   0.009488   0.011165   0.014431   0.011160   0.012369  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_L0_preds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_L0_preds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "df1 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds1_L0.csv\")\n",
    "df2 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds2_L0.csv\")\n",
    "df3 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds3_L0.csv\")\n",
    "df4 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds4_L0.csv\")\n",
    "df5 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_preds5_L0.csv\")\n",
    "\n",
    "df_test1 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds1_L0.csv\")\n",
    "df_test2 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds2_L0.csv\")\n",
    "df_test3 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds3_L0.csv\")\n",
    "df_test4 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds4_L0.csv\")\n",
    "df_test5 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_preds5_L0.csv\")\n",
    "\n",
    "train = train.merge(df1, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df2, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df3, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df4, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df5, on=\"order_id\", how=\"left\")\n",
    "\n",
    "test = test.merge(df_test1, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test2, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test3, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test4, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test5, on=\"order_id\", how=\"left\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6524047f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_mile_distance</th>\n",
       "      <th>alloted_orders</th>\n",
       "      <th>last_mile_distance</th>\n",
       "      <th>delivered_orders</th>\n",
       "      <th>reassignment_reason</th>\n",
       "      <th>lifetime_order_count</th>\n",
       "      <th>reassigned_order</th>\n",
       "      <th>rider_id</th>\n",
       "      <th>reassignment_method</th>\n",
       "      <th>order_id</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_8</th>\n",
       "      <th>pred_9</th>\n",
       "      <th>pred_10</th>\n",
       "      <th>pred_11</th>\n",
       "      <th>pred_12</th>\n",
       "      <th>pred_1_L0</th>\n",
       "      <th>pred_2_L0</th>\n",
       "      <th>pred_3_L0</th>\n",
       "      <th>pred_4_L0</th>\n",
       "      <th>pred_5_L0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.6585</td>\n",
       "      <td>216.0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1</td>\n",
       "      <td>747.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12884</td>\n",
       "      <td>0</td>\n",
       "      <td>130231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>0.008331</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>0.004883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0709</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.84</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3541</td>\n",
       "      <td>0</td>\n",
       "      <td>130232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>0.006202</td>\n",
       "      <td>0.006746</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>0.006559</td>\n",
       "      <td>0.008459</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.005881</td>\n",
       "      <td>0.005879</td>\n",
       "      <td>0.005896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3884</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>289.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2214.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>603</td>\n",
       "      <td>0</td>\n",
       "      <td>130233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>0.004042</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.003977</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.002663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.9039</td>\n",
       "      <td>125.0</td>\n",
       "      <td>2.59</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3414</td>\n",
       "      <td>0</td>\n",
       "      <td>130234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009631</td>\n",
       "      <td>0.006568</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>0.006174</td>\n",
       "      <td>0.008401</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.005720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8275</td>\n",
       "      <td>352.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7284.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1426</td>\n",
       "      <td>0</td>\n",
       "      <td>130235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009631</td>\n",
       "      <td>0.004417</td>\n",
       "      <td>0.004424</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.008105</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.002690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_mile_distance  alloted_orders  last_mile_distance  delivered_orders  \\\n",
       "0               1.6585           216.0                4.54             215.0   \n",
       "1               2.0709            52.0                5.84              52.0   \n",
       "2               1.3884           289.0                0.99             289.0   \n",
       "3               1.9039           125.0                2.59             122.0   \n",
       "4               0.8275           352.0                0.94             350.0   \n",
       "\n",
       "   reassignment_reason  lifetime_order_count  reassigned_order  rider_id  \\\n",
       "0                    1                 747.0               0.0     12884   \n",
       "1                    1                  75.0               0.0      3541   \n",
       "2                    1                2214.0               0.0       603   \n",
       "3                    1                1020.0               0.0      3414   \n",
       "4                    1                7284.0               0.0      1426   \n",
       "\n",
       "   reassignment_method  order_id  ...    pred_8    pred_9   pred_10   pred_11  \\\n",
       "0                    0    130231  ...  0.009735  0.004678  0.005262  0.005261   \n",
       "1                    0    130232  ...  0.009473  0.006202  0.006746  0.006044   \n",
       "2                    0    130233  ...  0.009473  0.004042  0.003182  0.003977   \n",
       "3                    0    130234  ...  0.009631  0.006568  0.006062  0.005997   \n",
       "4                    0    130235  ...  0.009631  0.004417  0.004424  0.004393   \n",
       "\n",
       "    pred_12  pred_1_L0  pred_2_L0  pred_3_L0  pred_4_L0  pred_5_L0  \n",
       "0  0.005528   0.008331   0.005108   0.003775   0.005117   0.004883  \n",
       "1  0.006559   0.008459   0.005885   0.005881   0.005879   0.005896  \n",
       "2  0.003594   0.008109   0.002748   0.002598   0.002756   0.002663  \n",
       "3  0.006174   0.008401   0.005570   0.005400   0.005561   0.005720  \n",
       "4  0.003748   0.008105   0.002585   0.002282   0.002576   0.002690  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7fa158f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_L1_preds.csv\", index=False)\n",
    "test.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_L1_preds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e521b8",
   "metadata": {},
   "source": [
    "## *L2 model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4c0b7bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_features = ['pred_1_L0', 'pred_2_L0', 'pred_3_L0', 'pred_4_L0', 'pred_5_L0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c9cd40",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression(solver='saga'), CV - 0.7670144085293248, public-lb - 0.77147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "2362cf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004455591470675202\n"
     ]
    }
   ],
   "source": [
    "diff = 0.77147 - 0.7670144085293248\n",
    "print(diff)\n",
    "score_dict.update({\"L2-Model: LogR\":diff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "263f5cf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7925811081903708\n",
      "0 0.7925811081903708\n",
      "ROC-AUC is:  0.7724360127282789\n",
      "1 0.7724360127282789\n",
      "ROC-AUC is:  0.7687408075868236\n",
      "2 0.7687408075868236\n",
      "ROC-AUC is:  0.7689515105750331\n",
      "3 0.7689515105750331\n",
      "ROC-AUC is:  0.776048393807503\n",
      "4 0.776048393807503\n",
      "ROC-AUC is:  0.7370356070821702\n",
      "5 0.7370356070821702\n",
      "ROC-AUC is:  0.7577289491261683\n",
      "6 0.7577289491261683\n",
      "ROC-AUC is:  0.7491045984419695\n",
      "7 0.7491045984419695\n",
      "ROC-AUC is:  0.7552117117093836\n",
      "8 0.7552117117093836\n",
      "ROC-AUC is:  0.7987307513861518\n",
      "9 0.7987307513861518\n",
      "ROC-AUC is:  0.7976973936402155\n",
      "10 0.7976973936402155\n",
      "ROC-AUC is:  0.768007051228047\n",
      "11 0.768007051228047\n",
      "ROC-AUC is:  0.7514664359443103\n",
      "12 0.7514664359443103\n",
      "ROC-AUC is:  0.7630306360077451\n",
      "13 0.7630306360077451\n",
      "ROC-AUC is:  0.7636555090561798\n",
      "14 0.7636555090561798\n",
      "ROC-AUC is:  0.8081546708097456\n",
      "15 0.8081546708097456\n",
      "ROC-AUC is:  0.7630285686031185\n",
      "16 0.7630285686031185\n",
      "ROC-AUC is:  0.7533527703824991\n",
      "17 0.7533527703824991\n",
      "ROC-AUC is:  0.7403784280799031\n",
      "18 0.7403784280799031\n",
      "ROC-AUC is:  0.7549472562008787\n",
      "19 0.7549472562008787\n",
      "0.7670144085293248 0.0189523064172238\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_L1_preds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_L1_preds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    xtest = xtest[useful_features]\n",
    "    \n",
    "    model = LogisticRegression(solver=\"saga\", random_state = RANDOM_SEED)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    \n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    test_preds = model.predict_proba(xtest)[:,1]\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    \n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"oof_pred_LogR\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_oofpredLogR.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"oof_pred_LogR\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\Stack-Meta-Logistic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "663c4afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>cancelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130231</td>\n",
       "      <td>0.007901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130232</td>\n",
       "      <td>0.008048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130233</td>\n",
       "      <td>0.007559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130234</td>\n",
       "      <td>0.008006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130235</td>\n",
       "      <td>0.007542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  cancelled\n",
       "0    130231   0.007901\n",
       "1    130232   0.008048\n",
       "2    130233   0.007559\n",
       "3    130234   0.008006\n",
       "4    130235   0.007542"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\L2_Meta_Logistic.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb95f79",
   "metadata": {},
   "source": [
    "### 2. Ridge Regression, CV - 0.7665423103311333, public lb - 0.77182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "2ae1af12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005277689668866659\n"
     ]
    }
   ],
   "source": [
    "diff = 0.77182 - 0.7665423103311333\n",
    "print(diff)\n",
    "score_dict.update({\"L2-Model: RidgeR\":diff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "40cb4875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7923140910348644\n",
      "0 0.7923140910348644\n",
      "ROC-AUC is:  0.7716230285002766\n",
      "1 0.7716230285002766\n",
      "ROC-AUC is:  0.7687807774096074\n",
      "2 0.7687807774096074\n",
      "ROC-AUC is:  0.7692810893292805\n",
      "3 0.7692810893292805\n",
      "ROC-AUC is:  0.7761784680152692\n",
      "4 0.7761784680152692\n",
      "ROC-AUC is:  0.7366276392358253\n",
      "5 0.7366276392358253\n",
      "ROC-AUC is:  0.7573177078891644\n",
      "6 0.7573177078891644\n",
      "ROC-AUC is:  0.746449706333787\n",
      "7 0.746449706333787\n",
      "ROC-AUC is:  0.7557811094003338\n",
      "8 0.7557811094003338\n",
      "ROC-AUC is:  0.798470947538057\n",
      "9 0.798470947538057\n",
      "ROC-AUC is:  0.7968464843525898\n",
      "10 0.7968464843525898\n",
      "ROC-AUC is:  0.7661245070316738\n",
      "11 0.7661245070316738\n",
      "ROC-AUC is:  0.7506108749962744\n",
      "12 0.7506108749962744\n",
      "ROC-AUC is:  0.763569367196732\n",
      "13 0.763569367196732\n",
      "ROC-AUC is:  0.7631002386301791\n",
      "14 0.7631002386301791\n",
      "ROC-AUC is:  0.806238014437031\n",
      "15 0.806238014437031\n",
      "ROC-AUC is:  0.7628912584791586\n",
      "16 0.7628912584791586\n",
      "ROC-AUC is:  0.7534973164226526\n",
      "17 0.7534973164226526\n",
      "ROC-AUC is:  0.7402001144308461\n",
      "18 0.7402001144308461\n",
      "ROC-AUC is:  0.754943465959063\n",
      "19 0.754943465959063\n",
      "0.7665423103311333 0.018834821871262352\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_L1_preds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_L1_preds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    xtest = xtest[useful_features]\n",
    "    \n",
    "    model = Ridge(alpha=0.01, random_state = RANDOM_SEED)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    \n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    \n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"oof_pred_Ridge\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_oofpredRidge.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"oof_pred_Ridge\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\Stack-Meta-Ridge.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "72d3a357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>cancelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130231</td>\n",
       "      <td>0.004834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130232</td>\n",
       "      <td>0.005735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130233</td>\n",
       "      <td>0.002445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130234</td>\n",
       "      <td>0.005407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130235</td>\n",
       "      <td>0.002291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  cancelled\n",
       "0    130231   0.004834\n",
       "1    130232   0.005735\n",
       "2    130233   0.002445\n",
       "3    130234   0.005407\n",
       "4    130235   0.002291"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\L2_Meta_Ridge.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cea0078",
   "metadata": {},
   "source": [
    "### 3. Lasso Regression, CV - 0.7665840725893249, public-lb - 0.77187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "bf0188d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005285927410675018\n"
     ]
    }
   ],
   "source": [
    "diff = 0.77187 - 0.7665840725893249\n",
    "print(diff)\n",
    "score_dict.update({\"L2-Model: LassoR\":diff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6b384b52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7924448325954621\n",
      "0 0.7924448325954621\n",
      "ROC-AUC is:  0.7715414014941894\n",
      "1 0.7715414014941894\n",
      "ROC-AUC is:  0.7688527920041058\n",
      "2 0.7688527920041058\n",
      "ROC-AUC is:  0.7692664452131744\n",
      "3 0.7692664452131744\n",
      "ROC-AUC is:  0.7763367967529343\n",
      "4 0.7763367967529343\n",
      "ROC-AUC is:  0.7364736175911325\n",
      "5 0.7364736175911325\n",
      "ROC-AUC is:  0.757021207608945\n",
      "6 0.757021207608945\n",
      "ROC-AUC is:  0.7470802647449452\n",
      "7 0.7470802647449452\n",
      "ROC-AUC is:  0.7558414087019473\n",
      "8 0.7558414087019473\n",
      "ROC-AUC is:  0.7985164304398454\n",
      "9 0.7985164304398454\n",
      "ROC-AUC is:  0.7964431681666548\n",
      "10 0.7964431681666548\n",
      "ROC-AUC is:  0.7657327338549049\n",
      "11 0.7657327338549049\n",
      "ROC-AUC is:  0.7507759227989764\n",
      "12 0.7507759227989764\n",
      "ROC-AUC is:  0.7636182957728983\n",
      "13 0.7636182957728983\n",
      "ROC-AUC is:  0.7630337371146853\n",
      "14 0.7630337371146853\n",
      "ROC-AUC is:  0.8067650303331328\n",
      "15 0.8067650303331328\n",
      "ROC-AUC is:  0.7628848839815594\n",
      "16 0.7628848839815594\n",
      "ROC-AUC is:  0.7536418624628061\n",
      "17 0.7536418624628061\n",
      "ROC-AUC is:  0.7404285626421017\n",
      "18 0.7404285626421017\n",
      "ROC-AUC is:  0.7549820575120957\n",
      "19 0.7549820575120957\n",
      "0.7665840725893249 0.018831328775501293\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_L1_preds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_L1_preds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    xtest = xtest[useful_features]\n",
    "    \n",
    "    model = Lasso(random_state=RANDOM_SEED, normalize=True, alpha=0.000001)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    \n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    \n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"oof_pred_Lasso\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_oofpredLasso.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"oof_pred_Lasso\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\Stack-Meta-Lasso.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b4e9026a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>cancelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130231</td>\n",
       "      <td>0.005088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130232</td>\n",
       "      <td>0.005931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130233</td>\n",
       "      <td>0.002815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130234</td>\n",
       "      <td>0.005621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130235</td>\n",
       "      <td>0.002660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  cancelled\n",
       "0    130231   0.005088\n",
       "1    130232   0.005931\n",
       "2    130233   0.002815\n",
       "3    130234   0.005621\n",
       "4    130235   0.002660"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\L2_Meta_Lasso.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac1be80",
   "metadata": {},
   "source": [
    "### 4. HistGradient Boosting Clf, CV - 0.7673018912093903, publoc-lb - 0.76878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "b980aa18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0014781087906097223\n"
     ]
    }
   ],
   "source": [
    "diff = 0.76878 - 0.7673018912093903\n",
    "print(diff)\n",
    "score_dict.update({\"L2-Model: HistGBREG\":diff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a2d3acac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7946446977033759\n",
      "0 0.7946446977033759\n",
      "ROC-AUC is:  0.7673317307692308\n",
      "1 0.7673317307692308\n",
      "ROC-AUC is:  0.7703524356352333\n",
      "2 0.7703524356352333\n",
      "ROC-AUC is:  0.7656811348810959\n",
      "3 0.7656811348810959\n",
      "ROC-AUC is:  0.77556212301092\n",
      "4 0.77556212301092\n",
      "ROC-AUC is:  0.7387260549319746\n",
      "5 0.7387260549319746\n",
      "ROC-AUC is:  0.753637038518677\n",
      "6 0.753637038518677\n",
      "ROC-AUC is:  0.7530113901935074\n",
      "7 0.7530113901935074\n",
      "ROC-AUC is:  0.7568929423802271\n",
      "8 0.7568929423802271\n",
      "ROC-AUC is:  0.7984193485642477\n",
      "9 0.7984193485642477\n",
      "ROC-AUC is:  0.7992399359173479\n",
      "10 0.7992399359173479\n",
      "ROC-AUC is:  0.7717162335540116\n",
      "11 0.7717162335540116\n",
      "ROC-AUC is:  0.7485029836955857\n",
      "12 0.7485029836955857\n",
      "ROC-AUC is:  0.7632994847510819\n",
      "13 0.7632994847510819\n",
      "ROC-AUC is:  0.7687445116867798\n",
      "14 0.7687445116867798\n",
      "ROC-AUC is:  0.8105484669419416\n",
      "15 0.8105484669419416\n",
      "ROC-AUC is:  0.7645599124385226\n",
      "16 0.7645599124385226\n",
      "ROC-AUC is:  0.7565352813797995\n",
      "17 0.7565352813797995\n",
      "ROC-AUC is:  0.7370574009726105\n",
      "18 0.7370574009726105\n",
      "ROC-AUC is:  0.7515747162616363\n",
      "19 0.7515747162616363\n",
      "0.7673018912093903 0.019594340747314358\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_L1_preds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_L1_preds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    xtest = xtest[useful_features]\n",
    "    \n",
    "    model = HistGradientBoostingRegressor(random_state=RANDOM_SEED,max_bins=255, max_iter=10000)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    \n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    \n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"oof_pred_HistGrReg\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_oofpredHistGrReg.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"oof_pred_HistGrReg\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\Stack-Meta-HistGrReg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0646f06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>cancelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130231</td>\n",
       "      <td>0.004797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130232</td>\n",
       "      <td>0.006382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130233</td>\n",
       "      <td>0.004282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130234</td>\n",
       "      <td>0.006529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130235</td>\n",
       "      <td>0.004287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  cancelled\n",
       "0    130231   0.004797\n",
       "1    130232   0.006382\n",
       "2    130233   0.004282\n",
       "3    130234   0.006529\n",
       "4    130235   0.004287"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\L2_Meta_HistGrbReg.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf9b4a3",
   "metadata": {},
   "source": [
    "### 5. Linear Regression, CV - 0.7664936721034142 , public-lb - 0.77190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "7a3953da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005406327896585794\n"
     ]
    }
   ],
   "source": [
    "diff = 0.77190 - 0.7664936721034142\n",
    "print(diff)\n",
    "score_dict.update({\"L2-Model: LinearREG\":diff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d3f52ccf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7920180201992252\n",
      "0 0.7920180201992252\n",
      "ROC-AUC is:  0.7715872302158273\n",
      "1 0.7715872302158273\n",
      "ROC-AUC is:  0.768878806845659\n",
      "2 0.768878806845659\n",
      "ROC-AUC is:  0.7693403549285804\n",
      "3 0.7693403549285804\n",
      "ROC-AUC is:  0.7759148739253586\n",
      "4 0.7759148739253586\n",
      "ROC-AUC is:  0.7366324631799542\n",
      "5 0.7366324631799542\n",
      "ROC-AUC is:  0.7575592496630562\n",
      "6 0.7575592496630562\n",
      "ROC-AUC is:  0.7466879747170195\n",
      "7 0.7466879747170195\n",
      "ROC-AUC is:  0.7560936320664104\n",
      "8 0.7560936320664104\n",
      "ROC-AUC is:  0.7982502520941517\n",
      "9 0.7982502520941517\n",
      "ROC-AUC is:  0.7969998168624068\n",
      "10 0.7969998168624068\n",
      "ROC-AUC is:  0.7667674698705925\n",
      "11 0.7667674698705925\n",
      "ROC-AUC is:  0.7507035636370403\n",
      "12 0.7507035636370403\n",
      "ROC-AUC is:  0.7638581147096013\n",
      "13 0.7638581147096013\n",
      "ROC-AUC is:  0.763022710956676\n",
      "14 0.763022710956676\n",
      "ROC-AUC is:  0.8049057444388108\n",
      "15 0.8049057444388108\n",
      "ROC-AUC is:  0.7627229372857975\n",
      "16 0.7627229372857975\n",
      "ROC-AUC is:  0.7532609431603278\n",
      "17 0.7532609431603278\n",
      "ROC-AUC is:  0.7398531350209901\n",
      "18 0.7398531350209901\n",
      "ROC-AUC is:  0.754816148290799\n",
      "19 0.754816148290799\n",
      "0.7664936721034142 0.018668590573905564\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_L1_preds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_L1_preds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "\n",
    "for fold in range(20):\n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.order_id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    xtest = xtest[useful_features]\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(xtrain, ytrain)\n",
    "    \n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    \n",
    "    scores.append(roc)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient=\"index\").reset_index()\n",
    "final_valid_predictions.columns = [\"order_id\", \"oof_pred_LinearReg\"]\n",
    "final_valid_predictions.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_oofpredLinearReg.csv\", index=False)\n",
    "\n",
    "sample_submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = [\"order_id\", \"oof_pred_LinearReg\"]\n",
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\Stack-Meta-LinearReg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5426a8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>cancelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130231</td>\n",
       "      <td>0.004845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130232</td>\n",
       "      <td>0.005751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130233</td>\n",
       "      <td>0.002427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130234</td>\n",
       "      <td>0.005410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130235</td>\n",
       "      <td>0.002296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  cancelled\n",
       "0    130231   0.004845\n",
       "1    130232   0.005751\n",
       "2    130233   0.002427\n",
       "3    130234   0.005410\n",
       "4    130235   0.002296"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.cancelled = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\L2_Meta_LinearReg.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daee441",
   "metadata": {},
   "source": [
    "## *Blend of all oofpreds from L2 Meta models*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8186d30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_mile_distance</th>\n",
       "      <th>alloted_orders</th>\n",
       "      <th>last_mile_distance</th>\n",
       "      <th>delivered_orders</th>\n",
       "      <th>reassignment_reason</th>\n",
       "      <th>lifetime_order_count</th>\n",
       "      <th>reassigned_order</th>\n",
       "      <th>rider_id</th>\n",
       "      <th>reassignment_method</th>\n",
       "      <th>order_id</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_1_L0</th>\n",
       "      <th>pred_2_L0</th>\n",
       "      <th>pred_3_L0</th>\n",
       "      <th>pred_4_L0</th>\n",
       "      <th>pred_5_L0</th>\n",
       "      <th>oof_pred_LogR</th>\n",
       "      <th>oof_pred_Ridge</th>\n",
       "      <th>oof_pred_Lasso</th>\n",
       "      <th>oof_pred_HistGrReg</th>\n",
       "      <th>oof_pred_LinearReg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5666</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>621.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11696</td>\n",
       "      <td>0</td>\n",
       "      <td>556753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008239</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.007928</td>\n",
       "      <td>0.004960</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.004953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5207</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.76</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18117</td>\n",
       "      <td>0</td>\n",
       "      <td>556754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.016451</td>\n",
       "      <td>0.016990</td>\n",
       "      <td>0.016478</td>\n",
       "      <td>0.016298</td>\n",
       "      <td>0.009886</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>0.016401</td>\n",
       "      <td>0.015522</td>\n",
       "      <td>0.016806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.2074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18623</td>\n",
       "      <td>0</td>\n",
       "      <td>556755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023031</td>\n",
       "      <td>0.072058</td>\n",
       "      <td>0.039929</td>\n",
       "      <td>0.071940</td>\n",
       "      <td>0.076832</td>\n",
       "      <td>0.027269</td>\n",
       "      <td>0.072352</td>\n",
       "      <td>0.069943</td>\n",
       "      <td>0.012691</td>\n",
       "      <td>0.071991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.1894</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15945</td>\n",
       "      <td>0</td>\n",
       "      <td>556756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018851</td>\n",
       "      <td>0.063044</td>\n",
       "      <td>0.063886</td>\n",
       "      <td>0.065463</td>\n",
       "      <td>0.050825</td>\n",
       "      <td>0.022261</td>\n",
       "      <td>0.066671</td>\n",
       "      <td>0.062545</td>\n",
       "      <td>0.046970</td>\n",
       "      <td>0.065904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.7870</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.01</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17589</td>\n",
       "      <td>0</td>\n",
       "      <td>556757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>0.011165</td>\n",
       "      <td>0.014431</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>0.012369</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>0.011436</td>\n",
       "      <td>0.011386</td>\n",
       "      <td>0.013012</td>\n",
       "      <td>0.011253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_mile_distance  alloted_orders  last_mile_distance  delivered_orders  \\\n",
       "0               1.5666            46.0                2.65              46.0   \n",
       "1               2.5207             8.0                2.76               8.0   \n",
       "2               2.2074             1.0                4.80               1.0   \n",
       "3               2.1894             1.0                6.38               1.0   \n",
       "4               2.7870            34.0                4.01              34.0   \n",
       "\n",
       "   reassignment_reason  lifetime_order_count  reassigned_order  rider_id  \\\n",
       "0                    1                 621.0               0.0     11696   \n",
       "1                    1                 105.0               0.0     18117   \n",
       "2                    1                  66.0               0.0     18623   \n",
       "3                    1                 127.0               0.0     15945   \n",
       "4                    1                  84.0               0.0     17589   \n",
       "\n",
       "   reassignment_method  order_id  ...  pred_1_L0  pred_2_L0  pred_3_L0  \\\n",
       "0                    0    556753  ...   0.008239   0.005294   0.002894   \n",
       "1                    0    556754  ...   0.009686   0.016451   0.016990   \n",
       "2                    0    556755  ...   0.023031   0.072058   0.039929   \n",
       "3                    0    556756  ...   0.018851   0.063044   0.063886   \n",
       "4                    0    556757  ...   0.009488   0.011165   0.014431   \n",
       "\n",
       "   pred_4_L0  pred_5_L0  oof_pred_LogR  oof_pred_Ridge  oof_pred_Lasso  \\\n",
       "0   0.005313   0.004988       0.007928        0.004960        0.005217   \n",
       "1   0.016478   0.016298       0.009886        0.016812        0.016401   \n",
       "2   0.071940   0.076832       0.027269        0.072352        0.069943   \n",
       "3   0.065463   0.050825       0.022261        0.066671        0.062545   \n",
       "4   0.011160   0.012369       0.009035        0.011436        0.011386   \n",
       "\n",
       "   oof_pred_HistGrReg  oof_pred_LinearReg  \n",
       "0            0.004920            0.004953  \n",
       "1            0.015522            0.016806  \n",
       "2            0.012691            0.071991  \n",
       "3            0.046970            0.065904  \n",
       "4            0.013012            0.011253  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_L1_preds.csv\")\n",
    "test = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_L1_preds.csv\")\n",
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")\n",
    "\n",
    "df1 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_oofpredLogR.csv\")\n",
    "df2 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_oofpredRidge.csv\")\n",
    "df3 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_oofpredLasso.csv\")\n",
    "df4 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_oofpredHistGrReg.csv\")\n",
    "df5 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_oofpredLinearReg.csv\")\n",
    "\n",
    "df_test1 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\Stack-Meta-Logistic.csv\")\n",
    "df_test2 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\Stack-Meta-Ridge.csv\")\n",
    "df_test3 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\Stack-Meta-Lasso.csv\")\n",
    "df_test4 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\Stack-Meta-HistGrReg.csv\")\n",
    "df_test5 = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\Stack-Meta-LinearReg.csv\")\n",
    "\n",
    "train = train.merge(df1, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df2, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df3, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df4, on=\"order_id\", how=\"left\")\n",
    "train = train.merge(df5, on=\"order_id\", how=\"left\")\n",
    "\n",
    "test = test.merge(df_test1, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test2, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test3, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test4, on=\"order_id\", how=\"left\")\n",
    "test = test.merge(df_test5, on=\"order_id\", how=\"left\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "12f1aad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_mile_distance</th>\n",
       "      <th>alloted_orders</th>\n",
       "      <th>last_mile_distance</th>\n",
       "      <th>delivered_orders</th>\n",
       "      <th>reassignment_reason</th>\n",
       "      <th>lifetime_order_count</th>\n",
       "      <th>reassigned_order</th>\n",
       "      <th>rider_id</th>\n",
       "      <th>reassignment_method</th>\n",
       "      <th>order_id</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_1_L0</th>\n",
       "      <th>pred_2_L0</th>\n",
       "      <th>pred_3_L0</th>\n",
       "      <th>pred_4_L0</th>\n",
       "      <th>pred_5_L0</th>\n",
       "      <th>oof_pred_LogR</th>\n",
       "      <th>oof_pred_Ridge</th>\n",
       "      <th>oof_pred_Lasso</th>\n",
       "      <th>oof_pred_HistGrReg</th>\n",
       "      <th>oof_pred_LinearReg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.6585</td>\n",
       "      <td>216.0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1</td>\n",
       "      <td>747.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12884</td>\n",
       "      <td>0</td>\n",
       "      <td>130231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008331</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.007901</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.004797</td>\n",
       "      <td>0.004845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0709</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.84</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3541</td>\n",
       "      <td>0</td>\n",
       "      <td>130232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008459</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.005881</td>\n",
       "      <td>0.005879</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.005931</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.005751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.3884</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>289.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2214.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>603</td>\n",
       "      <td>0</td>\n",
       "      <td>130233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>0.007559</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>0.002427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.9039</td>\n",
       "      <td>125.0</td>\n",
       "      <td>2.59</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3414</td>\n",
       "      <td>0</td>\n",
       "      <td>130234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008401</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.005561</td>\n",
       "      <td>0.005720</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>0.005407</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>0.006529</td>\n",
       "      <td>0.005410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.8275</td>\n",
       "      <td>352.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7284.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1426</td>\n",
       "      <td>0</td>\n",
       "      <td>130235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008105</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.002282</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.004287</td>\n",
       "      <td>0.002296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   first_mile_distance  alloted_orders  last_mile_distance  delivered_orders  \\\n",
       "0               1.6585           216.0                4.54             215.0   \n",
       "1               2.0709            52.0                5.84              52.0   \n",
       "2               1.3884           289.0                0.99             289.0   \n",
       "3               1.9039           125.0                2.59             122.0   \n",
       "4               0.8275           352.0                0.94             350.0   \n",
       "\n",
       "   reassignment_reason  lifetime_order_count  reassigned_order  rider_id  \\\n",
       "0                    1                 747.0               0.0     12884   \n",
       "1                    1                  75.0               0.0      3541   \n",
       "2                    1                2214.0               0.0       603   \n",
       "3                    1                1020.0               0.0      3414   \n",
       "4                    1                7284.0               0.0      1426   \n",
       "\n",
       "   reassignment_method  order_id  ...  pred_1_L0  pred_2_L0  pred_3_L0  \\\n",
       "0                    0    130231  ...   0.008331   0.005108   0.003775   \n",
       "1                    0    130232  ...   0.008459   0.005885   0.005881   \n",
       "2                    0    130233  ...   0.008109   0.002748   0.002598   \n",
       "3                    0    130234  ...   0.008401   0.005570   0.005400   \n",
       "4                    0    130235  ...   0.008105   0.002585   0.002282   \n",
       "\n",
       "   pred_4_L0  pred_5_L0  oof_pred_LogR  oof_pred_Ridge  oof_pred_Lasso  \\\n",
       "0   0.005117   0.004883       0.007901        0.004834        0.005088   \n",
       "1   0.005879   0.005896       0.008048        0.005735        0.005931   \n",
       "2   0.002756   0.002663       0.007559        0.002445        0.002815   \n",
       "3   0.005561   0.005720       0.008006        0.005407        0.005621   \n",
       "4   0.002576   0.002690       0.007542        0.002291        0.002660   \n",
       "\n",
       "   oof_pred_HistGrReg  oof_pred_LinearReg  \n",
       "0            0.004797            0.004845  \n",
       "1            0.006382            0.005751  \n",
       "2            0.004282            0.002427  \n",
       "3            0.006529            0.005410  \n",
       "4            0.004287            0.002296  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e97351ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\train_ALL_PREDS.csv\", index=False)\n",
    "test.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\test_ALL_PREDS.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4c7b1e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['first_mile_distance', 'alloted_orders', 'last_mile_distance',\n",
       "       'delivered_orders', 'reassignment_reason', 'lifetime_order_count',\n",
       "       'reassigned_order', 'rider_id', 'reassignment_method', 'order_id',\n",
       "       'undelivered_orders', 'session_time', 'cancelled', 'Accept_time_f1',\n",
       "       'order_day_of_week', 'order_time_hour', 'diff_allot_and_order',\n",
       "       'diff_accept_and_allot', 'diff_accept_and_order', 'kfold', 'pred_1',\n",
       "       'pred_2', 'pred_3', 'pred_4', 'pred_5', 'pred_6', 'pred_7', 'pred_8',\n",
       "       'pred_9', 'pred_10', 'pred_11', 'pred_12', 'pred_1_L0', 'pred_2_L0',\n",
       "       'pred_3_L0', 'pred_4_L0', 'pred_5_L0', 'oof_pred_LogR',\n",
       "       'oof_pred_Ridge', 'oof_pred_Lasso', 'oof_pred_HistGrReg',\n",
       "       'oof_pred_LinearReg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8ce1f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train oof meta - preds\n",
    "tr_l2_log = train.oof_pred_LogR\n",
    "tr_l2_rr = train.oof_pred_Ridge\n",
    "tr_l2_lassor = train.oof_pred_Lasso\n",
    "tr_l2_HistReg = train.oof_pred_HistGrReg\n",
    "tr_l2_LR = train.oof_pred_LinearReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d506699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test oof meta-preds\n",
    "te_l2_log = test.oof_pred_LogR\n",
    "te_l2_rr = test.oof_pred_Ridge\n",
    "te_l2_lassor = test.oof_pred_Lasso\n",
    "te_l2_HistReg = test.oof_pred_HistGrReg\n",
    "te_l2_LR = test.oof_pred_LinearReg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186c94e7",
   "metadata": {},
   "source": [
    "### *Averaging L2 Meta*, oof-score - 0.7664323750634199 , public lb - 0.77155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "2c6ec96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0051176249365800786\n"
     ]
    }
   ],
   "source": [
    "diff = 0.77155 - 0.7664323750634199\n",
    "print(diff)\n",
    "score_dict.update({\"Average L2\":diff})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1e601eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.cancelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "600cd3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score: 0.7664323750634199\n"
     ]
    }
   ],
   "source": [
    "#Checking OOF score\n",
    "oof_avg = (tr_l2_log + tr_l2_rr + tr_l2_lassor + tr_l2_HistReg + tr_l2_LR)/5\n",
    "print('OOF score: {}'.format(roc_auc_score(y_train.values, oof_avg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "40b9c1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>cancelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130231</td>\n",
       "      <td>0.005493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130232</td>\n",
       "      <td>0.006369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130233</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130234</td>\n",
       "      <td>0.006195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130235</td>\n",
       "      <td>0.003815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  cancelled\n",
       "0    130231   0.005493\n",
       "1    130232   0.006369\n",
       "2    130233   0.003906\n",
       "3    130234   0.006195\n",
       "4    130235   0.003815"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_avg = (te_l2_log + te_l2_rr + te_l2_lassor + te_l2_HistReg + te_l2_LR)/5\n",
    "sample_submission.cancelled = sub_avg\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "25a253a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>cancelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130231</td>\n",
       "      <td>0.005493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130232</td>\n",
       "      <td>0.006369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130233</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130234</td>\n",
       "      <td>0.006195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130235</td>\n",
       "      <td>0.003815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  cancelled\n",
       "0    130231   0.005493\n",
       "1    130232   0.006369\n",
       "2    130233   0.003906\n",
       "3    130234   0.006195\n",
       "4    130235   0.003815"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\FINAL_SUBMISSION2.csv\", index=False)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd7de58",
   "metadata": {},
   "source": [
    "### *Weighted Blending L2 Meta*, OOF score - 0.7666002003119106 , public-lb = 0.77119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "b1833f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00458979968808948\n"
     ]
    }
   ],
   "source": [
    "diff = 0.77119- 0.7666002003119106\n",
    "print(diff)\n",
    "score_dict.update({\"Average Meta Blend\":diff})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b1276e",
   "metadata": {},
   "source": [
    "###### *Optuna for Weights*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "28a28595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(trial):\n",
    "    \n",
    "    samples = [0.2]*5\n",
    "\n",
    "    samples[0]=trial.suggest_uniform('w0', 0, 1)\n",
    "    samples[1]=trial.suggest_uniform('w1', 0, 1)\n",
    "    samples[2]=trial.suggest_uniform('w2', 0, 1)\n",
    "    samples[3]=trial.suggest_uniform('w3', 0, 1)\n",
    "    samples[4]=trial.suggest_uniform('w4', 0, 1)\n",
    "    \n",
    "    w = [samples[i]/sum(samples) for i in range(len(samples))]\n",
    "    \n",
    "    oof_preds = (w[0] * tr_l2_log + w[1] * tr_l2_rr + w[2] * tr_l2_lassor + w[3] * tr_l2_HistReg + w[4] * tr_l2_LR)\n",
    "    roc = roc_auc_score(y_train.values, oof_preds)\n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5779ce49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:17:39,834]\u001b[0m A new study created in memory with name: no-name-f1c6ed3a-283e-475c-9854-407cfdf921fb\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:39,965]\u001b[0m Trial 0 finished with value: 0.7664430925846355 and parameters: {'w0': 0.040116027813093424, 'w1': 0.9370626596975528, 'w2': 0.08930920618465532, 'w3': 0.7939339864116544, 'w4': 0.3389560229664027}. Best is trial 0 with value: 0.7664430925846355.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:40,094]\u001b[0m Trial 1 finished with value: 0.766445352079741 and parameters: {'w0': 0.06651317418997182, 'w1': 0.969649516280526, 'w2': 0.8495635600796606, 'w3': 0.8764000060252303, 'w4': 0.4154568117222365}. Best is trial 1 with value: 0.766445352079741.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:40,228]\u001b[0m Trial 2 finished with value: 0.7664188482538582 and parameters: {'w0': 0.0409241624711042, 'w1': 0.9532959283075831, 'w2': 0.37119197311151597, 'w3': 0.6855817054382176, 'w4': 0.5922169048405301}. Best is trial 1 with value: 0.766445352079741.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:40,356]\u001b[0m Trial 3 finished with value: 0.7662891642651374 and parameters: {'w0': 0.9535183821850648, 'w1': 0.2441078357313916, 'w2': 0.6271748947261199, 'w3': 0.15216420123687258, 'w4': 0.8963838184937158}. Best is trial 1 with value: 0.766445352079741.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:40,485]\u001b[0m Trial 4 finished with value: 0.7663998709078577 and parameters: {'w0': 0.22674371314973252, 'w1': 0.9741267276452176, 'w2': 0.30681707593576113, 'w3': 0.6435511876576567, 'w4': 0.858010884899348}. Best is trial 1 with value: 0.766445352079741.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:40,615]\u001b[0m Trial 5 finished with value: 0.7663186100880797 and parameters: {'w0': 0.6315586672019905, 'w1': 0.1256316016388307, 'w2': 0.8122694367337622, 'w3': 0.21969981247659276, 'w4': 0.9761389228670797}. Best is trial 1 with value: 0.766445352079741.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:40,742]\u001b[0m Trial 6 finished with value: 0.76642600116733 and parameters: {'w0': 0.35381968072943837, 'w1': 0.403685274558896, 'w2': 0.07732302835365523, 'w3': 0.6979214011411767, 'w4': 0.01940266765387655}. Best is trial 1 with value: 0.766445352079741.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:40,866]\u001b[0m Trial 7 finished with value: 0.7664334651707077 and parameters: {'w0': 0.4620040566516884, 'w1': 0.5141166154387595, 'w2': 0.725153877329881, 'w3': 0.5860059661046251, 'w4': 0.5724719555114032}. Best is trial 1 with value: 0.766445352079741.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:40,998]\u001b[0m Trial 8 finished with value: 0.7664898362127847 and parameters: {'w0': 0.2691891603074208, 'w1': 0.052425760205221494, 'w2': 0.6432513065391997, 'w3': 0.6587023103248614, 'w4': 0.35977571435047817}. Best is trial 8 with value: 0.7664898362127847.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:41,124]\u001b[0m Trial 9 finished with value: 0.7664359142496893 and parameters: {'w0': 0.5404742674550007, 'w1': 0.037420268180588856, 'w2': 0.8835733687286922, 'w3': 0.560934867918297, 'w4': 0.8315899282528466}. Best is trial 8 with value: 0.7664898362127847.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:41,259]\u001b[0m Trial 10 finished with value: 0.7664093164936133 and parameters: {'w0': 0.8103343992872847, 'w1': 0.6256643441138494, 'w2': 0.9971097701711025, 'w3': 0.36066467274468056, 'w4': 0.20109801247865783}. Best is trial 8 with value: 0.7664898362127847.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:41,394]\u001b[0m Trial 11 finished with value: 0.7664676936777977 and parameters: {'w0': 0.23043443102917174, 'w1': 0.7212936632816129, 'w2': 0.5632612205954027, 'w3': 0.9763155095286964, 'w4': 0.40099946528492236}. Best is trial 8 with value: 0.7664898362127847.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:41,532]\u001b[0m Trial 12 finished with value: 0.7664720463512447 and parameters: {'w0': 0.2517203892640405, 'w1': 0.7101498476498743, 'w2': 0.5859711621750712, 'w3': 0.9901765004382558, 'w4': 0.25020698560644095}. Best is trial 8 with value: 0.7664898362127847.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:41,681]\u001b[0m Trial 13 finished with value: 0.7664672796093773 and parameters: {'w0': 0.25070102290518664, 'w1': 0.7688370184307821, 'w2': 0.4310513125886757, 'w3': 0.9925915807336013, 'w4': 0.21385915167623237}. Best is trial 8 with value: 0.7664898362127847.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:41,837]\u001b[0m Trial 14 finished with value: 0.7664790126969476 and parameters: {'w0': 0.3677570515682713, 'w1': 0.33790835412317227, 'w2': 0.641038966376483, 'w3': 0.43001209938691654, 'w4': 0.023330177217984638}. Best is trial 8 with value: 0.7664898362127847.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:41,979]\u001b[0m Trial 15 finished with value: 0.7664878632478556 and parameters: {'w0': 0.44242018699386076, 'w1': 0.30141809036058476, 'w2': 0.24952637544202416, 'w3': 0.41515242474896474, 'w4': 0.01869783852360401}. Best is trial 8 with value: 0.7664898362127847.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:42,116]\u001b[0m Trial 16 finished with value: 0.7661857096365514 and parameters: {'w0': 0.6075710485045196, 'w1': 0.18182739369572365, 'w2': 0.24886921314493055, 'w3': 0.019586075750989362, 'w4': 0.6511469483183241}. Best is trial 8 with value: 0.7664898362127847.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:42,260]\u001b[0m Trial 17 finished with value: 0.7665092758849195 and parameters: {'w0': 0.7378476945922798, 'w1': 0.004622921279755832, 'w2': 0.18677753379554776, 'w3': 0.340997144713695, 'w4': 0.09359675852618476}. Best is trial 17 with value: 0.7665092758849195.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:42,404]\u001b[0m Trial 18 finished with value: 0.7665105865988995 and parameters: {'w0': 0.7821581323536337, 'w1': 0.001835657733146645, 'w2': 0.4604383659415877, 'w3': 0.31900688223875273, 'w4': 0.15519169779983769}. Best is trial 18 with value: 0.7665105865988995.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:42,542]\u001b[0m Trial 19 finished with value: 0.7665041355766418 and parameters: {'w0': 0.7726937792716256, 'w1': 0.12832425598972197, 'w2': 0.1736947951132851, 'w3': 0.2791458257382402, 'w4': 0.15069959868959007}. Best is trial 18 with value: 0.7665105865988995.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:42,683]\u001b[0m Trial 20 finished with value: 0.7665091660124458 and parameters: {'w0': 0.7779865468539878, 'w1': 0.01732014832272412, 'w2': 0.011030664887704433, 'w3': 0.08955036170385977, 'w4': 0.13187197520872374}. Best is trial 18 with value: 0.7665105865988995.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:42,817]\u001b[0m Trial 21 finished with value: 0.7664029089894726 and parameters: {'w0': 0.7796476927729028, 'w1': 0.022816469079600082, 'w2': 0.010737058100138419, 'w3': 0.018984626775165936, 'w4': 0.11453995777554347}. Best is trial 18 with value: 0.7665105865988995.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:42,953]\u001b[0m Trial 22 finished with value: 0.7665275702980934 and parameters: {'w0': 0.9310061620033152, 'w1': 0.007418279139692993, 'w2': 0.15424258299244742, 'w3': 0.1661051387194768, 'w4': 0.10446604615089887}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:43,087]\u001b[0m Trial 23 finished with value: 0.7664587556597832 and parameters: {'w0': 0.9867737248950056, 'w1': 0.15726657439202635, 'w2': 0.45452470457454996, 'w3': 0.28638838773808933, 'w4': 0.2957051062384623}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:43,224]\u001b[0m Trial 24 finished with value: 0.7664858864050745 and parameters: {'w0': 0.890026633546037, 'w1': 0.23298498248545657, 'w2': 0.16076306442350316, 'w3': 0.21590008371451955, 'w4': 0.08466017836864936}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:43,362]\u001b[0m Trial 25 finished with value: 0.7664501890538169 and parameters: {'w0': 0.6737105295800693, 'w1': 0.10568052266055478, 'w2': 0.3548488614445992, 'w3': 0.3450771587501354, 'w4': 0.4593455978101562}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:43,499]\u001b[0m Trial 26 finished with value: 0.7664874939901696 and parameters: {'w0': 0.8797737029379878, 'w1': 0.3862880140229377, 'w2': 0.16572310301409743, 'w3': 0.4813547107610929, 'w4': 0.18505281630528442}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:43,641]\u001b[0m Trial 27 finished with value: 0.766397208116143 and parameters: {'w0': 0.8756910280742516, 'w1': 0.23847811437825628, 'w2': 0.2459244320339644, 'w3': 0.140600553170306, 'w4': 0.2758805136985635}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:43,778]\u001b[0m Trial 28 finished with value: 0.7665029812693595 and parameters: {'w0': 0.6966510185756358, 'w1': 0.08486333900177134, 'w2': 0.4743350101988947, 'w3': 0.3064265378061404, 'w4': 0.08124545930769489}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:17:43,919]\u001b[0m Trial 29 finished with value: 0.766478361648682 and parameters: {'w0': 0.7169006997975865, 'w1': 0.005815477275489234, 'w2': 0.09381760159093733, 'w3': 0.23126350337594553, 'w4': 0.3181849323342568}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:44,067]\u001b[0m Trial 30 finished with value: 0.7664682732012371 and parameters: {'w0': 0.5527296682996293, 'w1': 0.4964592901054661, 'w2': 0.38523686358197556, 'w3': 0.4128174921089028, 'w4': 0.07141861913520564}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:44,215]\u001b[0m Trial 31 finished with value: 0.7665041196343613 and parameters: {'w0': 0.8252497415281165, 'w1': 0.006607678750772918, 'w2': 0.04577097663427409, 'w3': 0.09555546800238328, 'w4': 0.14625927276792178}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:44,362]\u001b[0m Trial 32 finished with value: 0.7664289603992874 and parameters: {'w0': 0.929875941684394, 'w1': 0.08345256529596617, 'w2': 0.09167635025440461, 'w3': 0.09265641980179345, 'w4': 0.23306636967677097}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:44,501]\u001b[0m Trial 33 finished with value: 0.7664634961184313 and parameters: {'w0': 0.7541063534154471, 'w1': 0.17482983499133997, 'w2': 0.16107940887375563, 'w3': 0.1682483070385301, 'w4': 0.15211634486606035}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:44,643]\u001b[0m Trial 34 finished with value: 0.766433747823032 and parameters: {'w0': 0.8392216194245009, 'w1': 0.07883156332662555, 'w2': 0.3024667205536046, 'w3': 0.08091275282520231, 'w4': 0.06920347876661434}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:44,777]\u001b[0m Trial 35 finished with value: 0.7663489542800712 and parameters: {'w0': 0.9915775340222024, 'w1': 0.8587024666238453, 'w2': 0.014100014136320949, 'w3': 0.1919997204292176, 'w4': 0.3608679696539287}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:44,915]\u001b[0m Trial 36 finished with value: 0.7665017093338996 and parameters: {'w0': 0.9407385371853768, 'w1': 0.20615462757775344, 'w2': 0.11869731775161937, 'w3': 0.37364976054122406, 'w4': 0.12812429237471912}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:45,053]\u001b[0m Trial 37 finished with value: 0.7664395783889679 and parameters: {'w0': 0.654899481340477, 'w1': 0.000895500659497965, 'w2': 0.20878129739063717, 'w3': 0.25639982509512615, 'w4': 0.513233948683911}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:45,190]\u001b[0m Trial 38 finished with value: 0.7664968060054671 and parameters: {'w0': 0.724902757213772, 'w1': 0.2970172677814015, 'w2': 0.315745030373202, 'w3': 0.4844578276370801, 'w4': 0.0025135835511158056}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:45,329]\u001b[0m Trial 39 finished with value: 0.7662925401507497 and parameters: {'w0': 0.5784999388566776, 'w1': 0.1321467843276809, 'w2': 0.5358957994217711, 'w3': 0.12723776228336875, 'w4': 0.724083937806968}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:45,469]\u001b[0m Trial 40 finished with value: 0.7662393519634295 and parameters: {'w0': 0.9056641250739085, 'w1': 0.060799260638221345, 'w2': 0.7023648630632422, 'w3': 0.0015060414459308613, 'w4': 0.18714135517952246}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:45,610]\u001b[0m Trial 41 finished with value: 0.7665058125322004 and parameters: {'w0': 0.7891991015289755, 'w1': 0.14246870393222927, 'w2': 0.13753712962668707, 'w3': 0.29417537008547223, 'w4': 0.14647584646996206}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:45,748]\u001b[0m Trial 42 finished with value: 0.7664941255479822 and parameters: {'w0': 0.8280129672424603, 'w1': 0.05844786823355922, 'w2': 0.05113808688767202, 'w3': 0.30851033409355255, 'w4': 0.05199745990918152}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:45,883]\u001b[0m Trial 43 finished with value: 0.7663896566456588 and parameters: {'w0': 0.15239999177968205, 'w1': 0.12659570036724038, 'w2': 0.11460858520100571, 'w3': 0.794349294157346, 'w4': 0.1164520657844997}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:46,022]\u001b[0m Trial 44 finished with value: 0.7664632341479843 and parameters: {'w0': 0.756228333414948, 'w1': 0.05343383063556861, 'w2': 0.22094107522622905, 'w3': 0.18145338067294556, 'w4': 0.25086085966677185}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:46,169]\u001b[0m Trial 45 finished with value: 0.7664831072777993 and parameters: {'w0': 0.8426532220384344, 'w1': 0.10414560074374005, 'w2': 0.12880279643365528, 'w3': 0.5379767404213893, 'w4': 0.1745064916930077}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:46,316]\u001b[0m Trial 46 finished with value: 0.7664749379362281 and parameters: {'w0': 0.4975005969170598, 'w1': 0.00010611157855760361, 'w2': 0.04693214063181133, 'w3': 0.32773720211244, 'w4': 0.3403543850377273}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:46,462]\u001b[0m Trial 47 finished with value: 0.7664742506946771 and parameters: {'w0': 0.6281951645135802, 'w1': 0.1596920357384926, 'w2': 0.3999903130775637, 'w3': 0.24651426759627604, 'w4': 0.11582628850429169}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:46,603]\u001b[0m Trial 48 finished with value: 0.7662780981681132 and parameters: {'w0': 0.7886139243848396, 'w1': 0.5407806656943644, 'w2': 0.30367505851764753, 'w3': 0.06603161345087309, 'w4': 0.22092382184595105}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:46,747]\u001b[0m Trial 49 finished with value: 0.7664764895079053 and parameters: {'w0': 0.7316008618889593, 'w1': 0.2701265202865842, 'w2': 0.8012793626315897, 'w3': 0.39498526809971796, 'w4': 0.03977436856885655}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:46,883]\u001b[0m Trial 50 finished with value: 0.7664327128674174 and parameters: {'w0': 0.9629153827769985, 'w1': 0.04152538635270096, 'w2': 0.19697251759560253, 'w3': 0.45801441668992743, 'w4': 0.9709856381376166}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:47,027]\u001b[0m Trial 51 finished with value: 0.7665063942100023 and parameters: {'w0': 0.7873182886941645, 'w1': 0.12387803238692612, 'w2': 0.1546152735597203, 'w3': 0.283473180232582, 'w4': 0.15483552854787638}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:47,164]\u001b[0m Trial 52 finished with value: 0.7665165175581151 and parameters: {'w0': 0.6843486864638214, 'w1': 0.0426980117893702, 'w2': 0.06382527892820596, 'w3': 0.20926339917220563, 'w4': 0.10155493415580791}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:47,303]\u001b[0m Trial 53 finished with value: 0.766504152380667 and parameters: {'w0': 0.6849359591868212, 'w1': 0.04911353452515662, 'w2': 0.0027301846002109054, 'w3': 0.21140741742338903, 'w4': 0.08755355441479815}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:47,439]\u001b[0m Trial 54 finished with value: 0.7665050188651555 and parameters: {'w0': 0.8644621269384047, 'w1': 0.20257879414049382, 'w2': 0.05617219041304164, 'w3': 0.15393503763462407, 'w4': 0.001330991251538599}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:47,572]\u001b[0m Trial 55 finished with value: 0.7663642847216909 and parameters: {'w0': 0.6076428577980889, 'w1': 0.09310638976996786, 'w2': 0.09052302182027486, 'w3': 0.054239550082567284, 'w4': 0.20351927564245756}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:47,707]\u001b[0m Trial 56 finished with value: 0.7664835545233981 and parameters: {'w0': 0.8116897814623077, 'w1': 0.034744412496419935, 'w2': 0.27267139835444365, 'w3': 0.2475606649433041, 'w4': 0.26255411113192806}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:47,844]\u001b[0m Trial 57 finished with value: 0.7662958811356941 and parameters: {'w0': 0.013413900724973393, 'w1': 0.12025065211902998, 'w2': 0.9707019001737133, 'w3': 0.12399952538428682, 'w4': 0.4083414133041029}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:17:47,977]\u001b[0m Trial 58 finished with value: 0.7665029545552677 and parameters: {'w0': 0.6639765524174821, 'w1': 0.08354623404789407, 'w2': 0.19212650227343975, 'w3': 0.34200119238999827, 'w4': 0.04975234904418645}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:48,115]\u001b[0m Trial 59 finished with value: 0.7665170785540395 and parameters: {'w0': 0.9208551050384838, 'w1': 0.036368592211823564, 'w2': 0.06931722822919689, 'w3': 0.27056692967891066, 'w4': 0.1701530138950172}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:48,248]\u001b[0m Trial 60 finished with value: 0.7664781979171527 and parameters: {'w0': 0.915883532242225, 'w1': 0.036003319588886265, 'w2': 0.0737877123650868, 'w3': 0.6009173057848096, 'w4': 0.29779864769191133}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:48,388]\u001b[0m Trial 61 finished with value: 0.7665103974458957 and parameters: {'w0': 0.8666687092321222, 'w1': 0.030565181378736705, 'w2': 0.024242885622929707, 'w3': 0.26025593833648175, 'w4': 0.1118646933803226}. Best is trial 22 with value: 0.7665275702980934.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:48,522]\u001b[0m Trial 62 finished with value: 0.7665316304091496 and parameters: {'w0': 0.9642993502685225, 'w1': 0.02153910013516374, 'w2': 0.02314676420254766, 'w3': 0.20217089259738855, 'w4': 0.11472091670766928}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:48,657]\u001b[0m Trial 63 finished with value: 0.7665297289690466 and parameters: {'w0': 0.9652535427110016, 'w1': 0.029592437938363723, 'w2': 0.026538353792054, 'w3': 0.20723179595739694, 'w4': 0.09312774373194692}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:48,789]\u001b[0m Trial 64 finished with value: 0.7665245244607743 and parameters: {'w0': 0.962472095964026, 'w1': 0.07146802981301704, 'w2': 0.02074309538220545, 'w3': 0.2118827541967849, 'w4': 0.1021641858713072}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:48,925]\u001b[0m Trial 65 finished with value: 0.7665075933280189 and parameters: {'w0': 0.9623029118407218, 'w1': 0.07968654237539409, 'w2': 0.07391358692049031, 'w3': 0.20862063843091358, 'w4': 0.17473742909682177}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:49,058]\u001b[0m Trial 66 finished with value: 0.7665048960665084 and parameters: {'w0': 0.9969591980283099, 'w1': 0.20680166871058325, 'w2': 0.0349523666873247, 'w3': 0.16832573560914227, 'w4': 0.03948808100825352}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:49,202]\u001b[0m Trial 67 finished with value: 0.7664762538206773 and parameters: {'w0': 0.9501674409705434, 'w1': 0.16854793222268236, 'w2': 0.1085739329253393, 'w3': 0.12789772008404698, 'w4': 0.099233086725214}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:49,337]\u001b[0m Trial 68 finished with value: 0.7663665739469954 and parameters: {'w0': 0.9209308911205689, 'w1': 0.8979561843489748, 'w2': 0.06565851396954435, 'w3': 0.19812175822044728, 'w4': 0.2038588275016064}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:49,477]\u001b[0m Trial 69 finished with value: 0.7664654492632278 and parameters: {'w0': 0.9699996978514928, 'w1': 0.4619988486536819, 'w2': 0.005272020769197038, 'w3': 0.22876371200269127, 'w4': 0.06307847917055148}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:49,613]\u001b[0m Trial 70 finished with value: 0.7664139281214002 and parameters: {'w0': 0.8994129351259256, 'w1': 0.9939811613179467, 'w2': 0.14482469037750037, 'w3': 0.37504005586452804, 'w4': 0.231635699088731}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:49,746]\u001b[0m Trial 71 finished with value: 0.7665090393359468 and parameters: {'w0': 0.8700293513135456, 'w1': 0.029804294790190866, 'w2': 0.028234125958845346, 'w3': 0.26433770948652574, 'w4': 0.09934192648124811}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:49,901]\u001b[0m Trial 72 finished with value: 0.7665023534882061 and parameters: {'w0': 0.8488811973258215, 'w1': 0.025920604218402046, 'w2': 0.04112512877815905, 'w3': 0.31194744855299517, 'w4': 0.12862593535293576}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:50,038]\u001b[0m Trial 73 finished with value: 0.7665165278990538 and parameters: {'w0': 0.9395342219514359, 'w1': 0.06976612171836681, 'w2': 0.09357942345362742, 'w3': 0.2691120132175631, 'w4': 0.17063923752746907}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:50,175]\u001b[0m Trial 74 finished with value: 0.7665064933106649 and parameters: {'w0': 0.9372854851827223, 'w1': 0.06232564407479248, 'w2': 0.09195334336703434, 'w3': 0.18334135540337906, 'w4': 0.16883734517499632}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:50,313]\u001b[0m Trial 75 finished with value: 0.7665314472883602 and parameters: {'w0': 0.9981507238750547, 'w1': 0.09633330273202736, 'w2': 0.12529385916469044, 'w3': 0.23105841584074271, 'w4': 0.029911146143366735}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:50,448]\u001b[0m Trial 76 finished with value: 0.7663646569954841 and parameters: {'w0': 0.9940337663583176, 'w1': 0.5974029581923481, 'w2': 0.12252850134266963, 'w3': 0.10939352426692486, 'w4': 0.0706654948180503}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:50,590]\u001b[0m Trial 77 finished with value: 0.7663497238182594 and parameters: {'w0': 0.8956888952799187, 'w1': 0.08672328136748547, 'w2': 0.07165116986666957, 'w3': 0.15678471110525424, 'w4': 0.7694263590933523}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:50,731]\u001b[0m Trial 78 finished with value: 0.7665112242901191 and parameters: {'w0': 0.9603013055646556, 'w1': 0.15395292004910344, 'w2': 0.0012625669058616562, 'w3': 0.23303370554365418, 'w4': 0.03689345881771061}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:50,867]\u001b[0m Trial 79 finished with value: 0.7664219910374774 and parameters: {'w0': 0.4281991306832237, 'w1': 0.1101784942853759, 'w2': 0.10737504229301803, 'w3': 0.28224551742181747, 'w4': 0.5721478514035786}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:51,001]\u001b[0m Trial 80 finished with value: 0.7663214086046148 and parameters: {'w0': 0.9257454843030306, 'w1': 0.34833287551225817, 'w2': 0.22786030167362017, 'w3': 0.038861945755348515, 'w4': 0.026042265640079804}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:51,137]\u001b[0m Trial 81 finished with value: 0.7665147673542405 and parameters: {'w0': 0.9742820921429922, 'w1': 0.15275662012914343, 'w2': 0.030353139542249767, 'w3': 0.23710352526221484, 'w4': 0.018934444952708213}. Best is trial 62 with value: 0.7665316304091496.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:51,273]\u001b[0m Trial 82 finished with value: 0.7665357030155069 and parameters: {'w0': 0.9767830593839694, 'w1': 0.06771697540334547, 'w2': 0.05806888098335237, 'w3': 0.1988849022520529, 'w4': 0.007623049106850521}. Best is trial 82 with value: 0.7665357030155069.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:51,407]\u001b[0m Trial 83 finished with value: 0.7665242952366332 and parameters: {'w0': 0.9330350403961892, 'w1': 0.06234344519282175, 'w2': 0.14445055438677332, 'w3': 0.19481193422728135, 'w4': 0.08356452451867344}. Best is trial 82 with value: 0.7665357030155069.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:51,540]\u001b[0m Trial 84 finished with value: 0.7665192053404316 and parameters: {'w0': 0.9397525188618073, 'w1': 0.10475584297836452, 'w2': 0.17437346743271348, 'w3': 0.1458482140634993, 'w4': 0.00440700698386624}. Best is trial 82 with value: 0.7665357030155069.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:51,675]\u001b[0m Trial 85 finished with value: 0.7664919505038759 and parameters: {'w0': 0.9943581391078335, 'w1': 0.19289648981301255, 'w2': 0.18267963980382818, 'w3': 0.14584193267808507, 'w4': 0.00964306012870924}. Best is trial 82 with value: 0.7665357030155069.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:51,813]\u001b[0m Trial 86 finished with value: 0.7664862491996738 and parameters: {'w0': 0.9002745903744303, 'w1': 0.10438118525336225, 'w2': 0.15008669555817178, 'w3': 0.1053298662177418, 'w4': 0.06488129869013247}. Best is trial 82 with value: 0.7665357030155069.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:17:51,947]\u001b[0m Trial 87 finished with value: 0.7665360472825911 and parameters: {'w0': 0.9504892955560603, 'w1': 0.020774435945686426, 'w2': 0.1313469993040955, 'w3': 0.17328934445106872, 'w4': 0.07957599815984442}. Best is trial 87 with value: 0.7665360472825911.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:52,084]\u001b[0m Trial 88 finished with value: 0.7665250789936121 and parameters: {'w0': 0.9504889130116199, 'w1': 0.06629211632264875, 'w2': 0.17312913565823101, 'w3': 0.17602214277241307, 'w4': 0.04627339697643117}. Best is trial 87 with value: 0.7665360472825911.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:52,220]\u001b[0m Trial 89 finished with value: 0.7665218655469117 and parameters: {'w0': 0.976557921906553, 'w1': 0.004894048118901567, 'w2': 0.25061606955486987, 'w3': 0.1683578679602863, 'w4': 0.07900531447279628}. Best is trial 87 with value: 0.7665360472825911.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:52,353]\u001b[0m Trial 90 finished with value: 0.7664161057507409 and parameters: {'w0': 0.2978267937481237, 'w1': 0.06513765479825655, 'w2': 0.1228407420026593, 'w3': 0.07518400178292184, 'w4': 0.1346824671857851}. Best is trial 87 with value: 0.7665360472825911.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:52,488]\u001b[0m Trial 91 finished with value: 0.7665215023214399 and parameters: {'w0': 0.9666880047539774, 'w1': 0.012901170349511583, 'w2': 0.2586932404889108, 'w3': 0.17430951099540948, 'w4': 0.0731688372001098}. Best is trial 87 with value: 0.7665360472825911.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:52,621]\u001b[0m Trial 92 finished with value: 0.7665442058523512 and parameters: {'w0': 0.9779423683736767, 'w1': 0.00928776981472915, 'w2': 0.2071804321847413, 'w3': 0.18820161406908795, 'w4': 0.0394496823649008}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:52,759]\u001b[0m Trial 93 finished with value: 0.7665260411317835 and parameters: {'w0': 0.8878866977620218, 'w1': 0.06120019737958903, 'w2': 0.21937320590356896, 'w3': 0.19743228963955667, 'w4': 0.03977569354299425}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:52,893]\u001b[0m Trial 94 finished with value: 0.7665092500325728 and parameters: {'w0': 0.999211299940227, 'w1': 0.13653861197531125, 'w2': 0.23444570889469518, 'w3': 0.21185821026170623, 'w4': 0.04120399619181589}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:53,027]\u001b[0m Trial 95 finished with value: 0.7664711337634046 and parameters: {'w0': 0.8879542439672153, 'w1': 0.7216774287904052, 'w2': 0.2811698657295977, 'w3': 0.9447651916302481, 'w4': 0.025037605630472377}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:53,161]\u001b[0m Trial 96 finished with value: 0.7664961648672677 and parameters: {'w0': 0.9526149316667071, 'w1': 0.01767026493772346, 'w2': 0.3366806558963443, 'w3': 0.12556827166967527, 'w4': 0.04967509794632281}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:53,301]\u001b[0m Trial 97 finished with value: 0.7665043798813185 and parameters: {'w0': 0.851883721690959, 'w1': 0.053800004245069075, 'w2': 0.20390885636084446, 'w3': 0.1820876692465289, 'w4': 0.12024858634289132}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:53,440]\u001b[0m Trial 98 finished with value: 0.7665277594510971 and parameters: {'w0': 0.91321020489058, 'w1': 0.083128709967111, 'w2': 0.16944066125082846, 'w3': 0.22409689108651482, 'w4': 0.055371995978448295}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:53,579]\u001b[0m Trial 99 finished with value: 0.7664999854132443 and parameters: {'w0': 0.913200393259593, 'w1': 0.0908140097774795, 'w2': 0.21633459372750746, 'w3': 0.10460270816912275, 'w4': 0.00023200381092495712}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:53,718]\u001b[0m Trial 100 finished with value: 0.7664353872926881 and parameters: {'w0': 0.8826372906204878, 'w1': 0.001970595028309859, 'w2': 0.16855098166493737, 'w3': 0.7362147500765949, 'w4': 0.0618474311717368}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:53,857]\u001b[0m Trial 101 finished with value: 0.7665272678256365 and parameters: {'w0': 0.9755964599768815, 'w1': 0.07375518010929508, 'w2': 0.10530663911628085, 'w3': 0.2284903091553565, 'w4': 0.10110171834566455}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:53,992]\u001b[0m Trial 102 finished with value: 0.7665338028680211 and parameters: {'w0': 0.9811193771809036, 'w1': 0.045478736142282705, 'w2': 0.1312051706312214, 'w3': 0.24005254505217438, 'w4': 0.04591257635389548}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:54,125]\u001b[0m Trial 103 finished with value: 0.7665337317740675 and parameters: {'w0': 0.9765697761482005, 'w1': 0.04528504088880368, 'w2': 0.13853103556442445, 'w3': 0.2426007958477702, 'w4': 0.028945792273410955}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:54,261]\u001b[0m Trial 104 finished with value: 0.7665295764402007 and parameters: {'w0': 0.9801196744725157, 'w1': 0.03168828514335472, 'w2': 0.13463450353683903, 'w3': 0.2334381711987817, 'w4': 0.13461791900611303}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:54,402]\u001b[0m Trial 105 finished with value: 0.7664632268231528 and parameters: {'w0': 0.12188651619764035, 'w1': 0.02929538406250059, 'w2': 0.13202027280462544, 'w3': 0.2988263459455903, 'w4': 0.14339467077673895}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:54,537]\u001b[0m Trial 106 finished with value: 0.7665310793232915 and parameters: {'w0': 0.9799324711462697, 'w1': 0.04232724142819335, 'w2': 0.1323333411983157, 'w3': 0.2455913964988588, 'w4': 0.08471609745633696}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:54,671]\u001b[0m Trial 107 finished with value: 0.7665215492865365 and parameters: {'w0': 0.9849498839756246, 'w1': 0.11919198363769302, 'w2': 0.08375117234245491, 'w3': 0.2500700554313249, 'w4': 0.021601407252614904}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:54,811]\u001b[0m Trial 108 finished with value: 0.7665012121070973 and parameters: {'w0': 0.9982923857169881, 'w1': 0.09574147652696383, 'w2': 0.050801724466502746, 'w3': 0.32342952779585343, 'w4': 0.0598033001280775}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:54,948]\u001b[0m Trial 109 finished with value: 0.7665289430577056 and parameters: {'w0': 0.9096505353446156, 'w1': 0.04120381133646406, 'w2': 0.1376220363168605, 'w3': 0.2473090715672363, 'w4': 0.08517088786256835}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:55,088]\u001b[0m Trial 110 finished with value: 0.7665233736004718 and parameters: {'w0': 0.9796187465026368, 'w1': 0.04719830103358564, 'w2': 0.13571179845513012, 'w3': 0.29193585613848705, 'w4': 0.08788291738289584}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:55,229]\u001b[0m Trial 111 finished with value: 0.7665427645840202 and parameters: {'w0': 0.9114072097710242, 'w1': 0.020254376126072934, 'w2': 0.18879478014509143, 'w3': 0.2241346410117809, 'w4': 0.024218249228116242}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:55,363]\u001b[0m Trial 112 finished with value: 0.7665244800809125 and parameters: {'w0': 0.9440928091880848, 'w1': 0.02033322176705588, 'w2': 0.1012387918599239, 'w3': 0.24989255218534095, 'w4': 0.020462505340846322}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:55,499]\u001b[0m Trial 113 finished with value: 0.7665246050339218 and parameters: {'w0': 0.9598936252564572, 'w1': 0.04095853182226763, 'w2': 0.126114349003343, 'w3': 0.27491072968531716, 'w4': 0.11715014634221235}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:55,634]\u001b[0m Trial 114 finished with value: 0.7665147445180007 and parameters: {'w0': 0.9259028458366758, 'w1': 0.028357882882102996, 'w2': 0.1931872082840801, 'w3': 0.3553729602474449, 'w4': 0.08106313695592782}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:55,771]\u001b[0m Trial 115 finished with value: 0.7664489136713775 and parameters: {'w0': 0.9744312379351256, 'w1': 0.04361603826770099, 'w2': 0.051300197451637435, 'w3': 0.20030340819430772, 'w4': 0.4366828441526831}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:17:55,909]\u001b[0m Trial 116 finished with value: 0.766536920230166 and parameters: {'w0': 0.9449954367721992, 'w1': 0.0021980949963682113, 'w2': 0.15346714456922098, 'w3': 0.24215075873672726, 'w4': 0.03041653088354688}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:56,046]\u001b[0m Trial 117 finished with value: 0.7665346529793566 and parameters: {'w0': 0.9995795148442153, 'w1': 0.0030132084262076003, 'w2': 0.08424633618458911, 'w3': 0.22779949716641867, 'w4': 0.01564596124504397}. Best is trial 92 with value: 0.7665442058523512.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:56,181]\u001b[0m Trial 118 finished with value: 0.7665598525543459 and parameters: {'w0': 0.9486736593091251, 'w1': 0.005164714932448994, 'w2': 0.08466972114449386, 'w3': 0.15321197563452976, 'w4': 0.028439016051325948}. Best is trial 118 with value: 0.7665598525543459.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:56,315]\u001b[0m Trial 119 finished with value: 0.7665622576843382 and parameters: {'w0': 0.9389405242074013, 'w1': 0.003117646207728062, 'w2': 0.07957032542446471, 'w3': 0.1428914210472637, 'w4': 0.03067718715985341}. Best is trial 119 with value: 0.7665622576843382.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:56,454]\u001b[0m Trial 120 finished with value: 0.7665604777502648 and parameters: {'w0': 0.9479692797333842, 'w1': 0.008992331413039182, 'w2': 0.08688467175514415, 'w3': 0.14756903609316088, 'w4': 0.029454793390515717}. Best is trial 119 with value: 0.7665622576843382.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:56,589]\u001b[0m Trial 121 finished with value: 0.7665751200885886 and parameters: {'w0': 0.9438501943214654, 'w1': 0.0007915700146012526, 'w2': 0.08025868294790456, 'w3': 0.13455043691210467, 'w4': 0.0009384352348889742}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:56,731]\u001b[0m Trial 122 finished with value: 0.7665741760470599 and parameters: {'w0': 0.933718014663843, 'w1': 0.001807728412039078, 'w2': 0.08580102273191757, 'w3': 0.13494790423072864, 'w4': 0.0017575611211658425}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:56,869]\u001b[0m Trial 123 finished with value: 0.7665600761771454 and parameters: {'w0': 0.8648299259077264, 'w1': 0.01096915440573206, 'w2': 0.09834216855277689, 'w3': 0.1505207591621204, 'w4': 0.008471072248302215}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:57,014]\u001b[0m Trial 124 finished with value: 0.7665635748614048 and parameters: {'w0': 0.8166536632299086, 'w1': 0.0021182273855559, 'w2': 0.07650612974832327, 'w3': 0.1379158687606348, 'w4': 0.00227312968307462}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:57,159]\u001b[0m Trial 125 finished with value: 0.7665659946410601 and parameters: {'w0': 0.859387668978772, 'w1': 0.003769344830295138, 'w2': 0.08222236453832484, 'w3': 0.13976246123052305, 'w4': 0.0053578353868737535}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:57,297]\u001b[0m Trial 126 finished with value: 0.7665649428814201 and parameters: {'w0': 0.8240284763367872, 'w1': 0.008631126192928388, 'w2': 0.06763045353294486, 'w3': 0.13351837554866447, 'w4': 0.00019126002359078076}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:57,435]\u001b[0m Trial 127 finished with value: 0.7665559398016661 and parameters: {'w0': 0.8196325440989914, 'w1': 0.00017252575050545615, 'w2': 0.1034836467336531, 'w3': 0.06163876740163443, 'w4': 0.0032142587238646256}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:57,572]\u001b[0m Trial 128 finished with value: 0.7665450314039572 and parameters: {'w0': 0.8135948717754279, 'w1': 0.002047676201707292, 'w2': 0.0786548903686957, 'w3': 0.037886414868235185, 'w4': 0.005727779639586431}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:57,706]\u001b[0m Trial 129 finished with value: 0.766561286066973 and parameters: {'w0': 0.8151727755570579, 'w1': 0.002316420838801351, 'w2': 0.07701110788132394, 'w3': 0.05477416600203383, 'w4': 0.004494472810960484}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:57,844]\u001b[0m Trial 130 finished with value: 0.7665518598704775 and parameters: {'w0': 0.8172354213017468, 'w1': 0.003267874072847613, 'w2': 0.07709406979650835, 'w3': 0.04378946525948561, 'w4': 0.005564491428778716}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:57,980]\u001b[0m Trial 131 finished with value: 0.7665419566981844 and parameters: {'w0': 0.8129783387359066, 'w1': 0.00010130993235687828, 'w2': 0.0784367832091575, 'w3': 0.036708201212367404, 'w4': 0.009452225338089574}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:58,115]\u001b[0m Trial 132 finished with value: 0.766553145162983 and parameters: {'w0': 0.760386518270159, 'w1': 0.0046441808259755635, 'w2': 0.1010531855020648, 'w3': 0.06245928231142249, 'w4': 0.0021040886160261056}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:58,250]\u001b[0m Trial 133 finished with value: 0.7664242923272101 and parameters: {'w0': 0.7650586982548825, 'w1': 0.0004153471514285012, 'w2': 0.09499169211653262, 'w3': 0.0038299612418282794, 'w4': 0.0017309291717193139}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:58,387]\u001b[0m Trial 134 finished with value: 0.7665509576235761 and parameters: {'w0': 0.7982481000028352, 'w1': 0.02214132132437297, 'w2': 0.06357027549769542, 'w3': 0.05317707718197312, 'w4': 0.0038573869317684115}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:58,523]\u001b[0m Trial 135 finished with value: 0.7665619060924224 and parameters: {'w0': 0.8347507026088523, 'w1': 0.02226450843194276, 'w2': 0.04589459272292596, 'w3': 0.05817588696743081, 'w4': 0.0026023314922432976}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:58,660]\u001b[0m Trial 136 finished with value: 0.7665413633868268 and parameters: {'w0': 0.8397408769204382, 'w1': 0.020393359209001878, 'w2': 0.03925318731962184, 'w3': 0.09080236660800911, 'w4': 0.058424584697552163}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:58,799]\u001b[0m Trial 137 finished with value: 0.766524601586942 and parameters: {'w0': 0.848799393588402, 'w1': 0.06208387253294556, 'w2': 0.10611099205240776, 'w3': 0.0765151562539968, 'w4': 0.0017596885144851278}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:58,934]\u001b[0m Trial 138 finished with value: 0.7665397178849562 and parameters: {'w0': 0.8280054478386107, 'w1': 0.022122668276398992, 'w2': 0.05374455718910538, 'w3': 0.0612265087869107, 'w4': 0.03153501289248953}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:59,073]\u001b[0m Trial 139 finished with value: 0.7664211068872187 and parameters: {'w0': 0.7431507823072578, 'w1': 0.0527729484565313, 'w2': 0.6077905725994607, 'w3': 0.11512776893167433, 'w4': 0.05505268630781032}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:59,215]\u001b[0m Trial 140 finished with value: 0.7664392974601333 and parameters: {'w0': 0.7051695227885155, 'w1': 0.4217270379398753, 'w2': 0.016496442049923496, 'w3': 0.13965054077405434, 'w4': 0.027854620600244268}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:59,351]\u001b[0m Trial 141 finished with value: 0.7665526177751094 and parameters: {'w0': 0.7878629636962711, 'w1': 0.020763568218969932, 'w2': 0.06998714442293076, 'w3': 0.054472821955457114, 'w4': 0.0007774447747910251}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:59,492]\u001b[0m Trial 142 finished with value: 0.7665107395586177 and parameters: {'w0': 0.7766611396916834, 'w1': 0.021018135199970193, 'w2': 0.04310746813824648, 'w3': 0.017914351806889994, 'w4': 0.000810983887538145}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:59,642]\u001b[0m Trial 143 finished with value: 0.7663074677266326 and parameters: {'w0': 0.7975835402053312, 'w1': 0.8244121101626318, 'w2': 0.10393333624255251, 'w3': 0.08872821866831301, 'w4': 0.04573909786776757}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:17:59,776]\u001b[0m Trial 144 finished with value: 0.7665535997334133 and parameters: {'w0': 0.8622467587016618, 'w1': 0.0009590277381594419, 'w2': 0.06396040778908554, 'w3': 0.058892071729814005, 'w4': 0.0271963667108325}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:17:59,911]\u001b[0m Trial 145 finished with value: 0.7665288383557012 and parameters: {'w0': 0.8672297542850173, 'w1': 0.05143017453172478, 'w2': 0.06637506819174856, 'w3': 0.0743733410000531, 'w4': 0.025452116402113624}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:00,054]\u001b[0m Trial 146 finished with value: 0.7665414762754075 and parameters: {'w0': 0.8612645113655579, 'w1': 0.034766684502009065, 'w2': 0.03400086040830905, 'w3': 0.12260171102553934, 'w4': 0.06167576084157142}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:00,189]\u001b[0m Trial 147 finished with value: 0.7662909429065934 and parameters: {'w0': 0.8318000309674655, 'w1': 0.0783363831103179, 'w2': 0.50179802995896, 'w3': 0.09843110644358335, 'w4': 0.6414819697538336}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:00,324]\u001b[0m Trial 148 finished with value: 0.7664254892908645 and parameters: {'w0': 0.7579058794111524, 'w1': 0.00021918665890239587, 'w2': 0.10730896952743499, 'w3': 0.015105822783495343, 'w4': 0.04078176774165965}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:00,462]\u001b[0m Trial 149 finished with value: 0.766542610762557 and parameters: {'w0': 0.7940280060184215, 'w1': 0.023225951925481356, 'w2': 0.0002735203451001214, 'w3': 0.13947230130470029, 'w4': 0.023097722513439528}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:00,599]\u001b[0m Trial 150 finished with value: 0.7664828461690973 and parameters: {'w0': 0.8844612386433728, 'w1': 0.06838373850015132, 'w2': 0.060748883742687915, 'w3': 0.05456388842985186, 'w4': 0.05987822181738099}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:00,743]\u001b[0m Trial 151 finished with value: 0.7665026365714029 and parameters: {'w0': 0.8207677872564256, 'w1': 0.020105694154739825, 'w2': 0.08998058859144929, 'w3': 0.03784214914709411, 'w4': 0.025915238772575625}. Best is trial 121 with value: 0.7665751200885886.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:00,877]\u001b[0m Trial 152 finished with value: 0.7665765863475215 and parameters: {'w0': 0.844106822198068, 'w1': 0.000503089399193888, 'w2': 0.08348948920297906, 'w3': 0.10990889073299939, 'w4': 0.001973243148990872}. Best is trial 152 with value: 0.7665765863475215.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:01,021]\u001b[0m Trial 153 finished with value: 0.766533044963389 and parameters: {'w0': 0.8642659811784718, 'w1': 0.043338449637837895, 'w2': 0.08701253446212948, 'w3': 0.10972166485447571, 'w4': 0.04055590448573956}. Best is trial 152 with value: 0.7665765863475215.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:01,162]\u001b[0m Trial 154 finished with value: 0.7665465782360376 and parameters: {'w0': 0.8471071322962405, 'w1': 0.021281487295109713, 'w2': 0.03569989316391947, 'w3': 0.151232106375914, 'w4': 0.019088760843964717}. Best is trial 152 with value: 0.7665765863475215.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:01,298]\u001b[0m Trial 155 finished with value: 0.7665767543877753 and parameters: {'w0': 0.8049209814248348, 'w1': 0.00012595376369479907, 'w2': 0.0625996383224271, 'w3': 0.07352703096963834, 'w4': 0.00013454757709822126}. Best is trial 155 with value: 0.7665767543877753.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:01,436]\u001b[0m Trial 156 finished with value: 0.7662622265507018 and parameters: {'w0': 0.8739000056932212, 'w1': 0.0008506266413580393, 'w2': 0.1097041417252397, 'w3': 0.07837514124506678, 'w4': 0.8913936462837575}. Best is trial 155 with value: 0.7665767543877753.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:01,575]\u001b[0m Trial 157 finished with value: 0.7665385045481492 and parameters: {'w0': 0.8261560296206344, 'w1': 0.052692908358493926, 'w2': 0.05053510921247532, 'w3': 0.13735643146412446, 'w4': 0.04540426637303747}. Best is trial 155 with value: 0.7665767543877753.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:01,710]\u001b[0m Trial 158 finished with value: 0.7665946054332026 and parameters: {'w0': 0.894359939849639, 'w1': 0.00029513428180652393, 'w2': 0.020421268088929037, 'w3': 0.09404739907116172, 'w4': 0.0008798883629568231}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:01,849]\u001b[0m Trial 159 finished with value: 0.7665438370255376 and parameters: {'w0': 0.8916834307732646, 'w1': 0.038924540721266804, 'w2': 0.020686557744870875, 'w3': 0.11686131527271304, 'w4': 0.058030142366205746}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:01,990]\u001b[0m Trial 160 finished with value: 0.7665330178184249 and parameters: {'w0': 0.8472905109285176, 'w1': 0.08119347257115539, 'w2': 0.02518618949043385, 'w3': 0.0949543058220382, 'w4': 0.024585088368256215}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:02,128]\u001b[0m Trial 161 finished with value: 0.7665340045163258 and parameters: {'w0': 0.8973210842713762, 'w1': 0.033859233209189765, 'w2': 0.09042728683253777, 'w3': 0.06747890407095805, 'w4': 0.015701858591372644}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:02,267]\u001b[0m Trial 162 finished with value: 0.7665485667123746 and parameters: {'w0': 0.8054253701128756, 'w1': 0.0037636839314714125, 'w2': 0.05100747255994871, 'w3': 0.1532531750667855, 'w4': 0.0012549711448138698}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:02,410]\u001b[0m Trial 163 finished with value: 0.7665533188045788 and parameters: {'w0': 0.8747617364450931, 'w1': 0.018870060209930463, 'w2': 0.06834472724734805, 'w3': 0.12581919475955858, 'w4': 0.038396408627390646}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:02,546]\u001b[0m Trial 164 finished with value: 0.7665351644249496 and parameters: {'w0': 0.881952728532513, 'w1': 0.05830480639905926, 'w2': 0.06888093263514171, 'w3': 0.12685573921765136, 'w4': 0.040947950259452665}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:02,684]\u001b[0m Trial 165 finished with value: 0.7663636638344967 and parameters: {'w0': 0.8604483333001739, 'w1': 0.03316319407621903, 'w2': 0.041803332522781525, 'w3': 0.09897458947198587, 'w4': 0.5025685930837079}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:02,823]\u001b[0m Trial 166 finished with value: 0.7665427387316734 and parameters: {'w0': 0.9231288373119916, 'w1': 0.02144806456864301, 'w2': 0.08019679093581687, 'w3': 0.1547222603535388, 'w4': 0.0695034003148555}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:02,963]\u001b[0m Trial 167 finished with value: 0.7664296881428482 and parameters: {'w0': 0.8677082528616558, 'w1': 0.0008695757319184556, 'w2': 0.6740640285039733, 'w3': 0.113400454177631, 'w4': 0.038151198773453625}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:03,104]\u001b[0m Trial 168 finished with value: 0.7665326468372491 and parameters: {'w0': 0.8374655620314598, 'w1': 0.053056861966596425, 'w2': 0.11573126337270889, 'w3': 0.0871665695183852, 'w4': 3.271190269970225e-05}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:03,246]\u001b[0m Trial 169 finished with value: 0.7665254969398845 and parameters: {'w0': 0.902271015820668, 'w1': 0.035093419481334515, 'w2': 0.010070527377272362, 'w3': 0.028710819738379176, 'w4': 0.023635176353253004}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:03,383]\u001b[0m Trial 170 finished with value: 0.7664134429590264 and parameters: {'w0': 0.83632967413503, 'w1': 0.01903635543596273, 'w2': 0.783501511074934, 'w3': 0.12803159150034205, 'w4': 0.07078149690475034}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:03,530]\u001b[0m Trial 171 finished with value: 0.7665477239258708 and parameters: {'w0': 0.775228836937396, 'w1': 0.0021915442675393016, 'w2': 0.09205120579079056, 'w3': 0.06535002093072573, 'w4': 0.019402161793885205}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:18:03,680]\u001b[0m Trial 172 finished with value: 0.7665425508712871 and parameters: {'w0': 0.8062451826053947, 'w1': 0.020494010344291436, 'w2': 0.06235738298574214, 'w3': 0.16301761479581148, 'w4': 0.0005611298953683386}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:03,825]\u001b[0m Trial 173 finished with value: 0.7665315007165434 and parameters: {'w0': 0.8774613446711956, 'w1': 0.0017698864854107585, 'w2': 0.11271489216634592, 'w3': 0.07511208969512385, 'w4': 0.045262962266540224}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:03,967]\u001b[0m Trial 174 finished with value: 0.7665436931141407 and parameters: {'w0': 0.8521903734084912, 'w1': 0.042606114754578366, 'w2': 0.07548723525334815, 'w3': 0.10262148412546807, 'w4': 0.021534381537655484}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:04,121]\u001b[0m Trial 175 finished with value: 0.7665374463254222 and parameters: {'w0': 0.8231959648099897, 'w1': 0.06409804546721534, 'w2': 0.0417746451684648, 'w3': 0.14161569533378393, 'w4': 0.03857013889415605}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:04,267]\u001b[0m Trial 176 finished with value: 0.7665653384223252 and parameters: {'w0': 0.7453607340915576, 'w1': 1.41186421639709e-05, 'w2': 0.10155390561176998, 'w3': 0.0851857904289294, 'w4': 0.00075179815390755}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:04,405]\u001b[0m Trial 177 finished with value: 0.7663685158891083 and parameters: {'w0': 0.9245277310840296, 'w1': 0.6395352467077788, 'w2': 0.060027810134042084, 'w3': 0.11347715165318079, 'w4': 0.0550448279939995}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:04,549]\u001b[0m Trial 178 finished with value: 0.766352566283784 and parameters: {'w0': 0.5025213995770018, 'w1': 0.029431470953824288, 'w2': 0.9139866592644372, 'w3': 0.08495151111769109, 'w4': 0.029198646631990517}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:04,697]\u001b[0m Trial 179 finished with value: 0.7665519757751653 and parameters: {'w0': 0.9071096225931969, 'w1': 2.1106430205721644e-05, 'w2': 0.027160363296231036, 'w3': 0.16148461296743433, 'w4': 0.01777714022526552}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:04,839]\u001b[0m Trial 180 finished with value: 0.7665282747745422 and parameters: {'w0': 0.8850612481281384, 'w1': 0.04394215439790046, 'w2': 0.08936328314670652, 'w3': 0.13231092540650613, 'w4': 0.06852265666154}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:04,981]\u001b[0m Trial 181 finished with value: 0.7665269162337207 and parameters: {'w0': 0.7336225367861613, 'w1': 0.019820925291224877, 'w2': 0.11002531129242046, 'w3': 0.06396007989962593, 'w4': 0.019122300934919095}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:05,124]\u001b[0m Trial 182 finished with value: 0.7663846662809922 and parameters: {'w0': 0.7536889793820848, 'w1': 0.019576569009623342, 'w2': 0.09172725994077717, 'w3': 0.0021834164475352733, 'w4': 0.014541903547333146}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:05,268]\u001b[0m Trial 183 finished with value: 0.7664066050133121 and parameters: {'w0': 0.7767560546047875, 'w1': 0.0004177494513389574, 'w2': 0.4228728063193478, 'w3': 0.046084871459594855, 'w4': 0.0002824018105158123}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:05,418]\u001b[0m Trial 184 finished with value: 0.7664425811390423 and parameters: {'w0': 0.8005017853636367, 'w1': 0.037676674413191905, 'w2': 0.0688417983433472, 'w3': 0.024984319173061362, 'w4': 0.050268628300785594}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:05,562]\u001b[0m Trial 185 finished with value: 0.7665329424157469 and parameters: {'w0': 0.8359056829713174, 'w1': 0.058107843444046965, 'w2': 0.11849402583147137, 'w3': 0.09679350657294888, 'w4': 0.0005406141089543226}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:05,706]\u001b[0m Trial 186 finished with value: 0.766555191376228 and parameters: {'w0': 0.8165246462130339, 'w1': 0.019231011499622842, 'w2': 0.05057536917208563, 'w3': 0.12134585621799061, 'w4': 0.03356692353832893}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:05,848]\u001b[0m Trial 187 finished with value: 0.7665521227026694 and parameters: {'w0': 0.8585321388002287, 'w1': 0.02042247505954158, 'w2': 0.04362989707505335, 'w3': 0.1372685776563901, 'w4': 0.03641814418713767}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:05,996]\u001b[0m Trial 188 finished with value: 0.7664551139258717 and parameters: {'w0': 0.8167667491647825, 'w1': 0.07434000539885055, 'w2': 0.05585632156155839, 'w3': 0.5286979338691644, 'w4': 0.036826147536174886}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:06,140]\u001b[0m Trial 189 finished with value: 0.7665305915756828 and parameters: {'w0': 0.8527916343789061, 'w1': 0.03696170771930917, 'w2': 0.02229769144223038, 'w3': 0.1757880489206834, 'w4': 0.07142275362246077}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:06,286]\u001b[0m Trial 190 finished with value: 0.76653655097248 and parameters: {'w0': 0.9257225306310457, 'w1': 0.01624032225176882, 'w2': 0.07759361166358612, 'w3': 0.08657540399219887, 'w4': 0.053486226403844324}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:06,433]\u001b[0m Trial 191 finished with value: 0.766559487174512 and parameters: {'w0': 0.7823584311190572, 'w1': 0.001769673066320639, 'w2': 0.10269353423437023, 'w3': 0.11425572969337763, 'w4': 0.02096716779149004}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:06,580]\u001b[0m Trial 192 finished with value: 0.7665562788982809 and parameters: {'w0': 0.804540474717909, 'w1': 0.021857606429430056, 'w2': 0.07089373547937006, 'w3': 0.11608238928386802, 'w4': 0.02226265407398766}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:06,728]\u001b[0m Trial 193 finished with value: 0.766537560075748 and parameters: {'w0': 0.7778781732872403, 'w1': 0.044531245290768906, 'w2': 0.1011504114168145, 'w3': 0.11093602413714228, 'w4': 0.018367034009289882}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:06,874]\u001b[0m Trial 194 finished with value: 0.766546133144801 and parameters: {'w0': 0.7990361206257269, 'w1': 0.0025920487310761983, 'w2': 0.04956706745830016, 'w3': 0.15292405181206836, 'w4': 0.018125829119229404}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:07,011]\u001b[0m Trial 195 finished with value: 0.7665278495034382 and parameters: {'w0': 0.8159413261406234, 'w1': 0.03166883917144339, 'w2': 0.15048657905168522, 'w3': 0.11008130139849912, 'w4': 0.029308186984143895}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:07,142]\u001b[0m Trial 196 finished with value: 0.7665366866973005 and parameters: {'w0': 0.8324393765293995, 'w1': 0.05730732841250981, 'w2': 0.08012538494609497, 'w3': 0.08047717613314574, 'w4': 0.0015323814533251085}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:07,277]\u001b[0m Trial 197 finished with value: 0.7665362135993552 and parameters: {'w0': 0.7783820553260354, 'w1': 0.020269180160142102, 'w2': 0.11927597380993779, 'w3': 0.1330955207581683, 'w4': 0.05098861496099916}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:07,414]\u001b[0m Trial 198 finished with value: 0.7665407989439227 and parameters: {'w0': 0.7195861262916695, 'w1': 0.0023801364551244426, 'w2': 0.09762051125362889, 'w3': 0.16811699313592543, 'w4': 0.0010637961087775316}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:07,555]\u001b[0m Trial 199 finished with value: 0.7664187392431294 and parameters: {'w0': 0.800497539289979, 'w1': 8.759023181607959e-05, 'w2': 0.03374317406711349, 'w3': 0.10499001081874827, 'w4': 0.3654484571323973}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:18:07,700]\u001b[0m Trial 200 finished with value: 0.766543436314163 and parameters: {'w0': 0.8337983152823584, 'w1': 0.03708008072198662, 'w2': 0.009716031239227221, 'w3': 0.05060690115206458, 'w4': 0.028227038359592237}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:07,846]\u001b[0m Trial 201 finished with value: 0.7665542089870516 and parameters: {'w0': 0.8961403403860995, 'w1': 0.020299507758057, 'w2': 0.06462183426730911, 'w3': 0.12257875522985553, 'w4': 0.037507673231683254}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:07,997]\u001b[0m Trial 202 finished with value: 0.7665631668251986 and parameters: {'w0': 0.8993869135432766, 'w1': 0.01902247359886118, 'w2': 0.0608947424077932, 'w3': 0.12530237844794823, 'w4': 0.021188374389848382}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:08,146]\u001b[0m Trial 203 finished with value: 0.7664000290380453 and parameters: {'w0': 0.903509033350874, 'w1': 0.021680906056892692, 'w2': 0.08230472498570916, 'w3': 0.1516765596908129, 'w4': 0.5375160530382127}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:08,297]\u001b[0m Trial 204 finished with value: 0.7663247280459369 and parameters: {'w0': 0.9282860568065754, 'w1': 0.05249592823603262, 'w2': 0.05189624059177489, 'w3': 0.12473019456230401, 'w4': 0.8001792389468448}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:08,443]\u001b[0m Trial 205 finished with value: 0.7665579631786714 and parameters: {'w0': 0.9494833194500043, 'w1': 0.022290378698458607, 'w2': 0.09389419607424215, 'w3': 0.14093286469869454, 'w4': 0.022080459197184252}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:08,585]\u001b[0m Trial 206 finished with value: 0.7665103836579774 and parameters: {'w0': 0.3858864843111505, 'w1': 0.03810685485899758, 'w2': 0.11427814588147764, 'w3': 0.1770989097947134, 'w4': 0.017742555713723504}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:08,727]\u001b[0m Trial 207 finished with value: 0.7665254422190839 and parameters: {'w0': 0.9475313321628785, 'w1': 0.07437459234946843, 'w2': 0.0989840310476148, 'w3': 0.14799142622982905, 'w4': 0.0534729950292083}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:08,874]\u001b[0m Trial 208 finished with value: 0.7665637295446128 and parameters: {'w0': 0.9428727264077709, 'w1': 0.020811938337383085, 'w2': 0.08118771119356677, 'w3': 0.09036603644381236, 'w4': 0.0011072986412466873}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:09,012]\u001b[0m Trial 209 finished with value: 0.7665731014511803 and parameters: {'w0': 0.9479010654017729, 'w1': 0.0004448522783177143, 'w2': 0.08618361648405806, 'w3': 0.0919122708228992, 'w4': 0.002601311360867389}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:09,155]\u001b[0m Trial 210 finished with value: 0.7665411686324811 and parameters: {'w0': 0.9447547805627973, 'w1': 0.0473382294837775, 'w2': 0.08278752271501864, 'w3': 0.09285253130466255, 'w4': 0.016903263526279903}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:09,293]\u001b[0m Trial 211 finished with value: 0.7665566740083137 and parameters: {'w0': 0.9391243319086389, 'w1': 0.0006512737389353874, 'w2': 0.1222133149930719, 'w3': 0.07716085912634078, 'w4': 0.0031696046002173987}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:09,428]\u001b[0m Trial 212 finished with value: 0.7665435237812697 and parameters: {'w0': 0.9355432168748077, 'w1': 0.021432815853276877, 'w2': 0.1313195778169175, 'w3': 0.09872085314624869, 'w4': 0.015780777545946017}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:09,561]\u001b[0m Trial 213 finished with value: 0.7665529568717242 and parameters: {'w0': 0.9535700736032398, 'w1': 0.03251979629401315, 'w2': 0.08055372313835368, 'w3': 0.07683920517468776, 'w4': 0.0004270047183964447}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:09,697]\u001b[0m Trial 214 finished with value: 0.7665573048055743 and parameters: {'w0': 0.9127640841433285, 'w1': 0.016733186846482225, 'w2': 0.11851423453760848, 'w3': 0.14367307645398403, 'w4': 0.01735183831524544}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:09,830]\u001b[0m Trial 215 finished with value: 0.7665472034319563 and parameters: {'w0': 0.9119768125498736, 'w1': 0.0007635185618425704, 'w2': 0.1517120675319765, 'w3': 0.14291740945564022, 'w4': 0.04148825504298885}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:09,971]\u001b[0m Trial 216 finished with value: 0.7665656951847104 and parameters: {'w0': 0.936441118804664, 'w1': 0.0004863274192175304, 'w2': 0.11061837543020027, 'w3': 0.15986049590678922, 'w4': 0.0007563956013266902}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:10,115]\u001b[0m Trial 217 finished with value: 0.7665466152910678 and parameters: {'w0': 0.9595286846487601, 'w1': 0.03778003351342567, 'w2': 0.09684768414221501, 'w3': 0.1866563837857842, 'w4': 0.018732401368331156}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:10,256]\u001b[0m Trial 218 finished with value: 0.7665429830363502 and parameters: {'w0': 0.9283013490743035, 'w1': 0.017281287189268867, 'w2': 0.1139326731526309, 'w3': 0.1595539623245268, 'w4': 0.06210047580142632}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:10,400]\u001b[0m Trial 219 finished with value: 0.7665502337578672 and parameters: {'w0': 0.9165448830503521, 'w1': 0.05932415295858988, 'w2': 0.09193766675491735, 'w3': 0.1363188190964761, 'w4': 0.00025332974880986833}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:10,545]\u001b[0m Trial 220 finished with value: 0.7664250562640564 and parameters: {'w0': 0.8974786777003823, 'w1': 0.01773681300635265, 'w2': 0.06448692163005114, 'w3': 0.6181290653263375, 'w4': 0.035739025361182314}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:10,697]\u001b[0m Trial 221 finished with value: 0.7665575111934758 and parameters: {'w0': 0.9464874818514153, 'w1': 0.01793540287704759, 'w2': 0.12429964586756295, 'w3': 0.16217268912279045, 'w4': 0.016241125021109398}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:10,845]\u001b[0m Trial 222 finished with value: 0.766554598926615 and parameters: {'w0': 0.9583412649681929, 'w1': 0.035112442869367884, 'w2': 0.1405876870289613, 'w3': 0.1763515939117195, 'w4': 0.0003062337910497599}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:10,992]\u001b[0m Trial 223 finished with value: 0.7665601713999559 and parameters: {'w0': 0.9349011965682218, 'w1': 3.373399833733401e-05, 'w2': 0.11655815046061284, 'w3': 0.1566010714885329, 'w4': 0.02698699742037499}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:11,133]\u001b[0m Trial 224 finished with value: 0.7665562965640513 and parameters: {'w0': 0.9337611801054123, 'w1': 7.6395007511704e-06, 'w2': 0.09720477068990446, 'w3': 0.16461973622202672, 'w4': 0.03560443253208184}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:11,273]\u001b[0m Trial 225 finished with value: 0.7664779307762363 and parameters: {'w0': 0.9524760117901035, 'w1': 0.2607824968791857, 'w2': 0.084298517325145, 'w3': 0.13272898262814373, 'w4': 0.022697854541253663}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:11,416]\u001b[0m Trial 226 finished with value: 0.7665464567300077 and parameters: {'w0': 0.9597091742972332, 'w1': 0.03358820094464849, 'w2': 0.04260134583469542, 'w3': 0.11162175079666611, 'w4': 0.049887436991324016}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:11,562]\u001b[0m Trial 227 finished with value: 0.7663654984893706 and parameters: {'w0': 0.9385088425107352, 'w1': 0.01745912298291925, 'w2': 0.06750905725886011, 'w3': 0.8673105009246602, 'w4': 0.018767085247088942}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:18:11,714]\u001b[0m Trial 228 finished with value: 0.7665644818479032 and parameters: {'w0': 0.9187690741917148, 'w1': 0.000765882059916383, 'w2': 0.11551490414172007, 'w3': 0.16035247360059335, 'w4': 0.0015625700038482578}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:11,857]\u001b[0m Trial 229 finished with value: 0.7665428546363614 and parameters: {'w0': 0.8848010698266833, 'w1': 0.002224756056684451, 'w2': 0.10378572316304853, 'w3': 0.19242705591569012, 'w4': 0.03921540929073819}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:11,997]\u001b[0m Trial 230 finished with value: 0.7665513242960273 and parameters: {'w0': 0.9208568323391663, 'w1': 0.0493125270611054, 'w2': 0.07809529156813752, 'w3': 0.10233538963608664, 'w4': 0.0015209923332135796}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:12,137]\u001b[0m Trial 231 finished with value: 0.7665618479246423 and parameters: {'w0': 0.9390630393080981, 'w1': 0.018170667143341007, 'w2': 0.1265913076327475, 'w3': 0.16034846038299894, 'w4': 0.00041119171471000417}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:12,282]\u001b[0m Trial 232 finished with value: 0.7663553587681049 and parameters: {'w0': 0.9107051474015374, 'w1': 0.9485829201396386, 'w2': 0.1560533634190316, 'w3': 0.1532180929525887, 'w4': 0.0019338359061751784}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:12,427]\u001b[0m Trial 233 finished with value: 0.7665602868737713 and parameters: {'w0': 0.9331708083230362, 'w1': 0.0011475944393557556, 'w2': 0.11484131146821949, 'w3': 0.13403345918886644, 'w4': 0.026525407633176217}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:12,564]\u001b[0m Trial 234 finished with value: 0.7665654758706355 and parameters: {'w0': 0.8982661293012926, 'w1': 0.0028901418231149895, 'w2': 0.1332748945513115, 'w3': 0.12371709659531599, 'w4': 0.00015396197231173653}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:12,703]\u001b[0m Trial 235 finished with value: 0.7665443407154267 and parameters: {'w0': 0.8761804612380355, 'w1': 0.030107559801683743, 'w2': 0.13720950231991957, 'w3': 0.17754676365867822, 'w4': 0.03330434132648575}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:12,849]\u001b[0m Trial 236 finished with value: 0.7665702783749158 and parameters: {'w0': 0.8993264932814019, 'w1': 0.0011250657063920499, 'w2': 0.11763011779087448, 'w3': 0.1287606849119048, 'w4': 0.0023177315446510907}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:12,991]\u001b[0m Trial 237 finished with value: 0.7665607806535941 and parameters: {'w0': 0.8986944836717046, 'w1': 0.0011261523371352568, 'w2': 0.161451748826908, 'w3': 0.13259751020035151, 'w4': 0.0010573572311048138}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:13,133]\u001b[0m Trial 238 finished with value: 0.7665628781406602 and parameters: {'w0': 0.9007092758462538, 'w1': 0.0005682116114212624, 'w2': 0.14844878246758078, 'w3': 0.12608280739947075, 'w4': 0.0012583844726950372}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:13,272]\u001b[0m Trial 239 finished with value: 0.7663700834030659 and parameters: {'w0': 0.8966158042971253, 'w1': 0.5342280816282976, 'w2': 0.1652202778047123, 'w3': 0.09468655960739682, 'w4': 0.00043459405790631706}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:13,413]\u001b[0m Trial 240 finished with value: 0.7665397971654864 and parameters: {'w0': 0.8965350529682644, 'w1': 0.035559711336083974, 'w2': 0.1719089028522171, 'w3': 0.12033582224883113, 'w4': 0.0005974346977196574}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:13,557]\u001b[0m Trial 241 finished with value: 0.7665592359758762 and parameters: {'w0': 0.9286110903027283, 'w1': 0.0015921620080949837, 'w2': 0.1364246178085752, 'w3': 0.1379709066737399, 'w4': 0.018979176128690354}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:13,694]\u001b[0m Trial 242 finished with value: 0.766563371920483 and parameters: {'w0': 0.9124075015748652, 'w1': 0.00042201761210908305, 'w2': 0.14920641498862156, 'w3': 0.1281587068806207, 'w4': 0.0012391485549972446}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:13,832]\u001b[0m Trial 243 finished with value: 0.7665455307851219 and parameters: {'w0': 0.9065518497719014, 'w1': 0.019699911770352175, 'w2': 0.1485110035018583, 'w3': 0.12290368671267901, 'w4': 0.016669063792414285}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:13,969]\u001b[0m Trial 244 finished with value: 0.766549560735107 and parameters: {'w0': 0.8841053298171268, 'w1': 0.0009970277913979272, 'w2': 0.1592468646694245, 'w3': 0.09105261821324315, 'w4': 0.0015642540179163235}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:14,116]\u001b[0m Trial 245 finished with value: 0.7665315356172114 and parameters: {'w0': 0.9111789696886625, 'w1': 0.02511007244175792, 'w2': 0.13021989222661784, 'w3': 0.10661445023778368, 'w4': 0.04214534284087716}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:14,267]\u001b[0m Trial 246 finished with value: 0.7665601511489509 and parameters: {'w0': 0.8806884253810904, 'w1': 0.02100625633973046, 'w2': 0.12116248645750025, 'w3': 0.13028703679665773, 'w4': 0.00038399248203056747}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:14,426]\u001b[0m Trial 247 finished with value: 0.7662866122076412 and parameters: {'w0': 0.9190243278593538, 'w1': 0.041245115439574695, 'w2': 0.17231302059520892, 'w3': 0.08060949181991822, 'w4': 0.7009488539627801}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:14,577]\u001b[0m Trial 248 finished with value: 0.7665660528088403 and parameters: {'w0': 0.9041281283881225, 'w1': 0.0013888587319106395, 'w2': 0.13940614460964315, 'w3': 0.12790240109199008, 'w4': 0.0001160442655724174}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:14,724]\u001b[0m Trial 249 finished with value: 0.7664818374967018 and parameters: {'w0': 0.8934422887176332, 'w1': 2.9020604428277655e-05, 'w2': 0.15315781945028883, 'w3': 0.4476635318660077, 'w4': 0.002242466460121542}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:14,865]\u001b[0m Trial 250 finished with value: 0.7665343212075733 and parameters: {'w0': 0.8579234314619552, 'w1': 0.04937796793472575, 'w2': 0.13948374776337127, 'w3': 0.10142457686002097, 'w4': 0.00033136391962752863}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:15,004]\u001b[0m Trial 251 finished with value: 0.76629496079215 and parameters: {'w0': 0.8750933658745788, 'w1': 0.019124050777182877, 'w2': 0.03385987485344698, 'w3': 0.12061533162317237, 'w4': 0.9942643492183842}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:15,150]\u001b[0m Trial 252 finished with value: 0.7665454644307652 and parameters: {'w0': 0.9089357437154135, 'w1': 0.032529871009647646, 'w2': 0.059164704077848435, 'w3': 0.07108267409352487, 'w4': 0.019943594261615127}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:15,295]\u001b[0m Trial 253 finished with value: 0.7665093146634395 and parameters: {'w0': 0.896992545128186, 'w1': 0.017861943948139766, 'w2': 0.19515226991485146, 'w3': 0.09410573215469273, 'w4': 0.049480002902195105}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:15,442]\u001b[0m Trial 254 finished with value: 0.7665471905057828 and parameters: {'w0': 0.8556081176264514, 'w1': 0.04937347931396115, 'w2': 0.07145018647117263, 'w3': 0.13791159303424674, 'w4': 0.021617459373117615}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:15,588]\u001b[0m Trial 255 finished with value: 0.7665434164940306 and parameters: {'w0': 0.9229765815417095, 'w1': 0.0187242694022513, 'w2': 0.1057451366204928, 'w3': 0.11512610746372388, 'w4': 0.040646533160749954}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:18:15,733]\u001b[0m Trial 256 finished with value: 0.7665452265891752 and parameters: {'w0': 0.8726502282882114, 'w1': 0.00017484727488389538, 'w2': 0.05172765737666728, 'w3': 0.16904492801248291, 'w4': 0.017570343737448837}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:15,877]\u001b[0m Trial 257 finished with value: 0.7665248596795371 and parameters: {'w0': 0.8455575035631082, 'w1': 0.03493421849655157, 'w2': 0.08451623284677674, 'w3': 0.04399800888126212, 'w4': 0.0008433642345295629}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:16,020]\u001b[0m Trial 258 finished with value: 0.7664496741612441 and parameters: {'w0': 0.8968516638133095, 'w1': 0.355428824512679, 'w2': 0.1280246488510402, 'w3': 0.1451889569563529, 'w4': 0.033491903670373135}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:16,161]\u001b[0m Trial 259 finished with value: 0.7663930471809345 and parameters: {'w0': 0.5622597771178216, 'w1': 0.01937364121661652, 'w2': 0.03257602987499069, 'w3': 0.7058156503488214, 'w4': 0.0005708624883469402}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:16,304]\u001b[0m Trial 260 finished with value: 0.7664912240529325 and parameters: {'w0': 0.9631345390734005, 'w1': 0.06382798160280062, 'w2': 0.14744768988835572, 'w3': 0.0843784164167962, 'w4': 0.059278023107439695}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:16,446]\u001b[0m Trial 261 finished with value: 0.7665433010202151 and parameters: {'w0': 0.9236455277097484, 'w1': 0.0002417630350364537, 'w2': 0.17693780183719304, 'w3': 0.10909460207707998, 'w4': 0.01954375064183956}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:16,590]\u001b[0m Trial 262 finished with value: 0.7665112010230071 and parameters: {'w0': 0.9387341930951414, 'w1': 0.04023446359706055, 'w2': 0.1049234135549335, 'w3': 0.0648785306019669, 'w4': 0.03571101684432247}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:16,728]\u001b[0m Trial 263 finished with value: 0.766555501604389 and parameters: {'w0': 0.9079036013081581, 'w1': 0.00012691410656674382, 'w2': 0.07621907619561721, 'w3': 0.16247220822047503, 'w4': 0.019723526149357313}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:16,869]\u001b[0m Trial 264 finished with value: 0.7664405202761344 and parameters: {'w0': 0.18197829372227148, 'w1': 0.03007064959475674, 'w2': 0.5748102396849848, 'w3': 0.12708668821375046, 'w4': 0.00021104497111353705}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:17,005]\u001b[0m Trial 265 finished with value: 0.7665447879610254 and parameters: {'w0': 0.8748020648901461, 'w1': 0.01877793697961618, 'w2': 0.06189737180030766, 'w3': 0.10001272247297582, 'w4': 0.04905444084482621}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:17,144]\u001b[0m Trial 266 finished with value: 0.7665444023301865 and parameters: {'w0': 0.970478712995096, 'w1': 0.05625840283136866, 'w2': 0.09028844947223315, 'w3': 0.18466386750333036, 'w4': 0.01864129469733299}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:17,280]\u001b[0m Trial 267 finished with value: 0.7665613946468293 and parameters: {'w0': 0.9210722722299124, 'w1': 0.022206673180064862, 'w2': 0.1222684622628251, 'w3': 0.14556071625681274, 'w4': 0.0005098888541437759}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:17,422]\u001b[0m Trial 268 finished with value: 0.7665506409323285 and parameters: {'w0': 0.8875828546546132, 'w1': 0.03839398768586796, 'w2': 0.12203140028761086, 'w3': 0.12617867403169186, 'w4': 0.0014111950020549795}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:17,561]\u001b[0m Trial 269 finished with value: 0.7665395403655086 and parameters: {'w0': 0.8449598994711398, 'w1': 0.017554998686012253, 'w2': 0.14539562160007855, 'w3': 0.07984551997971394, 'w4': 0.00021705879045107738}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:17,699]\u001b[0m Trial 270 finished with value: 0.7665580933021501 and parameters: {'w0': 0.9184263149384064, 'w1': 1.988848007562885e-05, 'w2': 0.10899228045497705, 'w3': 0.15308836576912485, 'w4': 0.03563424229543661}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:17,838]\u001b[0m Trial 271 finished with value: 0.7665213553939358 and parameters: {'w0': 0.6121341744290751, 'w1': 0.05193765836206275, 'w2': 0.12868690392348653, 'w3': 0.11354937297567572, 'w4': 0.021001171510551364}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:17,975]\u001b[0m Trial 272 finished with value: 0.766530587697831 and parameters: {'w0': 0.8640695236907115, 'w1': 0.03182372189119356, 'w2': 0.021663800052854662, 'w3': 0.030708802592558065, 'w4': 0.018020763424990583}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:18,114]\u001b[0m Trial 273 finished with value: 0.7665307962400947 and parameters: {'w0': 0.8954565674361454, 'w1': 0.021230939445326526, 'w2': 0.16359846951217713, 'w3': 0.13773472927512348, 'w4': 0.05097506390484608}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:18,254]\u001b[0m Trial 274 finished with value: 0.7665271308081988 and parameters: {'w0': 0.9282186123148295, 'w1': 0.06730202650980607, 'w2': 0.0014918010326319155, 'w3': 0.0551744543743876, 'w4': 0.032541071868662}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:18,397]\u001b[0m Trial 275 finished with value: 0.7665754441046679 and parameters: {'w0': 0.91106560790598, 'w1': 0.0003240141927442089, 'w2': 0.04739305022041004, 'w3': 0.09153491444601863, 'w4': 0.020361599771903702}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:18,536]\u001b[0m Trial 276 finished with value: 0.7665294799247728 and parameters: {'w0': 0.9307717680018093, 'w1': 0.03757399211016903, 'w2': 0.04550494340783626, 'w3': 0.09234318666299116, 'w4': 0.06761604430756306}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:18,676]\u001b[0m Trial 277 finished with value: 0.7665375975616506 and parameters: {'w0': 0.9124995094778222, 'w1': 0.017788666255755408, 'w2': 0.06380462678756779, 'w3': 0.06572356961916802, 'w4': 0.04069313579324285}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:18,816]\u001b[0m Trial 278 finished with value: 0.7664012527157913 and parameters: {'w0': 0.9498659431511572, 'w1': 0.48688563186372463, 'w2': 0.044017463385428314, 'w3': 0.10088500140001766, 'w4': 0.01751492039023196}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:18,956]\u001b[0m Trial 279 finished with value: 0.7665527914167051 and parameters: {'w0': 0.8334542945288459, 'w1': 0.02082274701076118, 'w2': 0.07472917200520224, 'w3': 0.08898661967891779, 'w4': 0.019831213651347882}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:19,094]\u001b[0m Trial 280 finished with value: 0.7665358171967052 and parameters: {'w0': 0.6440280994053231, 'w1': 0.00013437954820821868, 'w2': 0.02791673338931694, 'w3': 0.1685241343423318, 'w4': 0.0002062402048957307}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:19,231]\u001b[0m Trial 281 finished with value: 0.7665279891061106 and parameters: {'w0': 0.8824771336898736, 'w1': 0.04869510862770468, 'w2': 0.09131160823684614, 'w3': 0.11750693168404666, 'w4': 0.05284704993340158}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:19,369]\u001b[0m Trial 282 finished with value: 0.7665436271906566 and parameters: {'w0': 0.9405726425133355, 'w1': 0.029801523058025296, 'w2': 0.053826452501430956, 'w3': 0.0762138989892983, 'w4': 0.033602856475171895}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:19,507]\u001b[0m Trial 283 finished with value: 0.7664805616833901 and parameters: {'w0': 0.8564322545425432, 'w1': 0.08091052272413055, 'w2': 0.10552178563206878, 'w3': 0.043954729456389605, 'w4': 0.0004618426056298389}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:18:19,646]\u001b[0m Trial 284 finished with value: 0.7665572539626258 and parameters: {'w0': 0.9101279555182705, 'w1': 0.018060124002262267, 'w2': 0.0794240060873209, 'w3': 0.150368807009717, 'w4': 0.01992681795091099}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:19,783]\u001b[0m Trial 285 finished with value: 0.766461098744143 and parameters: {'w0': 0.9620786189526174, 'w1': 6.902471615681359e-05, 'w2': 0.7516371848158181, 'w3': 0.18999417727750118, 'w4': 0.072107135584584}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:19,922]\u001b[0m Trial 286 finished with value: 0.7665074791468206 and parameters: {'w0': 0.31838120991987473, 'w1': 0.04419862738358525, 'w2': 0.11772725891484807, 'w3': 0.10998930873154437, 'w4': 0.03812088403182122}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:20,061]\u001b[0m Trial 287 finished with value: 0.7664588745805782 and parameters: {'w0': 0.8789937973550217, 'w1': 0.31351110410025435, 'w2': 0.09365759236520473, 'w3': 0.12818295032905994, 'w4': 0.01730061598671727}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:20,198]\u001b[0m Trial 288 finished with value: 0.7665430791209056 and parameters: {'w0': 0.9227696044454394, 'w1': 0.01916447825162522, 'w2': 0.05790602802377497, 'w3': 0.07159822669645902, 'w4': 0.03925764005918027}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:20,340]\u001b[0m Trial 289 finished with value: 0.7665430536994313 and parameters: {'w0': 0.94074017946078, 'w1': 0.06231848136974746, 'w2': 0.032474613659244624, 'w3': 0.16462149357631556, 'w4': 0.019075670604786432}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:20,482]\u001b[0m Trial 290 finished with value: 0.7664620647601664 and parameters: {'w0': 0.834654871982992, 'w1': 0.04007340372145022, 'w2': 0.34693372614117035, 'w3': 0.10032483516554244, 'w4': 0.054752150975745775}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:20,631]\u001b[0m Trial 291 finished with value: 0.7665695523548447 and parameters: {'w0': 0.9721260074126757, 'w1': 0.019635179043767666, 'w2': 0.07483939298004467, 'w3': 0.1396845866391797, 'w4': 0.00045065886946038086}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:20,778]\u001b[0m Trial 292 finished with value: 0.7665479479795425 and parameters: {'w0': 0.9830151077307873, 'w1': 0.033519318595462366, 'w2': 0.13550038387654673, 'w3': 0.14378316657247403, 'w4': 0.018748529145901284}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:20,924]\u001b[0m Trial 293 finished with value: 0.7663866922432321 and parameters: {'w0': 0.9700167416263429, 'w1': 0.6028636599850541, 'w2': 0.10519786277490761, 'w3': 0.12464607222524583, 'w4': 0.035544795548841185}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:21,074]\u001b[0m Trial 294 finished with value: 0.7663277342429908 and parameters: {'w0': 0.9624529954636956, 'w1': 0.7679486970181635, 'w2': 0.01203932176079374, 'w3': 0.17071956912290323, 'w4': 0.47611728758926797}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:21,216]\u001b[0m Trial 295 finished with value: 0.766468131875075 and parameters: {'w0': 0.9078898917647765, 'w1': 0.4263155324615564, 'w2': 0.06777874767194865, 'w3': 0.1985523493732595, 'w4': 0.0004890535330620574}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:21,359]\u001b[0m Trial 296 finished with value: 0.7664696244172271 and parameters: {'w0': 0.9478565692603989, 'w1': 0.019011332602711355, 'w2': 0.042646013397771375, 'w3': 0.14005082223142165, 'w4': 0.2831202898209884}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:21,497]\u001b[0m Trial 297 finished with value: 0.7663296718763793 and parameters: {'w0': 0.9871158399495624, 'w1': 0.8999106115672556, 'w2': 0.09127776299900807, 'w3': 0.11030998465973756, 'w4': 0.018869117710946202}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:21,637]\u001b[0m Trial 298 finished with value: 0.7664703310480382 and parameters: {'w0': 0.9297968837298997, 'w1': 0.04919455215166865, 'w2': 0.48976126737908093, 'w3': 0.15480418408188423, 'w4': 0.062111460778523524}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:21,774]\u001b[0m Trial 299 finished with value: 0.76642028262823 and parameters: {'w0': 0.8889706904077357, 'w1': 0.00030436748975471134, 'w2': 0.12046830847527593, 'w3': 0.12324051124163879, 'w4': 0.3823259684999371}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:21,911]\u001b[0m Trial 300 finished with value: 0.7664804362995082 and parameters: {'w0': 0.9141996379037394, 'w1': 0.017656706458730888, 'w2': 0.3850624737805797, 'w3': 0.0963666642663529, 'w4': 0.0005982913534906991}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:22,060]\u001b[0m Trial 301 finished with value: 0.7664778101319516 and parameters: {'w0': 0.09148765839660694, 'w1': 0.06673866791133967, 'w2': 0.07447616004804611, 'w3': 0.14887071668063126, 'w4': 0.03210580680236442}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:22,206]\u001b[0m Trial 302 finished with value: 0.7665610042763935 and parameters: {'w0': 0.8652304206762692, 'w1': 0.036713094391211065, 'w2': 0.051643354150150034, 'w3': 0.12993323486421687, 'w4': 0.0008798596359056983}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:22,355]\u001b[0m Trial 303 finished with value: 0.7665451210254259 and parameters: {'w0': 0.9568756052210038, 'w1': 0.023346702093702522, 'w2': 0.13818261841113674, 'w3': 0.18123080402670855, 'w4': 0.04703520973576297}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:22,516]\u001b[0m Trial 304 finished with value: 0.7664124859913244 and parameters: {'w0': 0.897660257273209, 'w1': 0.017031974020619775, 'w2': 0.5379003970306417, 'w3': 0.09026752699931209, 'w4': 0.08500179131754995}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:22,664]\u001b[0m Trial 305 finished with value: 0.7665625437836422 and parameters: {'w0': 0.9357212243725899, 'w1': 0.0014384745634209095, 'w2': 0.10405969289977388, 'w3': 0.11255132516043746, 'w4': 0.01984461237813835}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:22,809]\u001b[0m Trial 306 finished with value: 0.7665611089783978 and parameters: {'w0': 0.9773222882259376, 'w1': 0.0018233539298466769, 'w2': 0.09467112294304962, 'w3': 0.11544376017941116, 'w4': 0.029886526731031537}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:22,961]\u001b[0m Trial 307 finished with value: 0.7665605626321366 and parameters: {'w0': 0.9302201183313547, 'w1': 0.0004181424191024054, 'w2': 0.08609911602945684, 'w3': 0.07753062385566079, 'w4': 0.017790408176199247}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:23,107]\u001b[0m Trial 308 finished with value: 0.7665339618599536 and parameters: {'w0': 0.9455810119710264, 'w1': 0.04634962464969352, 'w2': 0.06436076259282973, 'w3': 0.10702688268718394, 'w4': 0.05206877770818923}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:23,246]\u001b[0m Trial 309 finished with value: 0.7663333920290758 and parameters: {'w0': 0.5152019058096362, 'w1': 0.6576000048871287, 'w2': 0.11139076415376709, 'w3': 0.09489071560691084, 'w4': 0.02261676353339079}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:23,385]\u001b[0m Trial 310 finished with value: 0.7665728812753606 and parameters: {'w0': 0.9661570446139129, 'w1': 0.0002720179492894251, 'w2': 0.02763821847018441, 'w3': 0.12036672115363686, 'w4': 0.03756820532458481}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:23,525]\u001b[0m Trial 311 finished with value: 0.7665403366177883 and parameters: {'w0': 0.9946069475942383, 'w1': 0.000310169899283516, 'w2': 0.015367490471963861, 'w3': 0.06208873405320037, 'w4': 0.07987912000990748}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:18:23,668]\u001b[0m Trial 312 finished with value: 0.7664938536674688 and parameters: {'w0': 0.9602021190078885, 'w1': 0.03102774840781218, 'w2': 0.03206295438705233, 'w3': 0.3945175369707498, 'w4': 0.048567403597846705}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:23,813]\u001b[0m Trial 313 finished with value: 0.7665659756826726 and parameters: {'w0': 0.972355742591436, 'w1': 0.017252049096762218, 'w2': 0.024057910831584834, 'w3': 0.12105955180399479, 'w4': 0.037749357480506354}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:23,953]\u001b[0m Trial 314 finished with value: 0.7663691005830171 and parameters: {'w0': 0.9753482935554137, 'w1': 0.017270416832136374, 'w2': 0.006533422379253695, 'w3': 0.12006452500035157, 'w4': 0.611041609380195}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:24,098]\u001b[0m Trial 315 finished with value: 0.7665501105283477 and parameters: {'w0': 0.9999522506969208, 'w1': 0.039387713734874895, 'w2': 0.019343397418998418, 'w3': 0.13254252325547863, 'w4': 0.05424302101965684}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:24,245]\u001b[0m Trial 316 finished with value: 0.7665543925387135 and parameters: {'w0': 0.9715739552429647, 'w1': 0.00018738372667083462, 'w2': 0.034308679772611095, 'w3': 0.11009543679606779, 'w4': 0.0713911392093263}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:24,396]\u001b[0m Trial 317 finished with value: 0.766563414576855 and parameters: {'w0': 0.9465868166958997, 'w1': 0.00042085817349744176, 'w2': 0.05357130773073514, 'w3': 0.08902071961120914, 'w4': 0.037087386705606566}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:24,545]\u001b[0m Trial 318 finished with value: 0.7665110347062429 and parameters: {'w0': 0.44176441222168067, 'w1': 0.05732174694821229, 'w2': 0.05309297600815691, 'w3': 0.0836564998650908, 'w4': 0.034064202089429715}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:24,692]\u001b[0m Trial 319 finished with value: 0.7665412431734142 and parameters: {'w0': 0.966961481845508, 'w1': 0.03163361561004603, 'w2': 0.023920318057598106, 'w3': 0.09662397639709575, 'w4': 0.06606606602064045}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:24,834]\u001b[0m Trial 320 finished with value: 0.7663837588636213 and parameters: {'w0': 0.9817957167137437, 'w1': 0.0910372893504475, 'w2': 0.8450643896080514, 'w3': 0.10768290558053553, 'w4': 0.03279337363727319}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:24,980]\u001b[0m Trial 321 finished with value: 0.7665674242758351 and parameters: {'w0': 0.9546690017394274, 'w1': 0.01790518555724696, 'w2': 0.047508575038127505, 'w3': 0.12729144238339374, 'w4': 0.021183563468583404}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:25,125]\u001b[0m Trial 322 finished with value: 0.7663997528488076 and parameters: {'w0': 0.9570199925874803, 'w1': 0.056940900947053216, 'w2': 0.04684516258017703, 'w3': 0.8038145028400288, 'w4': 0.04458672968337672}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:25,273]\u001b[0m Trial 323 finished with value: 0.7665651634881123 and parameters: {'w0': 0.9096352331886107, 'w1': 0.019501482383599285, 'w2': 0.00795733697540061, 'w3': 0.12778943277566912, 'w4': 0.01865909325261411}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:25,420]\u001b[0m Trial 324 finished with value: 0.7665205664664877 and parameters: {'w0': 0.9490691286392613, 'w1': 0.03663904093190491, 'w2': 0.0021167137424957863, 'w3': 0.08074185274557008, 'w4': 0.10218368944064216}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:25,568]\u001b[0m Trial 325 finished with value: 0.766531000473634 and parameters: {'w0': 0.9190419640133415, 'w1': 0.07442620070647571, 'w2': 0.01887882728530005, 'w3': 0.13351529801199102, 'w4': 0.06769824830905564}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:25,712]\u001b[0m Trial 326 finished with value: 0.766553722101188 and parameters: {'w0': 0.9831127978253567, 'w1': 0.021477842520704612, 'w2': 0.030241406609714035, 'w3': 0.1555550268449518, 'w4': 0.040273369795396516}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:25,851]\u001b[0m Trial 327 finished with value: 0.7665515035389647 and parameters: {'w0': 0.9437588240080891, 'w1': 0.03857070677196004, 'w2': 0.04430661739711694, 'w3': 0.08650747521726726, 'w4': 0.02382911002698523}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:25,991]\u001b[0m Trial 328 finished with value: 0.7665569670015768 and parameters: {'w0': 0.8797427754437077, 'w1': 0.019129621296356165, 'w2': 0.0024046800856054734, 'w3': 0.13583484127290682, 'w4': 0.018778512550223385}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:26,130]\u001b[0m Trial 329 finished with value: 0.7665338985217041 and parameters: {'w0': 0.9628496911975529, 'w1': 0.054208804290231394, 'w2': 0.056503080347316166, 'w3': 0.11117730963067912, 'w4': 0.05178530083626673}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:26,270]\u001b[0m Trial 330 finished with value: 0.7665435246430146 and parameters: {'w0': 0.9089035398268055, 'w1': 0.019399003794265623, 'w2': 0.0318447825222756, 'w3': 0.16804904529528072, 'w4': 0.01871142447795099}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:26,412]\u001b[0m Trial 331 finished with value: 0.7665297354321332 and parameters: {'w0': 0.927303518269648, 'w1': 0.035698169124849174, 'w2': 0.06393666213806787, 'w3': 0.12406014147916741, 'w4': 0.08536316423099781}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:26,551]\u001b[0m Trial 332 finished with value: 0.7665607048200438 and parameters: {'w0': 0.8886191677858256, 'w1': 0.016665893713276696, 'w2': 0.027248159476960306, 'w3': 0.09850051693636852, 'w4': 0.03963331803957004}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:26,695]\u001b[0m Trial 333 finished with value: 0.7665716722472777 and parameters: {'w0': 0.8654907099247503, 'w1': 0.0008299396336741032, 'w2': 0.07266950554862198, 'w3': 0.06728549819577481, 'w4': 0.00014407762292326294}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:26,837]\u001b[0m Trial 334 finished with value: 0.7664030865089203 and parameters: {'w0': 0.8575750137481198, 'w1': 0.0004026811602952825, 'w2': 0.0026320416683493914, 'w3': 0.06947324522963008, 'w4': 0.32207787886281625}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:26,976]\u001b[0m Trial 335 finished with value: 0.7664182122861283 and parameters: {'w0': 0.8692643209635439, 'w1': 0.22537900811241554, 'w2': 0.0738863100319079, 'w3': 0.04977472194725404, 'w4': 0.001470997440610662}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:27,115]\u001b[0m Trial 336 finished with value: 0.7665537660501776 and parameters: {'w0': 0.9973948012233572, 'w1': 0.0002792605828841756, 'w2': 0.04841280778051223, 'w3': 0.02573274526811356, 'w4': 0.0006310653592097556}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:27,255]\u001b[0m Trial 337 finished with value: 0.7665506008611909 and parameters: {'w0': 0.9624361793790023, 'w1': 0.03609863465101847, 'w2': 0.037838469994076876, 'w3': 0.07015280218870984, 'w4': 0.020458991599614302}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:27,401]\u001b[0m Trial 338 finished with value: 0.7665464666400742 and parameters: {'w0': 0.9488190753807546, 'w1': 0.017313071849373612, 'w2': 0.07413928532950555, 'w3': 0.08667473125558559, 'w4': 0.03811746621433555}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:27,549]\u001b[0m Trial 339 finished with value: 0.7664976819691494 and parameters: {'w0': 0.8484892327420004, 'w1': 0.05476247870476786, 'w2': 0.08227133832207043, 'w3': 0.044348371109585755, 'w4': 0.016882877002720356}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:18:27,698]\u001b[0m Trial 340 finished with value: 0.7665671687684747 and parameters: {'w0': 0.9224005390101417, 'w1': 0.0006763787739213435, 'w2': 0.018776748879848797, 'w3': 0.14636104333348665, 'w4': 0.000135360215965526}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:27,844]\u001b[0m Trial 341 finished with value: 0.7665471306145129 and parameters: {'w0': 0.97658602070767, 'w1': 0.032762509688673266, 'w2': 0.0012660491054955585, 'w3': 0.1516619438532634, 'w4': 0.055285903741701836}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:27,987]\u001b[0m Trial 342 finished with value: 0.7665420519209949 and parameters: {'w0': 0.9333113757163932, 'w1': 0.000222761997050909, 'w2': 0.02816535896481416, 'w3': 0.17876507666547406, 'w4': 0.036298498476678924}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:28,132]\u001b[0m Trial 343 finished with value: 0.7665758693757717 and parameters: {'w0': 0.9513134204773998, 'w1': 0.01998050811515958, 'w2': 0.020610067292599052, 'w3': 0.1006570159956832, 'w4': 0.01811902112413925}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:28,281]\u001b[0m Trial 344 finished with value: 0.7665395877614778 and parameters: {'w0': 0.8816660080608087, 'w1': 0.07796279828278843, 'w2': 0.017565186279127953, 'w3': 0.15001716438946736, 'w4': 0.017760644686680264}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:28,433]\u001b[0m Trial 345 finished with value: 0.7665616363662714 and parameters: {'w0': 0.9201510410419544, 'w1': 0.047832024456922, 'w2': 0.012291637062733033, 'w3': 0.10556468107646035, 'w4': 0.01714469566798018}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:28,577]\u001b[0m Trial 346 finished with value: 0.7665086377628273 and parameters: {'w0': 0.673541972939335, 'w1': 0.022099471751789324, 'w2': 0.036825473946921886, 'w3': 0.20738075178892557, 'w4': 0.016565036348774237}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:28,722]\u001b[0m Trial 347 finished with value: 0.7665433975356429 and parameters: {'w0': 0.822592094859259, 'w1': 0.0681635315158874, 'w2': 0.04154819373524061, 'w3': 0.13166037338890765, 'w4': 0.017089975176777364}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:28,867]\u001b[0m Trial 348 finished with value: 0.766567219180551 and parameters: {'w0': 0.9744330540495648, 'w1': 0.03558724586599228, 'w2': 0.02126614811999862, 'w3': 0.06757027479611788, 'w4': 2.670987333003305e-06}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:29,013]\u001b[0m Trial 349 finished with value: 0.7665282657262209 and parameters: {'w0': 0.9782194326021144, 'w1': 0.10273158546099706, 'w2': 0.017953078795919328, 'w3': 0.06511974981789598, 'w4': 0.0004837510824621978}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:29,161]\u001b[0m Trial 350 finished with value: 0.7665619198803406 and parameters: {'w0': 0.9706312936576148, 'w1': 0.04921157940437982, 'w2': 0.0029423607652051646, 'w3': 0.056081035403929516, 'w4': 0.00038844103486322115}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:29,304]\u001b[0m Trial 351 finished with value: 0.7665370693120324 and parameters: {'w0': 0.9919107317068863, 'w1': 0.03135794998382547, 'w2': 0.023874643343378438, 'w3': 0.07854817294998662, 'w4': 0.06352542872888384}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:29,445]\u001b[0m Trial 352 finished with value: 0.7665559126567022 and parameters: {'w0': 0.9571213323472856, 'w1': 0.020318672611809446, 'w2': 0.05561174571786374, 'w3': 0.10008203385717473, 'w4': 0.03524961213218296}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:29,600]\u001b[0m Trial 353 finished with value: 0.7662482873962094 and parameters: {'w0': 0.9993578947468121, 'w1': 0.03785845060306239, 'w2': 0.0008317276424353315, 'w3': 0.06704376251013743, 'w4': 0.9341741085308999}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:29,742]\u001b[0m Trial 354 finished with value: 0.7665445005691041 and parameters: {'w0': 0.9380127289991392, 'w1': 0.06234298869364831, 'w2': 0.027799860031780532, 'w3': 0.11152703083246177, 'w4': 0.03264264085908762}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:29,884]\u001b[0m Trial 355 finished with value: 0.7665659420746218 and parameters: {'w0': 0.9597861638109533, 'w1': 0.01945330058525505, 'w2': 0.043137525781297224, 'w3': 0.09019718524008266, 'w4': 0.019359253672473323}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:30,032]\u001b[0m Trial 356 finished with value: 0.7662827511596548 and parameters: {'w0': 0.9791178103507815, 'w1': 0.018678425561738765, 'w2': 0.04090196693442847, 'w3': 0.03188178800037762, 'w4': 0.4366879808841795}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:30,189]\u001b[0m Trial 357 finished with value: 0.7664301353884468 and parameters: {'w0': 0.9505638365762368, 'w1': 0.044753068411904684, 'w2': 0.01971168802703223, 'w3': 0.01417891907845463, 'w4': 0.05454587186818544}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:30,337]\u001b[0m Trial 358 finished with value: 0.7665514337376287 and parameters: {'w0': 0.965105688920909, 'w1': 0.019955749230937788, 'w2': 0.05751025852640854, 'w3': 0.08328930324801953, 'w4': 0.03411812924149091}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:30,490]\u001b[0m Trial 359 finished with value: 0.7664592210020247 and parameters: {'w0': 0.9047905720307101, 'w1': 0.035091239411150964, 'w2': 0.03733250001655904, 'w3': 0.48807139246567055, 'w4': 0.019781264119364227}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:30,649]\u001b[0m Trial 360 finished with value: 0.7663842211897557 and parameters: {'w0': 0.92881614431938, 'w1': 0.017086994312008812, 'w2': 0.43844419874181295, 'w3': 0.047675442292264836, 'w4': 0.05145563879180328}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:30,798]\u001b[0m Trial 361 finished with value: 0.7665188024746948 and parameters: {'w0': 0.47353445514976056, 'w1': 0.054797618154105554, 'w2': 0.01775778469697027, 'w3': 0.11254929628010683, 'w4': 0.01823857550765978}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:30,951]\u001b[0m Trial 362 finished with value: 0.7665481207593932 and parameters: {'w0': 0.9610148969882835, 'w1': 0.00019289811053703856, 'w2': 0.06074334352641955, 'w3': 0.16664970675445873, 'w4': 0.0722667496975958}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:31,099]\u001b[0m Trial 363 finished with value: 0.7665178735137018 and parameters: {'w0': 0.8907154816543087, 'w1': 0.03331680768245194, 'w2': 0.9556245630088642, 'w3': 0.665210377278794, 'w4': 0.03832499106672147}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:31,242]\u001b[0m Trial 364 finished with value: 0.7665484072895697 and parameters: {'w0': 0.9180354234480596, 'w1': 0.07723471640096902, 'w2': 0.04237167563918795, 'w3': 0.14321103497939625, 'w4': 0.001553525145097156}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:31,383]\u001b[0m Trial 365 finished with value: 0.7665705106151639 and parameters: {'w0': 0.976914788814414, 'w1': 0.0175485878928638, 'w2': 0.06887450839489882, 'w3': 0.09759756812315692, 'w4': 0.00045600171442466866}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:31,523]\u001b[0m Trial 366 finished with value: 0.7662457396474376 and parameters: {'w0': 0.9858341700110532, 'w1': 0.052602617652605786, 'w2': 0.6667002449757145, 'w3': 0.07127995850131984, 'w4': 0.856696788377703}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:31,669]\u001b[0m Trial 367 finished with value: 0.7665595914456439 and parameters: {'w0': 0.9726469411069693, 'w1': 0.01882638223458909, 'w2': 0.06752082476529762, 'w3': 0.0965771372010652, 'w4': 0.02315878225663499}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:18:31,819]\u001b[0m Trial 368 finished with value: 0.7665503121766524 and parameters: {'w0': 0.9859572572099115, 'w1': 0.037770569754954415, 'w2': 0.020904263695726136, 'w3': 0.11454893935324074, 'w4': 0.05119970680898559}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:31,961]\u001b[0m Trial 369 finished with value: 0.7665929620856945 and parameters: {'w0': 0.9544368867338289, 'w1': 0.017833990046807965, 'w2': 0.0005042374447948791, 'w3': 0.08805206534306662, 'w4': 0.0005008913368045472}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:32,106]\u001b[0m Trial 370 finished with value: 0.7664790618164063 and parameters: {'w0': 0.9579022149177863, 'w1': 0.018241401969436875, 'w2': 0.0010205373739665055, 'w3': 0.5579179781715612, 'w4': 0.2428873875927624}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:32,257]\u001b[0m Trial 371 finished with value: 0.7662676055623143 and parameters: {'w0': 0.9982376994818457, 'w1': 0.08371441451717557, 'w2': 0.03435533379874267, 'w3': 0.06053380428108582, 'w4': 0.6902023319535096}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:32,407]\u001b[0m Trial 372 finished with value: 0.7665459370978382 and parameters: {'w0': 0.9418335244621753, 'w1': 0.05955074700708157, 'w2': 0.019879344144113822, 'w3': 0.08171216672383785, 'w4': 0.020787640942477828}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:32,556]\u001b[0m Trial 373 finished with value: 0.7664361413194682 and parameters: {'w0': 0.01692715027274605, 'w1': 0.031404369414660765, 'w2': 0.04687360853881617, 'w3': 0.04084749564502586, 'w4': 0.03856104261956381}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:32,703]\u001b[0m Trial 374 finished with value: 0.7665804861740279 and parameters: {'w0': 0.9667990399834807, 'w1': 0.01993862113188207, 'w2': 0.0028681361656492134, 'w3': 0.09455219850041567, 'w4': 0.021004617759821754}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:32,849]\u001b[0m Trial 375 finished with value: 0.7665115293478107 and parameters: {'w0': 0.9660385896293542, 'w1': 0.042499548027244524, 'w2': 0.021096570530101715, 'w3': 0.06394301386830165, 'w4': 0.08127762831879629}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:32,993]\u001b[0m Trial 376 finished with value: 0.7665775751997844 and parameters: {'w0': 0.9722894423148082, 'w1': 0.017210034851067736, 'w2': 0.04095198325463624, 'w3': 0.09138140669134595, 'w4': 0.0009057890879228016}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:33,140]\u001b[0m Trial 377 finished with value: 0.7664384081394053 and parameters: {'w0': 0.9819377519828892, 'w1': 0.0648519892307272, 'w2': 0.32000719642443076, 'w3': 0.9369075220334523, 'w4': 0.0006081017959366224}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:33,281]\u001b[0m Trial 378 finished with value: 0.7665484680425844 and parameters: {'w0': 0.9992045174870494, 'w1': 0.038347835635217764, 'w2': 0.042301501826865394, 'w3': 0.09481475978376896, 'w4': 0.036963772328277245}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:33,422]\u001b[0m Trial 379 finished with value: 0.766402952938462 and parameters: {'w0': 0.9676506364473804, 'w1': 0.388199873360604, 'w2': 0.019839669007838755, 'w3': 0.08461332622718948, 'w4': 0.05895652315333423}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:33,563]\u001b[0m Trial 380 finished with value: 0.7665636735311949 and parameters: {'w0': 0.9547420755625774, 'w1': 1.5587627043083105e-05, 'w2': 0.05292745475168366, 'w3': 0.052554404189333076, 'w4': 0.0196191768148385}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:33,702]\u001b[0m Trial 381 finished with value: 0.7664907195012984 and parameters: {'w0': 0.23251928354568635, 'w1': 0.018479731328661285, 'w2': 0.004760158047559904, 'w3': 0.09640128036717402, 'w4': 0.032824717427627166}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:33,845]\u001b[0m Trial 382 finished with value: 0.7665657369793376 and parameters: {'w0': 0.9735465033881637, 'w1': 0.048959632613764015, 'w2': 0.03392262741404278, 'w3': 0.10822885552200515, 'w4': 0.0006953682010412447}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:33,986]\u001b[0m Trial 383 finished with value: 0.766540959659345 and parameters: {'w0': 0.9779899617846546, 'w1': 0.0764056206364159, 'w2': 0.030364999117288113, 'w3': 0.06787594405555458, 'w4': 2.9018691034254394e-05}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:34,128]\u001b[0m Trial 384 finished with value: 0.7665573681438239 and parameters: {'w0': 0.9755173930592933, 'w1': 0.057668095074309034, 'w2': 0.0018508758208450396, 'w3': 0.10372261735758093, 'w4': 0.0212373523938814}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:34,268]\u001b[0m Trial 385 finished with value: 0.7664173548499611 and parameters: {'w0': 0.9487055312546575, 'w1': 0.09747357748203334, 'w2': 0.05658256255598055, 'w3': 0.02977873837314239, 'w4': 0.06156519131352613}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:34,414]\u001b[0m Trial 386 finished with value: 0.766533775723057 and parameters: {'w0': 0.9664113439468848, 'w1': 0.04627032497970912, 'w2': 0.035505352442137005, 'w3': 0.07491394302376599, 'w4': 0.04462794769290716}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:34,557]\u001b[0m Trial 387 finished with value: 0.7665756836697476 and parameters: {'w0': 0.9946746548038315, 'w1': 0.03252553430813625, 'w2': 0.0003572173672316131, 'w3': 0.10643178783686502, 'w4': 0.01860305294448293}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:34,699]\u001b[0m Trial 388 finished with value: 0.7665502376357193 and parameters: {'w0': 0.9962579764633326, 'w1': 0.06220425109531684, 'w2': 0.0003029937372155782, 'w3': 0.10080562676890426, 'w4': 0.03196782682496564}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:34,841]\u001b[0m Trial 389 finished with value: 0.7665598055892495 and parameters: {'w0': 0.9987419290278798, 'w1': 0.035033863843123667, 'w2': 0.019363159714213648, 'w3': 0.07793335735524068, 'w4': 0.02076278988295598}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:34,984]\u001b[0m Trial 390 finished with value: 0.7662759175226652 and parameters: {'w0': 0.9803568363276886, 'w1': 0.6952357259292756, 'w2': 0.03513819243186453, 'w3': 0.04605363309413074, 'w4': 0.0953041661524063}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:35,123]\u001b[0m Trial 391 finished with value: 0.7665255348566595 and parameters: {'w0': 0.9775844349490816, 'w1': 0.08530755305065305, 'w2': 0.03496908071936833, 'w3': 0.11228824980235524, 'w4': 0.053207425858672455}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:35,264]\u001b[0m Trial 392 finished with value: 0.7665069103951923 and parameters: {'w0': 0.4022317183977792, 'w1': 0.048795775208465834, 'w2': 0.0027339893521161123, 'w3': 0.09219370830761277, 'w4': 0.074318518532797}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:35,404]\u001b[0m Trial 393 finished with value: 0.7665639367942592 and parameters: {'w0': 0.9995246479810798, 'w1': 0.03064996845269732, 'w2': 0.0003315290714261531, 'w3': 0.06229439659500133, 'w4': 0.021346979198074826}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:35,545]\u001b[0m Trial 394 finished with value: 0.7665544278702541 and parameters: {'w0': 0.9569591455181088, 'w1': 0.01974099817621517, 'w2': 0.06040948479510494, 'w3': 0.11533089752375261, 'w4': 0.041186716183750714}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:35,692]\u001b[0m Trial 395 finished with value: 0.7665497684156258 and parameters: {'w0': 0.9619456248413522, 'w1': 0.0649960505160783, 'w2': 0.020487463058685595, 'w3': 0.09419332675297026, 'w4': 0.0168497276362808}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:18:35,832]\u001b[0m Trial 396 finished with value: 0.7665689469790583 and parameters: {'w0': 0.9435435051907168, 'w1': 0.03523037907161195, 'w2': 0.05237421664503096, 'w3': 0.11580977324613678, 'w4': 0.00022496586269643093}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:35,976]\u001b[0m Trial 397 finished with value: 0.7665500889847254 and parameters: {'w0': 0.9483797386383408, 'w1': 0.020208875613771993, 'w2': 0.05746652171744574, 'w3': 0.08158108157431038, 'w4': 0.0349899877886103}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:36,117]\u001b[0m Trial 398 finished with value: 0.7665530516636623 and parameters: {'w0': 0.9358392501440415, 'w1': 0.038505964762151484, 'w2': 0.07389391660450424, 'w3': 0.1195792153814356, 'w4': 0.019209909004768235}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:36,259]\u001b[0m Trial 399 finished with value: 0.7665218737334882 and parameters: {'w0': 0.9397080634604259, 'w1': 0.021843709712787523, 'w2': 0.04885924370845115, 'w3': 0.053450478216567475, 'w4': 0.054595057174129186}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:36,410]\u001b[0m Trial 400 finished with value: 0.766356077032472 and parameters: {'w0': 0.5875470017051432, 'w1': 0.8181619917357483, 'w2': 0.021683829943770033, 'w3': 0.13268788539776294, 'w4': 0.018529763263505142}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:36,555]\u001b[0m Trial 401 finished with value: 0.7665652182089129 and parameters: {'w0': 0.9571051561920919, 'w1': 0.017254165008498277, 'w2': 0.07405529889408317, 'w3': 0.08132513422325996, 'w4': 0.0002787789134492953}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:36,698]\u001b[0m Trial 402 finished with value: 0.7665500687337206 and parameters: {'w0': 0.9780803244987989, 'w1': 0.03533432628277454, 'w2': 0.03833575174410872, 'w3': 0.10369971514344666, 'w4': 0.0422676339290821}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:36,846]\u001b[0m Trial 403 finished with value: 0.766194015564688 and parameters: {'w0': 0.93468325521669, 'w1': 0.554456065997555, 'w2': 0.05289841234398564, 'w3': 0.02225146235932464, 'w4': 0.5530062137255193}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:36,996]\u001b[0m Trial 404 finished with value: 0.7665497408397892 and parameters: {'w0': 0.9474920981283417, 'w1': 0.0008537698883232895, 'w2': 0.07403537655935065, 'w3': 0.1246268824286573, 'w4': 0.06558652417071137}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:37,141]\u001b[0m Trial 405 finished with value: 0.7665463442722994 and parameters: {'w0': 0.9791382291736375, 'w1': 0.073282183212112, 'w2': 0.022874986707879137, 'w3': 0.07248297218235733, 'w4': 4.67875463442672e-05}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:37,282]\u001b[0m Trial 406 finished with value: 0.7665600964281503 and parameters: {'w0': 0.9633825001312459, 'w1': 0.016667065374265173, 'w2': 0.046314375279334734, 'w3': 0.13870313796790504, 'w4': 0.03580664013853943}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:37,434]\u001b[0m Trial 407 finished with value: 0.7665298017864899 and parameters: {'w0': 0.9300874664362191, 'w1': 0.11141501435943219, 'w2': 0.0014210294539767868, 'w3': 0.0967853998717726, 'w4': 0.020221817391971084}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:37,578]\u001b[0m Trial 408 finished with value: 0.7664333376324637 and parameters: {'w0': 0.9991899163181077, 'w1': 0.048701203523991266, 'w2': 0.6138068255637744, 'w3': 0.11373940964334216, 'w4': 0.028082625138438046}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:37,730]\u001b[0m Trial 409 finished with value: 0.7665420618310612 and parameters: {'w0': 0.9520167754205305, 'w1': 0.032970730985949784, 'w2': 0.08609979427132994, 'w3': 0.058153988502283684, 'w4': 0.0003049377122021574}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:37,883]\u001b[0m Trial 410 finished with value: 0.7665556472392755 and parameters: {'w0': 0.9228580704030189, 'w1': 0.01618373196283895, 'w2': 0.02286986354929465, 'w3': 0.09213878697324081, 'w4': 0.04993272174103153}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:38,039]\u001b[0m Trial 411 finished with value: 0.7665044725188942 and parameters: {'w0': 0.9704416135098286, 'w1': 0.053408563406398324, 'w2': 0.05572715391978907, 'w3': 0.03953473667149204, 'w4': 0.02104578640818827}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:38,194]\u001b[0m Trial 412 finished with value: 0.7665417356606197 and parameters: {'w0': 0.943061359340516, 'w1': 0.018813437292604922, 'w2': 0.0709818197251465, 'w3': 0.14474495464196094, 'w4': 0.0769955832052946}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:38,345]\u001b[0m Trial 413 finished with value: 0.766326057287432 and parameters: {'w0': 0.9599543763718794, 'w1': 0.9963512513393303, 'w2': 0.04136621622391387, 'w3': 0.12014031696885677, 'w4': 0.034613678033514665}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:38,500]\u001b[0m Trial 414 finished with value: 0.7665716519962726 and parameters: {'w0': 0.9823467029326534, 'w1': 0.03204959964571618, 'w2': 0.020350764143668487, 'w3': 0.07873540798353096, 'w4': 0.0004253924876376584}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:38,648]\u001b[0m Trial 415 finished with value: 0.7664253354694013 and parameters: {'w0': 0.9849678590219831, 'w1': 0.06481234661738781, 'w2': 0.022108886770156724, 'w3': 0.004521745618821876, 'w4': 0.0002954074582038694}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:38,801]\u001b[0m Trial 416 finished with value: 0.7665665797658415 and parameters: {'w0': 0.9840907089300253, 'w1': 0.03804461647554644, 'w2': 0.020439273216569527, 'w3': 0.0714006437152575, 'w4': 0.00023768799462978228}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:38,957]\u001b[0m Trial 417 finished with value: 0.7665337240183635 and parameters: {'w0': 0.9898098506731783, 'w1': 0.04303127482253315, 'w2': 0.018036086198488725, 'w3': 0.03783694439188144, 'w4': 0.019412723584338962}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:39,103]\u001b[0m Trial 418 finished with value: 0.7662737502342631 and parameters: {'w0': 0.9973647200096694, 'w1': 0.0814474015889367, 'w2': 0.0011551002869637991, 'w3': 0.07001045065214477, 'w4': 0.7418373968666508}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:39,255]\u001b[0m Trial 419 finished with value: 0.7665696729991296 and parameters: {'w0': 0.9160580590983721, 'w1': 0.0008697788135747848, 'w2': 0.06728575196035208, 'w3': 0.05444341358002779, 'w4': 0.0012946976295527077}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:39,413]\u001b[0m Trial 420 finished with value: 0.7664768225723058 and parameters: {'w0': 0.9211076691351349, 'w1': 0.03785805512200637, 'w2': 0.060786930822309564, 'w3': 0.021511384983109866, 'w4': 0.014833779932691228}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:39,558]\u001b[0m Trial 421 finished with value: 0.7665814009162303 and parameters: {'w0': 0.9312584848238031, 'w1': 9.458454399909372e-05, 'w2': 0.03747610581806882, 'w3': 0.04986458302590021, 'w4': 0.0007817136739762375}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:39,715]\u001b[0m Trial 422 finished with value: 0.7665319992359632 and parameters: {'w0': 0.9379770522057791, 'w1': 0.054532452656222294, 'w2': 0.03854403125983793, 'w3': 0.05341703356995642, 'w4': 0.01510815396956012}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:39,861]\u001b[0m Trial 423 finished with value: 0.766541134593558 and parameters: {'w0': 0.9743239471672673, 'w1': 0.03268468281497585, 'w2': 0.0012357819903237276, 'w3': 0.028328216767254957, 'w4': 0.017703826545671663}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:18:40,006]\u001b[0m Trial 424 finished with value: 0.7665871474620393 and parameters: {'w0': 0.9477779357256395, 'w1': 0.0013988826840655993, 'w2': 0.022243373553700374, 'w3': 0.0419647335169044, 'w4': 0.0015955415752602964}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:40,154]\u001b[0m Trial 425 finished with value: 0.7665710655788742 and parameters: {'w0': 0.9234804528962317, 'w1': 0.002215760028698578, 'w2': 0.04401899015668059, 'w3': 0.037067584038303736, 'w4': 0.0008287757862863385}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:40,308]\u001b[0m Trial 426 finished with value: 0.7664989211583032 and parameters: {'w0': 0.9427935501171689, 'w1': 4.1246213473888514e-05, 'w2': 0.06323059468734751, 'w3': 0.02436261332486463, 'w4': 0.037320146244471275}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:40,462]\u001b[0m Trial 427 finished with value: 0.766452296450949 and parameters: {'w0': 0.915929906166286, 'w1': 0.019801728997485092, 'w2': 0.043329252177150744, 'w3': 0.008739314129398969, 'w4': 0.01967196412616471}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:40,603]\u001b[0m Trial 428 finished with value: 0.7665029321499007 and parameters: {'w0': 0.9320108361470192, 'w1': 0.016321745137295247, 'w2': 0.07109073374004898, 'w3': 0.04112537734547838, 'w4': 0.050180946627630216}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:40,744]\u001b[0m Trial 429 finished with value: 0.7665513505792466 and parameters: {'w0': 0.9524348588746712, 'w1': 0.000149010140937282, 'w2': 0.043027689694876935, 'w3': 0.041697543811847766, 'w4': 0.029830218472141935}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:40,889]\u001b[0m Trial 430 finished with value: 0.7664469170084638 and parameters: {'w0': 0.9582701031019043, 'w1': 0.030224950417278042, 'w2': 0.08537234706137717, 'w3': 0.01609773009759071, 'w4': 0.018902874909350328}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:41,032]\u001b[0m Trial 431 finished with value: 0.7664331730391896 and parameters: {'w0': 0.9311466723102518, 'w1': 0.016763737324365514, 'w2': 0.06117735077116246, 'w3': 0.0022653106748232593, 'w4': 0.00037876265155900937}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:41,183]\u001b[0m Trial 432 finished with value: 0.7665024284600117 and parameters: {'w0': 0.9462456668626484, 'w1': 0.052721117315348516, 'w2': 0.032723565187665074, 'w3': 0.04609806003332968, 'w4': 0.048485796874006795}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:41,331]\u001b[0m Trial 433 finished with value: 0.7665169454144537 and parameters: {'w0': 0.9061113465043362, 'w1': 0.032431139607150036, 'w2': 0.05221318930382287, 'w3': 0.0425854625861993, 'w4': 0.031522663579927335}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:41,473]\u001b[0m Trial 434 finished with value: 0.7664331493412049 and parameters: {'w0': 0.9704629910734978, 'w1': 0.0012315886510782057, 'w2': 0.07763655587287235, 'w3': 0.06284158874885837, 'w4': 0.22030779877688783}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:41,616]\u001b[0m Trial 435 finished with value: 0.766531079754164 and parameters: {'w0': 0.9201045942167911, 'w1': 0.07037550141763987, 'w2': 0.021770527645988864, 'w3': 0.05804922706595668, 'w4': 0.015751106828692817}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:41,756]\u001b[0m Trial 436 finished with value: 0.7665590722443467 and parameters: {'w0': 0.9540842528923882, 'w1': 0.0008698418307847763, 'w2': 0.0003532932327758864, 'w3': 0.05713796853273319, 'w4': 0.05446056197434389}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:41,902]\u001b[0m Trial 437 finished with value: 0.7665738968417151 and parameters: {'w0': 0.8938720776572406, 'w1': 7.363599224133208e-06, 'w2': 0.04117637192160423, 'w3': 0.03467383858986558, 'w4': 0.00016291182966677502}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:42,044]\u001b[0m Trial 438 finished with value: 0.7665099726056641 and parameters: {'w0': 0.8954966599494795, 'w1': 0.017330505535321054, 'w2': 0.08608553105204532, 'w3': 0.02646124394316332, 'w4': 0.0004296199319353167}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:42,194]\u001b[0m Trial 439 finished with value: 0.7664010777815782 and parameters: {'w0': 0.8858894094809019, 'w1': 0.00047606241713578357, 'w2': 0.06127008806605603, 'w3': 5.3866237492247726e-05, 'w4': 0.03237979643871343}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:42,346]\u001b[0m Trial 440 finished with value: 0.7663231523454027 and parameters: {'w0': 0.9015762847972042, 'w1': 0.4607196960929639, 'w2': 0.04830543320792187, 'w3': 0.042330267851810495, 'w4': 0.021474323680333095}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:42,497]\u001b[0m Trial 441 finished with value: 0.7664944672298316 and parameters: {'w0': 0.9229703151591936, 'w1': 0.01920884623097363, 'w2': 0.08916010840815398, 'w3': 0.0373972408426615, 'w4': 0.03870204614167463}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:42,643]\u001b[0m Trial 442 finished with value: 0.76646108409448 and parameters: {'w0': 0.2900946510140061, 'w1': 0.00045433686491500383, 'w2': 0.03891484347350605, 'w3': 0.028352972527553907, 'w4': 0.06417440253826039}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:42,789]\u001b[0m Trial 443 finished with value: 0.7665594143570688 and parameters: {'w0': 0.8780481662711064, 'w1': 0.030403958212215223, 'w2': 0.0627325614563938, 'w3': 0.07784320796801311, 'w4': 0.0006568674547187715}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:42,932]\u001b[0m Trial 444 finished with value: 0.7665722922727272 and parameters: {'w0': 0.908682082753557, 'w1': 8.136249820036255e-05, 'w2': 0.03731133463571692, 'w3': 0.061252467849308365, 'w4': 0.018239263616426825}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:43,076]\u001b[0m Trial 445 finished with value: 0.7665195151377201 and parameters: {'w0': 0.9025272088407593, 'w1': 0.00019821312558092671, 'w2': 0.032199139521301816, 'w3': 0.016798830889395194, 'w4': 0.019295856480503908}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:43,222]\u001b[0m Trial 446 finished with value: 0.7664332691237448 and parameters: {'w0': 0.9115703959489768, 'w1': 0.019764210289403974, 'w2': 0.06922431150571381, 'w3': 0.05705955990544801, 'w4': 0.18743418617848917}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:43,371]\u001b[0m Trial 447 finished with value: 0.7665701607467381 and parameters: {'w0': 0.3384331700030333, 'w1': 0.000203638578572439, 'w2': 0.033246467750368935, 'w3': 0.053348137347036154, 'w4': 9.443876498013704e-05}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:43,517]\u001b[0m Trial 448 finished with value: 0.7665179118613494 and parameters: {'w0': 0.3352659449368745, 'w1': 0.0009787202401100106, 'w2': 0.01715415287344502, 'w3': 0.029872405287947504, 'w4': 0.04265408637420513}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:43,657]\u001b[0m Trial 449 finished with value: 0.7665494930881329 and parameters: {'w0': 0.4622951917580043, 'w1': 0.015373299505797085, 'w2': 0.03276896357290994, 'w3': 0.05582695107781032, 'w4': 0.017627170137858295}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:43,803]\u001b[0m Trial 450 finished with value: 0.7665382757548804 and parameters: {'w0': 0.2608341593523803, 'w1': 2.2863816600555392e-05, 'w2': 0.018105111885264098, 'w3': 0.04800664889807246, 'w4': 0.034304692653076015}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:43,948]\u001b[0m Trial 451 finished with value: 0.7664770164649063 and parameters: {'w0': 0.16094111307394662, 'w1': 0.02244673347529751, 'w2': 0.09315050429299636, 'w3': 0.0747984806227745, 'w4': 0.06319227740355805}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:18:44,090]\u001b[0m Trial 452 finished with value: 0.7664930039870057 and parameters: {'w0': 0.4165230257809579, 'w1': 0.04421887968595129, 'w2': 0.038684617467832264, 'w3': 0.024259582486877818, 'w4': 0.000649491141009534}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:44,233]\u001b[0m Trial 453 finished with value: 0.7665713534016679 and parameters: {'w0': 0.5206322125273839, 'w1': 0.021711055008586635, 'w2': 0.01651219864706377, 'w3': 0.06259869457820749, 'w4': 0.00018965734028487184}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:44,376]\u001b[0m Trial 454 finished with value: 0.7665724926284144 and parameters: {'w0': 0.8745742046093494, 'w1': 0.0012077989902173243, 'w2': 0.002570691412721246, 'w3': 0.054366660720936315, 'w4': 0.03304645468003261}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:44,522]\u001b[0m Trial 455 finished with value: 0.7663307344078305 and parameters: {'w0': 0.8584794447467772, 'w1': 0.329290956508254, 'w2': 0.007901219152630463, 'w3': 0.03965860800370059, 'w4': 0.09768747558831417}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:44,665]\u001b[0m Trial 456 finished with value: 0.7664775977118357 and parameters: {'w0': 0.23950383156145771, 'w1': 0.032337601895406146, 'w2': 0.002668838104028795, 'w3': 0.06685636747853563, 'w4': 0.07869309186756432}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:44,808]\u001b[0m Trial 457 finished with value: 0.7664484871076561 and parameters: {'w0': 0.36961615708533957, 'w1': 0.019129981966060593, 'w2': 0.016914553728298594, 'w3': 0.01969939381680342, 'w4': 0.05301311677667252}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:44,949]\u001b[0m Trial 458 finished with value: 0.7664180175317827 and parameters: {'w0': 0.5763215825054918, 'w1': 0.289937328889896, 'w2': 0.0038607589379798207, 'w3': 0.07613513285955975, 'w4': 0.03802527926453309}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:45,093]\u001b[0m Trial 459 finished with value: 0.7663179314639778 and parameters: {'w0': 0.06951583975987613, 'w1': 0.04809847152866459, 'w2': 0.025675351614234523, 'w3': 0.5190332968008494, 'w4': 0.031151025608229188}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:45,235]\u001b[0m Trial 460 finished with value: 0.7665023746009559 and parameters: {'w0': 0.20984856442078084, 'w1': 0.017418495200544986, 'w2': 6.400346630950488e-05, 'w3': 0.05365378869489185, 'w4': 0.051762495057278715}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:45,375]\u001b[0m Trial 461 finished with value: 0.7665374988918607 and parameters: {'w0': 0.2001534406389222, 'w1': 7.806111827823227e-05, 'w2': 0.025325708765075772, 'w3': 0.03602454652801326, 'w4': 0.02164605337346697}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:45,517]\u001b[0m Trial 462 finished with value: 0.7665552099037432 and parameters: {'w0': 0.8758544522671967, 'w1': 0.03423549852913592, 'w2': 0.02984897006903929, 'w3': 0.07506542319122805, 'w4': 0.018978302664468778}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:45,658]\u001b[0m Trial 463 finished with value: 0.7663592715207848 and parameters: {'w0': 0.868453151437497, 'w1': 0.05142005259289409, 'w2': 0.03899257743351127, 'w3': 0.0052377893513629314, 'w4': 0.07226484541289538}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:45,801]\u001b[0m Trial 464 finished with value: 0.7663799266840889 and parameters: {'w0': 0.634399461614159, 'w1': 0.017905570135504638, 'w2': 0.7231512988881449, 'w3': 0.08363203814136505, 'w4': 0.0372311926570142}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:45,943]\u001b[0m Trial 465 finished with value: 0.7665344577941386 and parameters: {'w0': 0.4988905592814311, 'w1': 0.03478369715098706, 'w2': 0.01861382301296824, 'w3': 0.048702852620106256, 'w4': 0.018706281181865913}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:46,088]\u001b[0m Trial 466 finished with value: 0.7665231262796879 and parameters: {'w0': 0.2953437193315137, 'w1': 0.0012702387427746646, 'w2': 0.043563346166617264, 'w3': 0.0630851289681999, 'w4': 0.050093229973744546}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:46,230]\u001b[0m Trial 467 finished with value: 0.7665314326386969 and parameters: {'w0': 0.5487042736227533, 'w1': 0.0619111812363068, 'w2': 0.019904565970868187, 'w3': 0.0842941206135702, 'w4': 0.017870012297382026}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:46,372]\u001b[0m Trial 468 finished with value: 0.7665703218930328 and parameters: {'w0': 0.8861448187405453, 'w1': 0.0004909416819116976, 'w2': 0.04320275546486883, 'w3': 0.03259620759984099, 'w4': 0.0003070031656757327}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:46,513]\u001b[0m Trial 469 finished with value: 0.7665089156755547 and parameters: {'w0': 0.8847850535124905, 'w1': 0.020997928301320974, 'w2': 0.0024700478820033583, 'w3': 0.02000966788767712, 'w4': 0.03615432773531963}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:46,656]\u001b[0m Trial 470 finished with value: 0.7663139402925125 and parameters: {'w0': 0.8559863672862236, 'w1': 0.03228928927204587, 'w2': 0.2965431831214641, 'w3': 0.001320588536419559, 'w4': 0.018175938645109333}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:46,798]\u001b[0m Trial 471 finished with value: 0.7665099941492866 and parameters: {'w0': 0.8690147920382558, 'w1': 0.000273371700900929, 'w2': 0.05046829784133598, 'w3': 0.035752742734776535, 'w4': 0.05747066387173314}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:46,942]\u001b[0m Trial 472 finished with value: 0.7665628260050943 and parameters: {'w0': 0.8890488486127656, 'w1': 0.050898741784148126, 'w2': 0.0018514267781329155, 'w3': 0.06997257864701531, 'w4': 4.09387319903714e-05}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:47,084]\u001b[0m Trial 473 finished with value: 0.7665493155686853 and parameters: {'w0': 0.8930533052120597, 'w1': 0.02503130024749799, 'w2': 0.051704702000201316, 'w3': 0.08513641301986093, 'w4': 0.03425135759118953}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:47,226]\u001b[0m Trial 474 finished with value: 0.7665386553535052 and parameters: {'w0': 0.8443532649771129, 'w1': 0.018804806245570124, 'w2': 0.03077522842377772, 'w3': 0.031534821735608974, 'w4': 0.018632494498720037}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:47,366]\u001b[0m Trial 475 finished with value: 0.7665288465422776 and parameters: {'w0': 0.8673559481949727, 'w1': 0.042448444642380886, 'w2': 0.01884952877632069, 'w3': 0.06007370780883721, 'w4': 0.046452773102820366}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:47,508]\u001b[0m Trial 476 finished with value: 0.7665821859658264 and parameters: {'w0': 0.9020253110110033, 'w1': 0.019169782354220205, 'w2': 0.00047651203303170135, 'w3': 0.09042759174199491, 'w4': 0.01734328037978014}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:47,651]\u001b[0m Trial 477 finished with value: 0.7665197491014581 and parameters: {'w0': 0.8937395487735513, 'w1': 0.07584223571086987, 'w2': 0.0002245839290777943, 'w3': 0.08837751100030297, 'w4': 0.06801315798496925}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:47,791]\u001b[0m Trial 478 finished with value: 0.7664797938686916 and parameters: {'w0': 0.9102658238628305, 'w1': 0.0623155422089453, 'w2': 0.017090941988568177, 'w3': 0.05021728750744004, 'w4': 0.08763891067075857}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:47,935]\u001b[0m Trial 479 finished with value: 0.7665162017286122 and parameters: {'w0': 0.8730422054027676, 'w1': 0.09519403730452373, 'w2': 0.00011051024000434265, 'w3': 0.06960225686343, 'w4': 0.03587855022455478}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:18:48,074]\u001b[0m Trial 480 finished with value: 0.7663050569952987 and parameters: {'w0': 0.9234462714610094, 'w1': 0.9166597767660759, 'w2': 0.03628451189005077, 'w3': 0.08676674320493372, 'w4': 0.024639199496046052}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:48,220]\u001b[0m Trial 481 finished with value: 0.7665350050021448 and parameters: {'w0': 0.9043755804748496, 'w1': 0.036551917990423566, 'w2': 0.02352413127018171, 'w3': 0.03712919571162211, 'w4': 0.017907898361530075}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:48,363]\u001b[0m Trial 482 finished with value: 0.7665856320836475 and parameters: {'w0': 0.9290614460405935, 'w1': 0.01815087731768197, 'w2': 0.0007999005406377352, 'w3': 0.06746178173753689, 'w4': 0.0002982517224649657}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:48,505]\u001b[0m Trial 483 finished with value: 0.7664888055658945 and parameters: {'w0': 0.9316771925454393, 'w1': 0.17737946201664972, 'w2': 0.00038310553301884424, 'w3': 0.09658277162045101, 'w4': 0.055565797410149206}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:48,646]\u001b[0m Trial 484 finished with value: 0.7665316385957262 and parameters: {'w0': 0.7096800621515582, 'w1': 0.054195129340132604, 'w2': 0.01771080168838165, 'w3': 0.0753972124354743, 'w4': 0.035245314122503146}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:48,788]\u001b[0m Trial 485 finished with value: 0.7665657399954446 and parameters: {'w0': 0.9277014199044225, 'w1': 0.03104505476472734, 'w2': 0.021607775236351497, 'w3': 0.09427320534941613, 'w4': 0.018673315382503844}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:48,931]\u001b[0m Trial 486 finished with value: 0.7665085511574656 and parameters: {'w0': 0.9409656322735008, 'w1': 0.019224976050682293, 'w2': 0.002108900975904396, 'w3': 0.059779325126266505, 'w4': 0.11321259534642658}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:49,074]\u001b[0m Trial 487 finished with value: 0.7663047226382809 and parameters: {'w0': 0.9122752043832538, 'w1': 0.04659375017475101, 'w2': 0.03722526646067163, 'w3': 0.07329806670358707, 'w4': 0.600284246682894}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:49,221]\u001b[0m Trial 488 finished with value: 0.7665592170174886 and parameters: {'w0': 0.9331295612331039, 'w1': 0.018469951443334517, 'w2': 0.017890505372209358, 'w3': 0.09601614261011515, 'w4': 0.04634924565020497}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:49,364]\u001b[0m Trial 489 finished with value: 0.7664827345731338 and parameters: {'w0': 0.9485444229026248, 'w1': 0.13283445250495685, 'w2': 0.049574325960177426, 'w3': 0.05934881082122384, 'w4': 0.01837728370167965}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:49,508]\u001b[0m Trial 490 finished with value: 0.7665162452467293 and parameters: {'w0': 0.9121833655258864, 'w1': 0.06880169112616148, 'w2': 0.01899294625925313, 'w3': 0.08158525011855082, 'w4': 0.06835584574092902}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:49,650]\u001b[0m Trial 491 finished with value: 0.7665582553101897 and parameters: {'w0': 0.9369841876105605, 'w1': 0.029788417624371677, 'w2': 0.05907558567560397, 'w3': 0.0980181247223395, 'w4': 0.017930416536151256}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:49,795]\u001b[0m Trial 492 finished with value: 0.7664206699825589 and parameters: {'w0': 0.8425547615556309, 'w1': 0.018110509560757767, 'w2': 0.0008741663225919384, 'w3': 0.4656150845088586, 'w4': 3.40376305587453e-05}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:49,937]\u001b[0m Trial 493 finished with value: 0.7662667347691016 and parameters: {'w0': 0.9591856376639802, 'w1': 4.89949985087168e-05, 'w2': 0.035386518797513145, 'w3': 0.04640024783756197, 'w4': 0.6340317871975164}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:50,076]\u001b[0m Trial 494 finished with value: 0.7664118457148699 and parameters: {'w0': 0.9990850277666614, 'w1': 0.05023263201577713, 'w2': 0.03328629440674988, 'w3': 0.7258061710373449, 'w4': 0.042971988270811654}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:50,220]\u001b[0m Trial 495 finished with value: 0.7664401531728106 and parameters: {'w0': 0.8913295356332736, 'w1': 0.03533863376751405, 'w2': 0.3638198586878745, 'w3': 0.07277566188872894, 'w4': 0.03360014225072604}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:50,364]\u001b[0m Trial 496 finished with value: 0.7663600117596466 and parameters: {'w0': 0.5251328446965738, 'w1': 0.3620618918943629, 'w2': 0.5218306845320363, 'w3': 0.10314143601330014, 'w4': 0.00011177761157833837}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:50,506]\u001b[0m Trial 497 finished with value: 0.7664946546593454 and parameters: {'w0': 0.9310491189350321, 'w1': 0.018077520625264302, 'w2': 0.05976626952749041, 'w3': 0.022015046624379857, 'w4': 0.019323864895854713}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:50,649]\u001b[0m Trial 498 finished with value: 0.7663032404370674 and parameters: {'w0': 0.9668104742665778, 'w1': 0.04370398511429194, 'w2': 0.01863174082944906, 'w3': 0.05794730062200873, 'w4': 0.5257202832367781}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:50,788]\u001b[0m Trial 499 finished with value: 0.76642161273147 and parameters: {'w0': 0.9076385145282106, 'w1': 7.966203581109138e-05, 'w2': 1.4508378178013093e-07, 'w3': 0.08370715869696785, 'w4': 0.33053054104895935}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:50,932]\u001b[0m Trial 500 finished with value: 0.7664147472099196 and parameters: {'w0': 0.9828582536108967, 'w1': 0.2224084293682968, 'w2': 0.2691958467883808, 'w3': 0.3604248048617178, 'w4': 0.7822648735826772}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:51,075]\u001b[0m Trial 501 finished with value: 0.7664844632333861 and parameters: {'w0': 0.9518553223874249, 'w1': 0.08759898194702823, 'w2': 0.050515135164374614, 'w3': 0.4095013951255791, 'w4': 0.05721223576103755}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:51,221]\u001b[0m Trial 502 finished with value: 0.7664573398129264 and parameters: {'w0': 0.6589762582361642, 'w1': 0.25213381679385966, 'w2': 0.034785244719145875, 'w3': 0.10098085972208332, 'w4': 0.029698899635078033}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:51,368]\u001b[0m Trial 503 finished with value: 0.7662533540252989 and parameters: {'w0': 0.12234239109105771, 'w1': 0.01572199572570658, 'w2': 0.00017381175212352086, 'w3': 0.04651229974801434, 'w4': 0.47454811274299313}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:51,509]\u001b[0m Trial 504 finished with value: 0.7665243012688475 and parameters: {'w0': 0.6953416329513982, 'w1': 0.060311874780490674, 'w2': 0.0725203199975229, 'w3': 0.07866664426865602, 'w4': 0.01575411442258838}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:51,653]\u001b[0m Trial 505 finished with value: 0.766545064150263 and parameters: {'w0': 0.8668583767890462, 'w1': 0.037523792150590894, 'w2': 0.021992245502966447, 'w3': 0.06896021103600564, 'w4': 0.033195026841415884}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:51,796]\u001b[0m Trial 506 finished with value: 0.7664091273406095 and parameters: {'w0': 0.9260269384361058, 'w1': 0.018631459340239992, 'w2': 0.050973006118144024, 'w3': 0.7650901469674678, 'w4': 0.08622441454122372}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:51,940]\u001b[0m Trial 507 finished with value: 0.7662176325451843 and parameters: {'w0': 0.8978377111968175, 'w1': 0.9665758228138595, 'w2': 0.4690557990217378, 'w3': 0.017106291945073585, 'w4': 0.0004596726106232129}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:18:52,081]\u001b[0m Trial 508 finished with value: 0.7665465174830226 and parameters: {'w0': 0.9640284543512301, 'w1': 0.032711776177657546, 'w2': 0.035114934655146195, 'w3': 0.10207283104032601, 'w4': 0.05118185864290005}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:52,221]\u001b[0m Trial 509 finished with value: 0.766539800612466 and parameters: {'w0': 0.9421957461237791, 'w1': 0.018031818045156776, 'w2': 0.06292306156478142, 'w3': 0.04445471975396915, 'w4': 0.015612982281977716}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:52,374]\u001b[0m Trial 510 finished with value: 0.7664357647369506 and parameters: {'w0': 0.9184801390842909, 'w1': 0.06439024687426426, 'w2': 0.020191900105914706, 'w3': 0.5937857940947102, 'w4': 0.03665933851333482}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:52,520]\u001b[0m Trial 511 finished with value: 0.7665280205597992 and parameters: {'w0': 0.9849751241387014, 'w1': 0.04390244962383891, 'w2': 0.08170875660759455, 'w3': 0.061018703751363805, 'w4': 0.01577462971879788}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:52,662]\u001b[0m Trial 512 finished with value: 0.7663284016644092 and parameters: {'w0': 0.846763982495722, 'w1': 0.7483327893209389, 'w2': 0.04414553840725973, 'w3': 0.08429119625381275, 'w4': 0.00027755090466905397}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:52,805]\u001b[0m Trial 513 finished with value: 0.7665479777097413 and parameters: {'w0': 0.9503257522109966, 'w1': 0.017382280234746115, 'w2': 0.018506927236527207, 'w3': 0.10498745670331473, 'w4': 0.07133322336696145}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:52,949]\u001b[0m Trial 514 finished with value: 0.7662145104434424 and parameters: {'w0': 0.8732858789159946, 'w1': 0.8408662216043468, 'w2': 0.06504223050642835, 'w3': 0.03944958523190738, 'w4': 0.3558693254415435}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:53,091]\u001b[0m Trial 515 finished with value: 0.7663788451942501 and parameters: {'w0': 0.8917830955225932, 'w1': 0.015583820777614278, 'w2': 0.03293945162506493, 'w3': 0.08673336756868195, 'w4': 0.4241656614646522}. Best is trial 158 with value: 0.7665946054332026.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:53,232]\u001b[0m Trial 516 finished with value: 0.7665950294116892 and parameters: {'w0': 0.9213592051547623, 'w1': 0.0006109011131602386, 'w2': 0.015149404395915556, 'w3': 0.06974354162620626, 'w4': 0.00022777380548457023}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:53,377]\u001b[0m Trial 517 finished with value: 0.7664496952739941 and parameters: {'w0': 0.9106966701534087, 'w1': 0.0026575869718748896, 'w2': 0.016375710793114742, 'w3': 0.8341759962378776, 'w4': 0.2977330640085175}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:53,524]\u001b[0m Trial 518 finished with value: 0.7665766074602713 and parameters: {'w0': 0.9219695792513329, 'w1': 0.00036767606713272006, 'w2': 0.0005275917167775687, 'w3': 0.06350556470189708, 'w4': 0.03506270254280572}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:53,665]\u001b[0m Trial 519 finished with value: 0.7665560203748136 and parameters: {'w0': 0.9046185191553748, 'w1': 0.00017361262516662403, 'w2': 0.00304003031631625, 'w3': 0.06737738436049633, 'w4': 0.061750032117404985}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:53,806]\u001b[0m Trial 520 finished with value: 0.7665364686758429 and parameters: {'w0': 0.8831723926916764, 'w1': 0.03545799047132221, 'w2': 0.017963031544999078, 'w3': 0.0634353953315102, 'w4': 0.045924470744110386}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:53,949]\u001b[0m Trial 521 finished with value: 0.7664302366434717 and parameters: {'w0': 0.9316867916930796, 'w1': 0.03199144515709804, 'w2': 0.0025795988121573507, 'w3': 0.07724683298536393, 'w4': 0.26596982756457693}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:54,093]\u001b[0m Trial 522 finished with value: 0.7665679645898821 and parameters: {'w0': 0.8554966555380291, 'w1': 0.0007517003374793008, 'w2': 0.0012014550689761622, 'w3': 0.05379253763527007, 'w4': 0.039037776723197935}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:54,234]\u001b[0m Trial 523 finished with value: 0.7663775702426833 and parameters: {'w0': 0.9138865695633018, 'w1': 2.8427076126071522e-05, 'w2': 0.8777743143084731, 'w3': 0.10098828787869146, 'w4': 0.09028411537478837}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:54,376]\u001b[0m Trial 524 finished with value: 0.7665423811075435 and parameters: {'w0': 0.8968574746558509, 'w1': 0.04850934641357712, 'w2': 0.019398212067125803, 'w3': 0.0723476953535201, 'w4': 0.03122601203893281}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:54,521]\u001b[0m Trial 525 finished with value: 0.7665440235933065 and parameters: {'w0': 0.9349655204270424, 'w1': 0.02772309355729417, 'w2': 0.029081879159728482, 'w3': 0.10730739481594267, 'w4': 0.0636316625413261}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:54,663]\u001b[0m Trial 526 finished with value: 0.7665325434278623 and parameters: {'w0': 0.8751254346222844, 'w1': 0.07131438158382328, 'w2': 0.0005617640377171769, 'w3': 0.05743243545969836, 'w4': 0.0209935829051575}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:54,804]\u001b[0m Trial 527 finished with value: 0.7665085653762564 and parameters: {'w0': 0.9482336324385402, 'w1': 0.017437187148981, 'w2': 0.019423821196603342, 'w3': 0.02548654077845937, 'w4': 0.04359201284564333}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:54,959]\u001b[0m Trial 528 finished with value: 0.7665809467766724 and parameters: {'w0': 0.921078008973827, 'w1': 6.558448705106944e-05, 'w2': 0.020315831840523636, 'w3': 0.08724293602365923, 'w4': 0.027231649534029755}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:55,105]\u001b[0m Trial 529 finished with value: 0.7665386376877349 and parameters: {'w0': 0.9209786924352531, 'w1': 0.018172837133699857, 'w2': 0.0341249830285712, 'w3': 0.09082856938956745, 'w4': 0.07288856876586511}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:55,249]\u001b[0m Trial 530 finished with value: 0.7665509727041117 and parameters: {'w0': 0.8998996848670913, 'w1': 0.03669073245284843, 'w2': 0.000617607702297851, 'w3': 0.11118925229798823, 'w4': 0.05361463379524101}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:55,392]\u001b[0m Trial 531 finished with value: 0.766505669051676 and parameters: {'w0': 0.9316202176133551, 'w1': 0.0003876448726266448, 'w2': 0.24018498764882779, 'w3': 0.08363078628382625, 'w4': 0.03044271774250463}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:55,539]\u001b[0m Trial 532 finished with value: 0.7665359218987092 and parameters: {'w0': 0.8900217588098555, 'w1': 0.050419593417197955, 'w2': 0.04369717506235093, 'w3': 0.11036974295428241, 'w4': 0.05145541106393503}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:55,683]\u001b[0m Trial 533 finished with value: 0.7665332802197443 and parameters: {'w0': 0.9575702997404469, 'w1': 0.02032999319379638, 'w2': 0.41985443880534157, 'w3': 0.3296995509125809, 'w4': 0.027979434028257328}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:55,825]\u001b[0m Trial 534 finished with value: 0.7665791164305229 and parameters: {'w0': 0.9163663182647854, 'w1': 1.8807582718995911e-06, 'w2': 0.03353706728644781, 'w3': 0.08210073880198933, 'w4': 0.018631799653554947}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:55,968]\u001b[0m Trial 535 finished with value: 0.766538747129336 and parameters: {'w0': 0.9142043295785112, 'w1': 0.012770675919939668, 'w2': 0.04787357189962505, 'w3': 0.09094681159129218, 'w4': 0.06986689210614208}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:18:56,113]\u001b[0m Trial 536 finished with value: 0.7665353914947286 and parameters: {'w0': 0.8796773824473447, 'w1': 0.0007949024678461878, 'w2': 0.034200988638752455, 'w3': 0.11148553293422771, 'w4': 0.11041846241036897}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:56,256]\u001b[0m Trial 537 finished with value: 0.7665210856677849 and parameters: {'w0': 0.9155085844612545, 'w1': 0.017367743531946526, 'w2': 0.053105220778670685, 'w3': 0.044729864550110666, 'w4': 0.044300677448645506}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:56,399]\u001b[0m Trial 538 finished with value: 0.766540239671488 and parameters: {'w0': 0.8619525614122989, 'w1': 0.0019267475959286152, 'w2': 0.021007468999235186, 'w3': 0.08661829047405409, 'w4': 0.08811960835962368}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:56,541]\u001b[0m Trial 539 finished with value: 0.7665661359672223 and parameters: {'w0': 0.8989111738561332, 'w1': 0.000935382913108488, 'w2': 0.03805660763142925, 'w3': 0.0694023790477232, 'w4': 0.029543353815420753}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:56,691]\u001b[0m Trial 540 finished with value: 0.7665561931546644 and parameters: {'w0': 0.9269697978859625, 'w1': 0.03225142920171361, 'w2': 0.060256304397284216, 'w3': 0.10653222488800954, 'w4': 0.020741888198441458}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:56,832]\u001b[0m Trial 541 finished with value: 0.7665017692251697 and parameters: {'w0': 0.8855240604925734, 'w1': 0.018388654135414673, 'w2': 0.08175014656493905, 'w3': 0.050420492340405354, 'w4': 0.058736943699882055}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:56,973]\u001b[0m Trial 542 finished with value: 0.7665703098286043 and parameters: {'w0': 0.9376033799376253, 'w1': 0.03400278263101718, 'w2': 7.42085395723282e-05, 'w3': 0.08917464271632183, 'w4': 0.018974333276430604}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:57,116]\u001b[0m Trial 543 finished with value: 0.7665126819316033 and parameters: {'w0': 0.9079555795605255, 'w1': 0.00047214040862430395, 'w2': 0.03450352193048992, 'w3': 0.02613903449479522, 'w4': 0.046774364625256255}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:57,261]\u001b[0m Trial 544 finished with value: 0.7663923246078428 and parameters: {'w0': 0.8366791266097527, 'w1': 8.626052119681607e-05, 'w2': 0.0005742829426197138, 'w3': 0.6276343714108706, 'w4': 0.031949617007909194}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:57,404]\u001b[0m Trial 545 finished with value: 0.7665348339457838 and parameters: {'w0': 0.9381032387259185, 'w1': 0.05004975731836433, 'w2': 0.057525693710021336, 'w3': 0.06431417690432627, 'w4': 0.017178451320530884}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:57,547]\u001b[0m Trial 546 finished with value: 0.7662934725587224 and parameters: {'w0': 0.8746692192195565, 'w1': 0.021822094733455543, 'w2': 0.021642475168691173, 'w3': 0.11334846808447205, 'w4': 0.9574463564255988}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:57,696]\u001b[0m Trial 547 finished with value: 0.766576931045478 and parameters: {'w0': 0.9128050121424202, 'w1': 0.0005185616930069609, 'w2': 0.03900746145793623, 'w3': 0.08436340509547699, 'w4': 0.01915697716446258}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:57,843]\u001b[0m Trial 548 finished with value: 0.7665566451398598 and parameters: {'w0': 0.9217980944779017, 'w1': 0.00012683765968149463, 'w2': 0.035562856240460086, 'w3': 0.11666546655639622, 'w4': 0.06498911994017648}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:57,987]\u001b[0m Trial 549 finished with value: 0.7665535725884494 and parameters: {'w0': 0.9058490083247002, 'w1': 0.034415087730358014, 'w2': 0.0008596039363122053, 'w3': 0.09286843456288696, 'w4': 0.045652507568916555}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:58,129]\u001b[0m Trial 550 finished with value: 0.7665412573922048 and parameters: {'w0': 0.9429446415535259, 'w1': 0.05119798268336007, 'w2': 0.021791764402882576, 'w3': 0.07922302656954552, 'w4': 0.03624471523938151}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:58,272]\u001b[0m Trial 551 finished with value: 0.76656410957411 and parameters: {'w0': 0.9236630454577551, 'w1': 0.02427953782356424, 'w2': 0.05166100613987798, 'w3': 0.1212354784994302, 'w4': 0.01962512853972422}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:58,416]\u001b[0m Trial 552 finished with value: 0.7665409691385388 and parameters: {'w0': 0.9455827144676076, 'w1': 0.019347736158138538, 'w2': 0.01841162477375176, 'w3': 0.09869017676158304, 'w4': 0.08111995240400975}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:58,559]\u001b[0m Trial 553 finished with value: 0.7665138974227725 and parameters: {'w0': 0.9016345932204622, 'w1': 0.00010347251823932332, 'w2': 0.042403445219687454, 'w3': 0.03579304733129149, 'w4': 0.0596573488368916}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:58,704]\u001b[0m Trial 554 finished with value: 0.7663002238990747 and parameters: {'w0': 0.958526989576918, 'w1': 0.67259995215331, 'w2': 0.018029595219466236, 'w3': 0.07141471944431443, 'w4': 0.15569397007138083}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:58,851]\u001b[0m Trial 555 finished with value: 0.766531600678951 and parameters: {'w0': 0.9196897030508564, 'w1': 0.03700170146747833, 'w2': 0.03820736519301301, 'w3': 0.053280934199692175, 'w4': 0.0319995741898812}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:58,997]\u001b[0m Trial 556 finished with value: 0.7665579054417637 and parameters: {'w0': 0.9353899561141056, 'w1': 0.01894134120628433, 'w2': 0.06521227209749389, 'w3': 0.08922058104775674, 'w4': 0.023000689193075817}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:59,139]\u001b[0m Trial 557 finished with value: 0.7662349105302587 and parameters: {'w0': 0.8945174218807465, 'w1': 0.6048003183988222, 'w2': 0.0007978064683716987, 'w3': 0.010107927571094036, 'w4': 0.0495426460745092}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:59,282]\u001b[0m Trial 558 finished with value: 0.7665480276909449 and parameters: {'w0': 0.9562851292906157, 'w1': 0.06366516774197853, 'w2': 0.03281593131871342, 'w3': 0.10430120805057576, 'w4': 0.020354312873896666}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:59,429]\u001b[0m Trial 559 finished with value: 0.7664050547342525 and parameters: {'w0': 0.9163363276097946, 'w1': 0.570778711240426, 'w2': 0.01754544686155753, 'w3': 0.12430489172110773, 'w4': 0.015979961641493033}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:59,574]\u001b[0m Trial 560 finished with value: 0.7665432182927054 and parameters: {'w0': 0.9434721303152561, 'w1': 0.019961105620662643, 'w2': 0.05140553351332804, 'w3': 0.0754797951171645, 'w4': 0.04497551236297333}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:59,717]\u001b[0m Trial 561 finished with value: 0.7665138159878803 and parameters: {'w0': 0.9621167861475821, 'w1': 0.04695820333335208, 'w2': 0.09173668652155376, 'w3': 0.043672607896869116, 'w4': 0.0005980658783234161}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:18:59,866]\u001b[0m Trial 562 finished with value: 0.7665635696909355 and parameters: {'w0': 0.9000392299885533, 'w1': 0.018553716732912437, 'w2': 0.019253254408447818, 'w3': 0.09549780334737153, 'w4': 0.03627356045289458}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:00,016]\u001b[0m Trial 563 finished with value: 0.7665232520944422 and parameters: {'w0': 0.9274810311974108, 'w1': 8.292340960908834e-06, 'w2': 0.0386777342607936, 'w3': 0.054532129936463176, 'w4': 0.08032598963548707}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:19:00,164]\u001b[0m Trial 564 finished with value: 0.7665574439773744 and parameters: {'w0': 0.8854023716484715, 'w1': 0.034961784608749484, 'w2': 0.06489441398789894, 'w3': 0.12037010719933419, 'w4': 0.015868130166467313}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:00,310]\u001b[0m Trial 565 finished with value: 0.7665254719492827 and parameters: {'w0': 0.9118098366095108, 'w1': 0.05141246911396323, 'w2': 0.017837238892691436, 'w3': 0.07469058553501279, 'w4': 0.061631100721049305}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:00,456]\u001b[0m Trial 566 finished with value: 0.7664578111873821 and parameters: {'w0': 0.9667550699068174, 'w1': 0.07998321592427649, 'w2': 0.05393104733072156, 'w3': 0.5652458913936518, 'w4': 0.0168974330654535}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:00,599]\u001b[0m Trial 567 finished with value: 0.7665706700379689 and parameters: {'w0': 0.9371841532544654, 'w1': 0.0002723616097069434, 'w2': 0.03579545263642167, 'w3': 0.09967828409572349, 'w4': 0.037836246935925126}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:00,743]\u001b[0m Trial 568 finished with value: 0.7665191290760088 and parameters: {'w0': 0.9523636734032382, 'w1': 0.019803724839473708, 'w2': 0.07670704106089335, 'w3': 0.028499220052439374, 'w4': 0.00034316640232031145}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:00,901]\u001b[0m Trial 569 finished with value: 0.7665461891582189 and parameters: {'w0': 0.9249064207567668, 'w1': 0.03639857556819586, 'w2': 0.019488138307848617, 'w3': 0.06691595483838429, 'w4': 0.033515493523197715}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:01,044]\u001b[0m Trial 570 finished with value: 0.7664318429359495 and parameters: {'w0': 0.8888754815737869, 'w1': 0.02051496453154895, 'w2': 0.7843043468731747, 'w3': 0.12988256341062496, 'w4': 0.0003976278553429434}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:01,186]\u001b[0m Trial 571 finished with value: 0.7664430102879982 and parameters: {'w0': 0.9671947606767828, 'w1': 0.28066366761173095, 'w2': 0.0015349425265573022, 'w3': 0.08585718420589439, 'w4': 0.056049747305892746}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:01,340]\u001b[0m Trial 572 finished with value: 0.7663715009734124 and parameters: {'w0': 0.9176021927951742, 'w1': 0.017904228641257236, 'w2': 0.049239336928679905, 'w3': 0.9386253376075837, 'w4': 0.023451197361563564}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:01,487]\u001b[0m Trial 573 finished with value: 0.7662768645803011 and parameters: {'w0': 0.9402720598620707, 'w1': 0.060261512912384234, 'w2': 0.032873271256775825, 'w3': 0.052197643041182025, 'w4': 0.5768602128685234}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:01,631]\u001b[0m Trial 574 finished with value: 0.7664138561657017 and parameters: {'w0': 0.902379304833582, 'w1': 0.4378413772325752, 'w2': 0.08756795508687791, 'w3': 0.11046011030091751, 'w4': 0.018689935395444342}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:01,774]\u001b[0m Trial 575 finished with value: 0.7663057114905438 and parameters: {'w0': 0.8718703011040411, 'w1': 0.03682992161360189, 'w2': 0.6441514842379573, 'w3': 0.016883305541932278, 'w4': 0.00018675030501382264}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:01,918]\u001b[0m Trial 576 finished with value: 0.7665681425402022 and parameters: {'w0': 0.972945009038778, 'w1': 0.00031929083364203026, 'w2': 0.017169110217276032, 'w3': 0.0822830199231986, 'w4': 0.04648662313930715}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:02,067]\u001b[0m Trial 577 finished with value: 0.7665237997333205 and parameters: {'w0': 0.9477043064815018, 'w1': 0.018185788177994953, 'w2': 0.06148335486931067, 'w3': 0.0427558222145339, 'w4': 0.03320501845146077}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:02,210]\u001b[0m Trial 578 finished with value: 0.7662585421604182 and parameters: {'w0': 0.9267333691604597, 'w1': 0.03803584093100305, 'w2': 0.03226965388016612, 'w3': 0.06691957148724263, 'w4': 0.8239649330786234}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:02,353]\u001b[0m Trial 579 finished with value: 0.7665287310684622 and parameters: {'w0': 0.9049468461238478, 'w1': 0.01677186588702637, 'w2': 0.048257588719788254, 'w3': 0.10292651596232044, 'w4': 0.0974263442498594}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:02,505]\u001b[0m Trial 580 finished with value: 0.7665513910812564 and parameters: {'w0': 0.8538372994599727, 'w1': 0.0005917468982898367, 'w2': 0.020540843369611896, 'w3': 0.1304100184873236, 'w4': 0.07027057773151524}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:02,652]\u001b[0m Trial 581 finished with value: 0.7665552814285691 and parameters: {'w0': 0.8801978398934746, 'w1': 0.05406329950246817, 'w2': 0.0008402302886639766, 'w3': 0.09411511111050334, 'w4': 0.021548328368408875}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:02,796]\u001b[0m Trial 582 finished with value: 0.7665639062023157 and parameters: {'w0': 0.957933681992057, 'w1': 0.00045210571814782263, 'w2': 0.06313550527561304, 'w3': 0.059053169032025454, 'w4': 0.016017704240203642}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:02,940]\u001b[0m Trial 583 finished with value: 0.7665264125438316 and parameters: {'w0': 0.9829474434045262, 'w1': 0.03333975936765077, 'w2': 0.09401560347301605, 'w3': 0.08296525594420934, 'w4': 0.04677116881530622}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:03,087]\u001b[0m Trial 584 finished with value: 0.7665647800116356 and parameters: {'w0': 0.9349261588054126, 'w1': 0.033314929308030594, 'w2': 0.03827461801122811, 'w3': 0.11371325656391969, 'w4': 0.017037599576847782}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:03,232]\u001b[0m Trial 585 finished with value: 0.7662101732814035 and parameters: {'w0': 0.9085693857612246, 'w1': 0.0641545141861883, 'w2': 0.017773305307992496, 'w3': 0.04003119212409581, 'w4': 0.9112922155972767}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:03,375]\u001b[0m Trial 586 finished with value: 0.7665815909309789 and parameters: {'w0': 0.8853420472364972, 'w1': 0.00019184406101418073, 'w2': 0.04750725619005627, 'w3': 0.07204835616316811, 'w4': 1.959506837987524e-05}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:03,521]\u001b[0m Trial 587 finished with value: 0.7664953776633094 and parameters: {'w0': 0.8566622624764186, 'w1': 0.19867903557982458, 'w2': 0.07479882527763132, 'w3': 0.13641965724845503, 'w4': 0.015364586426378194}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:03,674]\u001b[0m Trial 588 finished with value: 0.7665825259241862 and parameters: {'w0': 0.8814439812750857, 'w1': 0.016822957335504398, 'w2': 2.8986891509999988e-05, 'w3': 0.10495065674580702, 'w4': 0.00032178649332808423}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:03,831]\u001b[0m Trial 589 finished with value: 0.7665452132321293 and parameters: {'w0': 0.8908984556975131, 'w1': 0.10102112865941214, 'w2': 0.0014510482317098387, 'w3': 0.1093457869468286, 'w4': 0.0005596789911725512}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:03,982]\u001b[0m Trial 590 finished with value: 0.7664191558967844 and parameters: {'w0': 0.9997193408097806, 'w1': 0.07887793501865348, 'w2': 0.07117976172158275, 'w3': 0.1373667847635773, 'w4': 0.3902360397917354}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:04,136]\u001b[0m Trial 591 finished with value: 0.7665614704803798 and parameters: {'w0': 0.9669748741262377, 'w1': 0.0502552579127625, 'w2': 0.05275393262752399, 'w3': 0.11903265976999612, 'w4': 0.0014915219501656638}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:19:04,286]\u001b[0m Trial 592 finished with value: 0.7665544507064936 and parameters: {'w0': 0.9416015169501336, 'w1': 0.03330735700077538, 'w2': 0.09495664540947871, 'w3': 0.09768703567526593, 'w4': 0.0008019303868546459}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:04,432]\u001b[0m Trial 593 finished with value: 0.766415056145463 and parameters: {'w0': 0.887424703637477, 'w1': 0.4927417219409331, 'w2': 0.031021920949521893, 'w3': 0.11889655118625853, 'w4': 0.018592459451215727}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:04,578]\u001b[0m Trial 594 finished with value: 0.7665736180672427 and parameters: {'w0': 0.9230442070824931, 'w1': 0.018444077158569216, 'w2': 0.04724722386598465, 'w3': 0.08666408524505889, 'w4': 0.0005572860794890578}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:04,723]\u001b[0m Trial 595 finished with value: 0.7663577345987707 and parameters: {'w0': 0.9188046150305622, 'w1': 0.06183200905497207, 'w2': 0.07847089673305306, 'w3': 0.979554745787522, 'w4': 0.0005958213384958382}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:04,867]\u001b[0m Trial 596 finished with value: 0.7665600843637219 and parameters: {'w0': 0.8987435710392663, 'w1': 0.043232877694196585, 'w2': 0.048019627873362496, 'w3': 0.0890324521067041, 'w4': 0.0003164250397085314}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:05,021]\u001b[0m Trial 597 finished with value: 0.7665777014454112 and parameters: {'w0': 0.8733409489315834, 'w1': 0.020664737047859642, 'w2': 0.0006280051475985686, 'w3': 0.07925649633883644, 'w4': 0.018553136164693194}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:05,173]\u001b[0m Trial 598 finished with value: 0.7664013776688005 and parameters: {'w0': 0.8374258257048007, 'w1': 0.07542677453653947, 'w2': 0.015723360012339135, 'w3': 0.6729796730899329, 'w4': 0.030711839356940215}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:05,325]\u001b[0m Trial 599 finished with value: 0.7665584479101728 and parameters: {'w0': 0.870835054837911, 'w1': 0.04579670701351105, 'w2': 0.0024501410841279753, 'w3': 0.07697955069867145, 'w4': 0.01696305712986726}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:05,475]\u001b[0m Trial 600 finished with value: 0.7662961112215803 and parameters: {'w0': 0.8603036168789149, 'w1': 0.027414381882451478, 'w2': 0.0011387897998790032, 'w3': 0.07382398150278893, 'w4': 0.6651167121520306}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:05,632]\u001b[0m Trial 601 finished with value: 0.76656784265298 and parameters: {'w0': 0.8333619246260136, 'w1': 0.022200979024789947, 'w2': 0.000669684231452606, 'w3': 0.08726122540511864, 'w4': 0.0312846572391088}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:05,785]\u001b[0m Trial 602 finished with value: 0.7665531184488915 and parameters: {'w0': 0.8514060406428067, 'w1': 0.052467133232188476, 'w2': 0.027033068217118112, 'w3': 0.06910683147163299, 'w4': 0.0006332885374234244}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:05,934]\u001b[0m Trial 603 finished with value: 0.76652553140968 and parameters: {'w0': 0.873170923739021, 'w1': 0.09378720940476051, 'w2': 0.02080236681672531, 'w3': 0.09632792142432157, 'w4': 0.03186820851334488}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:06,083]\u001b[0m Trial 604 finished with value: 0.7665681274596666 and parameters: {'w0': 0.8770939135750934, 'w1': 0.020703393316529945, 'w2': 0.04049076013200735, 'w3': 0.10612293877456837, 'w4': 0.017739972247608194}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:06,233]\u001b[0m Trial 605 finished with value: 0.7665228983481642 and parameters: {'w0': 0.894762907288499, 'w1': 0.06665592039083974, 'w2': 0.0001984342239265239, 'w3': 0.0681541074047281, 'w4': 0.05186655960758541}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:06,382]\u001b[0m Trial 606 finished with value: 0.766535265249102 and parameters: {'w0': 0.8811496199307255, 'w1': 0.034244320828531516, 'w2': 0.03554323245548198, 'w3': 0.04131170568850605, 'w4': 0.01670467266285787}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:06,528]\u001b[0m Trial 607 finished with value: 0.766571245252684 and parameters: {'w0': 0.9071509476608426, 'w1': 0.017461641870639828, 'w2': 0.05423154831981558, 'w3': 0.08190101693787873, 'w4': 0.00011412279744010833}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:06,669]\u001b[0m Trial 608 finished with value: 0.7665473917232151 and parameters: {'w0': 0.8527809754834054, 'w1': 0.044664712101593534, 'w2': 0.020614913401535814, 'w3': 0.1031389859148253, 'w4': 0.039070604514802015}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:06,820]\u001b[0m Trial 609 finished with value: 0.7664452228180073 and parameters: {'w0': 0.917235107735454, 'w1': 0.018543497472332707, 'w2': 0.019900586369929158, 'w3': 0.002862658325966397, 'w4': 0.016474744792759562}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:06,965]\u001b[0m Trial 610 finished with value: 0.7665535174367761 and parameters: {'w0': 0.8145038350379676, 'w1': 0.03288842835702954, 'w2': 0.047941589629569056, 'w3': 0.05566883119318957, 'w4': 0.00032459069523029963}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:07,116]\u001b[0m Trial 611 finished with value: 0.7664929669319756 and parameters: {'w0': 0.8935205866848482, 'w1': 0.016862505981568812, 'w2': 0.03112202629620195, 'w3': 0.3817648750865528, 'w4': 0.03616281982688674}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:07,263]\u001b[0m Trial 612 finished with value: 0.7665215320516388 and parameters: {'w0': 0.9243841929808148, 'w1': 0.0541027821845667, 'w2': 0.05888532159784243, 'w3': 0.08151268763798244, 'w4': 0.05093584709760776}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:07,407]\u001b[0m Trial 613 finished with value: 0.7665471215661915 and parameters: {'w0': 0.8859502017679401, 'w1': 0.019381833558997984, 'w2': 0.016473158271776256, 'w3': 0.030953440033206492, 'w4': 0.019165979710391683}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:07,551]\u001b[0m Trial 614 finished with value: 0.7665589421208681 and parameters: {'w0': 0.907593822830507, 'w1': 0.03593688774341314, 'w2': 0.000185367018696557, 'w3': 0.12575296261753294, 'w4': 0.027762567823709162}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:07,695]\u001b[0m Trial 615 finished with value: 0.7665711586473224 and parameters: {'w0': 0.9291187697228059, 'w1': 0.018554680702197332, 'w2': 0.03991516923707277, 'w3': 0.06594543610993306, 'w4': 0.0006346158877516862}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:07,841]\u001b[0m Trial 616 finished with value: 0.7664083896869825 and parameters: {'w0': 0.864599154972548, 'w1': 0.07492095764557853, 'w2': 0.5856853320473746, 'w3': 0.10121660928983452, 'w4': 0.0572469382826668}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:07,985]\u001b[0m Trial 617 finished with value: 0.7665615540696343 and parameters: {'w0': 0.9002837171758241, 'w1': 0.0007303600917267748, 'w2': 0.020034129831795713, 'w3': 0.046464311134489816, 'w4': 0.03512574408682024}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:08,130]\u001b[0m Trial 618 finished with value: 0.766549603391479 and parameters: {'w0': 0.9288566555956131, 'w1': 0.0532029228402799, 'w2': 0.06657671580787694, 'w3': 0.14250979570883837, 'w4': 0.020122652150320434}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:08,274]\u001b[0m Trial 619 finished with value: 0.7665774153461071 and parameters: {'w0': 0.8432510540035046, 'w1': 0.0002887238115132848, 'w2': 0.042850317581443316, 'w3': 0.08549332886057327, 'w4': 0.0170854506832722}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:19:08,423]\u001b[0m Trial 620 finished with value: 0.7665287000456461 and parameters: {'w0': 0.8256739551397053, 'w1': 0.018493317808936007, 'w2': 0.020065696973685963, 'w3': 0.06199985499909059, 'w4': 0.0706249612997032}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:08,571]\u001b[0m Trial 621 finished with value: 0.7665639307620451 and parameters: {'w0': 0.8598006815257472, 'w1': 0.0005062955177585686, 'w2': 0.03431853057656564, 'w3': 0.11003174947439608, 'w4': 0.04744037220175641}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:08,715]\u001b[0m Trial 622 finished with value: 0.7665819321819559 and parameters: {'w0': 0.8478309833303656, 'w1': 0.000522998880203163, 'w2': 3.3448631958322636e-05, 'w3': 0.0789725384500189, 'w4': 0.03537320271552169}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:08,859]\u001b[0m Trial 623 finished with value: 0.7665333672559784 and parameters: {'w0': 0.8399578285992232, 'w1': 0.03725117726016703, 'w2': 0.01689247551775914, 'w3': 0.09036775871303204, 'w4': 0.06765131852080035}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:09,004]\u001b[0m Trial 624 finished with value: 0.7665437663624566 and parameters: {'w0': 0.8323128899323978, 'w1': 0.01755089216500118, 'w2': 0.003128703027016869, 'w3': 0.11780861700665551, 'w4': 0.08640988310185126}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:09,148]\u001b[0m Trial 625 finished with value: 0.7664345164994752 and parameters: {'w0': 0.8406653365691635, 'w1': 0.5278493645811333, 'w2': 9.988866692925788e-05, 'w3': 0.9018650740776064, 'w4': 0.05052738609695352}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:09,292]\u001b[0m Trial 626 finished with value: 0.7665445449489661 and parameters: {'w0': 0.8043600689295909, 'w1': 0.04060671247051739, 'w2': 1.9674184977426512e-05, 'w3': 0.07597702208365498, 'w4': 0.04203657576606946}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:09,442]\u001b[0m Trial 627 finished with value: 0.7665603898522859 and parameters: {'w0': 0.81609267076521, 'w1': 0.0004994484072383888, 'w2': 0.0005221144676631939, 'w3': 0.09538665192641392, 'w4': 0.0655166086585389}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:09,585]\u001b[0m Trial 628 finished with value: 0.7665467419675669 and parameters: {'w0': 0.8213030274801172, 'w1': 0.03196477195246101, 'w2': 0.021362828684562782, 'w3': 0.13635148012059686, 'w4': 0.03233705795920227}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:09,729]\u001b[0m Trial 629 finished with value: 0.7665653655672894 and parameters: {'w0': 0.7807014732778612, 'w1': 0.00013675573332751423, 'w2': 0.02882386686708259, 'w3': 0.10939996226512476, 'w4': 0.032937890272167133}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:09,874]\u001b[0m Trial 630 finished with value: 0.7665462994615652 and parameters: {'w0': 0.8530344405997642, 'w1': 0.019691721959763816, 'w2': 0.01999102047889124, 'w3': 0.08008602635624212, 'w4': 0.054513877932438184}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:10,021]\u001b[0m Trial 631 finished with value: 0.7665388406286568 and parameters: {'w0': 0.834108463755557, 'w1': 0.06319173389581463, 'w2': 0.051858646937369905, 'w3': 0.09986044141303305, 'w4': 0.01933043872700267}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:10,167]\u001b[0m Trial 632 finished with value: 0.76649767679868 and parameters: {'w0': 0.8625686294787653, 'w1': 0.034265430657323626, 'w2': 0.32342987902729536, 'w3': 0.1260417357895023, 'w4': 0.029493909280221567}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:10,312]\u001b[0m Trial 633 finished with value: 0.7663326405875305 and parameters: {'w0': 0.8624942916379017, 'w1': 0.017055459685236106, 'w2': 0.9525057277575708, 'w3': 0.06698869599353757, 'w4': 0.07854173410409557}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:10,458]\u001b[0m Trial 634 finished with value: 0.766539969945337 and parameters: {'w0': 0.8001359572561388, 'w1': 0.050505591675243065, 'w2': 0.03541468515085268, 'w3': 0.14858242860198506, 'w4': 0.017450183780870314}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:10,607]\u001b[0m Trial 635 finished with value: 0.7664825350791915 and parameters: {'w0': 0.8390129808523606, 'w1': 0.16346138275820804, 'w2': 0.01708996010192603, 'w3': 0.08478649922733242, 'w4': 0.05104819998431649}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:10,756]\u001b[0m Trial 636 finished with value: 0.7665586784269314 and parameters: {'w0': 0.8767353963979515, 'w1': 0.00030714536667295544, 'w2': 0.06741412809998559, 'w3': 0.05684056260021087, 'w4': 0.018726971629931213}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:10,907]\u001b[0m Trial 637 finished with value: 0.7665652544021985 and parameters: {'w0': 0.8461848205598346, 'w1': 0.01820223454021912, 'w2': 0.0010082792783930035, 'w3': 0.1025504647229035, 'w4': 0.03937238653827911}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:11,053]\u001b[0m Trial 638 finished with value: 0.7665500053954709 and parameters: {'w0': 0.8111106418522455, 'w1': 0.03546296958797228, 'w2': 0.03420525298194656, 'w3': 0.07429413173816883, 'w4': 0.022049145211588992}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:11,198]\u001b[0m Trial 639 finished with value: 0.76651415422275 and parameters: {'w0': 0.8745794269735832, 'w1': 0.11222670435483488, 'w2': 0.053598024901259256, 'w3': 0.11783323309282122, 'w4': 0.04272571029078804}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:11,343]\u001b[0m Trial 640 finished with value: 0.7665118740457674 and parameters: {'w0': 0.9477888664857362, 'w1': 0.0005108758151448634, 'w2': 0.018494723590938015, 'w3': 0.3108536907141237, 'w4': 0.06629347508005519}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:11,491]\u001b[0m Trial 641 finished with value: 0.766561143017321 and parameters: {'w0': 0.8879903739201095, 'w1': 0.04848494066569159, 'w2': 0.0007698437844352566, 'w3': 0.0914807688820591, 'w4': 0.017292487105555178}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:11,637]\u001b[0m Trial 642 finished with value: 0.7665599400214526 and parameters: {'w0': 0.9494832852914539, 'w1': 0.019117371150719518, 'w2': 0.03482723561769235, 'w3': 0.05364996660145465, 'w4': 0.015922106096738303}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:11,802]\u001b[0m Trial 643 finished with value: 0.7665135548791782 and parameters: {'w0': 0.853589199574928, 'w1': 0.03165991238642733, 'w2': 0.075659178723762, 'w3': 0.1297182358640864, 'w4': 0.12586055453082212}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:11,945]\u001b[0m Trial 644 finished with value: 0.7665605600469019 and parameters: {'w0': 0.9770183678575948, 'w1': 0.018053528531840057, 'w2': 0.01889050554971734, 'w3': 0.07772548235788469, 'w4': 0.03666927293362212}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:12,095]\u001b[0m Trial 645 finished with value: 0.7665515164651383 and parameters: {'w0': 0.9104472777525189, 'w1': 0.08753531140837435, 'w2': 0.00029875354015915863, 'w3': 0.107346130081264, 'w4': 0.0003805227503714}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:12,240]\u001b[0m Trial 646 finished with value: 0.7663720973008773 and parameters: {'w0': 0.6103272176203136, 'w1': 0.0658355429436257, 'w2': 0.40571730080788143, 'w3': 0.05439479845345432, 'w4': 0.05633584432142045}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:12,386]\u001b[0m Trial 647 finished with value: 0.766561532526012 and parameters: {'w0': 0.8868605175534866, 'w1': 0.03836755110365373, 'w2': 0.05281647142874729, 'w3': 0.09235954704540983, 'w4': 0.00036682628994483984}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:19:12,534]\u001b[0m Trial 648 finished with value: 0.7665419144726848 and parameters: {'w0': 0.8263004618080066, 'w1': 0.000811151126878688, 'w2': 0.03570123006885486, 'w3': 0.14862061458841802, 'w4': 0.09631004298401052}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:12,682]\u001b[0m Trial 649 finished with value: 0.7665571190995502 and parameters: {'w0': 0.9429082430690213, 'w1': 0.019233373452703578, 'w2': 0.021178111149959353, 'w3': 0.06897317756313136, 'w4': 0.0339775012433174}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:12,830]\u001b[0m Trial 650 finished with value: 0.7665730661196398 and parameters: {'w0': 0.8710285448322028, 'w1': 0.00010507242960179283, 'w2': 0.057147408469504196, 'w3': 0.11714522924331121, 'w4': 0.017578875217118293}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:12,976]\u001b[0m Trial 651 finished with value: 0.7665424556484766 and parameters: {'w0': 0.9640487597253924, 'w1': 0.04874444931749798, 'w2': 0.034270432900768436, 'w3': 0.08580875836928112, 'w4': 0.034681628375910115}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:13,122]\u001b[0m Trial 652 finished with value: 0.7665163365916878 and parameters: {'w0': 0.9096404010218883, 'w1': 0.03195251837096211, 'w2': 0.081282075037371, 'w3': 0.042771739674846605, 'w4': 0.01534453899974301}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:13,267]\u001b[0m Trial 653 finished with value: 0.7665486748613584 and parameters: {'w0': 0.932282808211143, 'w1': 0.018688620928939647, 'w2': 0.019837865611034917, 'w3': 0.0998976684369739, 'w4': 0.0650868656314714}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:13,413]\u001b[0m Trial 654 finished with value: 0.7665271743263158 and parameters: {'w0': 0.8928830773401927, 'w1': 0.06538547661437175, 'w2': 0.0006415311505875345, 'w3': 0.07085183669547376, 'w4': 0.047703174121487}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:13,559]\u001b[0m Trial 655 finished with value: 0.7664457859682937 and parameters: {'w0': 0.7890197880443652, 'w1': 0.37760676781219915, 'w2': 0.04439251215881388, 'w3': 0.1298671715830627, 'w4': 0.021915693644073947}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:13,706]\u001b[0m Trial 656 finished with value: 0.7665739226940619 and parameters: {'w0': 0.9838743033745437, 'w1': 0.0002542180794517472, 'w2': 0.06173484461845198, 'w3': 0.057895958498483564, 'w4': 0.0011984838586206609}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:13,851]\u001b[0m Trial 657 finished with value: 0.7665567451022673 and parameters: {'w0': 0.8539948488049467, 'w1': 0.031222232358746313, 'w2': 0.09672181601100645, 'w3': 0.1107227221517674, 'w4': 0.0001871717316400505}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:13,997]\u001b[0m Trial 658 finished with value: 0.7665642586559763 and parameters: {'w0': 0.9554660300669597, 'w1': 0.01765471364849172, 'w2': 0.019303215328425053, 'w3': 0.08144444060778623, 'w4': 0.032392632845581665}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:14,145]\u001b[0m Trial 659 finished with value: 0.7664743946060739 and parameters: {'w0': 0.999313687482356, 'w1': 0.0434484169331318, 'w2': 0.04418237441127396, 'w3': 0.028999906999588335, 'w4': 0.04697684630687261}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:14,289]\u001b[0m Trial 660 finished with value: 0.7665838672301097 and parameters: {'w0': 0.9229015885614377, 'w1': 0.017181944012058203, 'w2': 0.0004724333278569971, 'w3': 0.09729967545895947, 'w4': 0.016256322902437708}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:14,434]\u001b[0m Trial 661 finished with value: 0.766513571252331 and parameters: {'w0': 0.9209858788591173, 'w1': 0.0585578527992731, 'w2': 0.0004890645160714202, 'w3': 0.061635583643203845, 'w4': 0.06933104370909006}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:14,579]\u001b[0m Trial 662 finished with value: 0.7665315145044618 and parameters: {'w0': 0.8764918203754335, 'w1': 0.08545527962001448, 'w2': 0.0002869647934887684, 'w3': 0.09150660194779323, 'w4': 0.034451710627813215}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:14,725]\u001b[0m Trial 663 finished with value: 0.7664984166066693 and parameters: {'w0': 0.9135653684563868, 'w1': 0.04659979856245651, 'w2': 0.02335298992336014, 'w3': 0.039803801679332146, 'w4': 0.051845919538092436}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:14,870]\u001b[0m Trial 664 finished with value: 0.7665366358543519 and parameters: {'w0': 0.8946349386569101, 'w1': 0.0210387008841613, 'w2': 0.00016017662446043968, 'w3': 0.0767477603958021, 'w4': 0.08132157455757422}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:15,020]\u001b[0m Trial 665 finished with value: 0.7665675621550179 and parameters: {'w0': 0.9387920149377984, 'w1': 0.03259932637777406, 'w2': 0.020360614876459557, 'w3': 0.09974614755283781, 'w4': 0.017365483368423484}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:15,168]\u001b[0m Trial 666 finished with value: 0.7662526073233504 and parameters: {'w0': 0.8650943732916794, 'w1': 0.0001669816301560213, 'w2': 0.6885386658661413, 'w3': 0.06633607406299598, 'w4': 0.7267536896530017}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:15,317]\u001b[0m Trial 667 finished with value: 0.7663814377537561 and parameters: {'w0': 0.8434192296704405, 'w1': 0.3153605862325623, 'w2': 0.03228704030263943, 'w3': 0.04985139973356385, 'w4': 0.020023885830460372}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:15,465]\u001b[0m Trial 668 finished with value: 0.7665661217484316 and parameters: {'w0': 0.9056652427875401, 'w1': 0.018103379630779036, 'w2': 0.019563443619681525, 'w3': 0.10409203246896936, 'w4': 0.03493696514038836}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:15,612]\u001b[0m Trial 669 finished with value: 0.7665286483409526 and parameters: {'w0': 0.9309410834649581, 'w1': 0.06383122697784276, 'w2': 0.00015505382426186237, 'w3': 0.07930291653584269, 'w4': 0.05695412138654962}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:15,758]\u001b[0m Trial 670 finished with value: 0.7665065157160319 and parameters: {'w0': 0.9637566983765116, 'w1': 0.033963325579045085, 'w2': 0.038467592133308484, 'w3': 0.024851130260920895, 'w4': 0.015314875062247194}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:15,905]\u001b[0m Trial 671 finished with value: 0.7665623934091585 and parameters: {'w0': 0.8825237582978279, 'w1': 0.018815513668745412, 'w2': 0.018718172969519106, 'w3': 0.11669298319467425, 'w4': 0.03663850553643255}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:16,050]\u001b[0m Trial 672 finished with value: 0.7665607479072883 and parameters: {'w0': 0.9176113729972479, 'w1': 0.04742103216566533, 'w2': 0.03514903111086248, 'w3': 0.08888806088725902, 'w4': 0.000761650503261377}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:16,196]\u001b[0m Trial 673 finished with value: 0.7665797093110083 and parameters: {'w0': 0.9449005489555046, 'w1': 0.015337679742509505, 'w2': 0.01794858087528608, 'w3': 0.05639289608991796, 'w4': 7.811951063677741e-05}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:16,343]\u001b[0m Trial 674 finished with value: 0.7664869084345158 and parameters: {'w0': 0.8237540823244778, 'w1': 0.05094223556806281, 'w2': 0.019524925675918688, 'w3': 0.022337164054572534, 'w4': 0.020380608602304562}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:16,489]\u001b[0m Trial 675 finished with value: 0.7665257533089898 and parameters: {'w0': 0.948037025388056, 'w1': 0.03315194186134326, 'w2': 0.016059286860720053, 'w3': 0.04659300791804731, 'w4': 0.04875679494604348}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:19:16,633]\u001b[0m Trial 676 finished with value: 0.7665256748902045 and parameters: {'w0': 0.9748467061381344, 'w1': 0.0754822671838078, 'w2': 0.0169961487972696, 'w3': 0.05373977266541909, 'w4': 0.017448744596977917}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:16,781]\u001b[0m Trial 677 finished with value: 0.7665002275635588 and parameters: {'w0': 0.9062474854867644, 'w1': 0.00019279263481808417, 'w2': 0.03784348222600868, 'w3': 0.03683867152822144, 'w4': 0.07817976493992697}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:16,930]\u001b[0m Trial 678 finished with value: 0.7665635261728185 and parameters: {'w0': 0.8754639439316517, 'w1': 0.018619799914220785, 'w2': 0.00022874311461522497, 'w3': 0.0668332477185986, 'w4': 0.03345268368336928}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:17,077]\u001b[0m Trial 679 finished with value: 0.7662763880353761 and parameters: {'w0': 0.9375957384128732, 'w1': 0.047338266946979644, 'w2': 0.9982200548571876, 'w3': 0.016495668534908487, 'w4': 0.015605947819037076}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:17,228]\u001b[0m Trial 680 finished with value: 0.7665255443358534 and parameters: {'w0': 0.846491640854815, 'w1': 0.021056499578882504, 'w2': 0.03949968928328758, 'w3': 0.05781081439453907, 'w4': 0.05804956513741814}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:17,376]\u001b[0m Trial 681 finished with value: 0.7665483775593709 and parameters: {'w0': 0.8944990219618348, 'w1': 0.03724237995217425, 'w2': 0.018277824600977925, 'w3': 0.07272403872413512, 'w4': 0.031965699686980584}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:17,524]\u001b[0m Trial 682 finished with value: 0.7663444490777785 and parameters: {'w0': 0.9582982942979621, 'w1': 0.06858511504069596, 'w2': 0.560854233635619, 'w3': 0.03514353947600697, 'w4': 0.00021239083072145323}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:17,672]\u001b[0m Trial 683 finished with value: 0.7664464396017939 and parameters: {'w0': 0.9248067191002792, 'w1': 0.017795735688535128, 'w2': 0.44372997629259325, 'w3': 0.0828835855006469, 'w4': 0.018391311516824185}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:17,816]\u001b[0m Trial 684 finished with value: 0.7665680473173917 and parameters: {'w0': 0.9838747859981853, 'w1': 0.01667559319698147, 'w2': 0.05067185450450562, 'w3': 0.061101757204928525, 'w4': 0.0007068272152469038}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:17,964]\u001b[0m Trial 685 finished with value: 0.7665638066707807 and parameters: {'w0': 0.7385955997291141, 'w1': 6.325806170596473e-05, 'w2': 0.01942650181399224, 'w3': 0.0886512103669267, 'w4': 0.04624105061648043}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:18,110]\u001b[0m Trial 686 finished with value: 0.7664687799072334 and parameters: {'w0': 0.8651764341406898, 'w1': 0.050514603495323336, 'w2': 0.03713833822728724, 'w3': 0.05067355834056431, 'w4': 0.10169929868117261}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:18,256]\u001b[0m Trial 687 finished with value: 0.766576852626693 and parameters: {'w0': 0.902586986335721, 'w1': 0.03418458238682967, 'w2': 0.01642790361972877, 'w3': 0.09956984959361914, 'w4': 9.452792733125048e-05}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:18,406]\u001b[0m Trial 688 finished with value: 0.7665484521003041 and parameters: {'w0': 0.8909991906002211, 'w1': 0.0768502631200029, 'w2': 0.0005281803847553157, 'w3': 0.09936199269049663, 'w4': 0.015606111597587033}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:18,551]\u001b[0m Trial 689 finished with value: 0.7665603976079899 and parameters: {'w0': 0.9414787916513164, 'w1': 0.05739261666497848, 'w2': 0.0001864977643404301, 'w3': 0.07149670632948928, 'w4': 0.000645098561609356}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:18,696]\u001b[0m Trial 690 finished with value: 0.7664602288126751 and parameters: {'w0': 0.8549652271012245, 'w1': 0.09384735085453946, 'w2': 0.0001544955400514094, 'w3': 0.4433744631371046, 'w4': 0.0005384707265089946}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:18,841]\u001b[0m Trial 691 finished with value: 0.7665566128244264 and parameters: {'w0': 0.9066604460696341, 'w1': 0.03527595098353964, 'w2': 0.01978121339602725, 'w3': 0.10532748465553288, 'w4': 0.034260089656635705}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:18,990]\u001b[0m Trial 692 finished with value: 0.7665075222340654 and parameters: {'w0': 0.8803462272297797, 'w1': 0.06283910587847504, 'w2': 0.019367660408092693, 'w3': 0.04054309240494322, 'w4': 0.02956154634652622}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:19,136]\u001b[0m Trial 693 finished with value: 0.7664579813819982 and parameters: {'w0': 0.8043153643499376, 'w1': 0.036481460872011054, 'w2': 0.032168280255164584, 'w3': 0.012802294769057879, 'w4': 0.018207949800329932}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:19,286]\u001b[0m Trial 694 finished with value: 0.7663115248215818 and parameters: {'w0': 0.9637825477183078, 'w1': 0.7266414486170929, 'w2': 0.01797679452494938, 'w3': 0.06969166821276608, 'w4': 0.0492682715519968}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:19,436]\u001b[0m Trial 695 finished with value: 0.7665556312969951 and parameters: {'w0': 0.9256175951403228, 'w1': 0.032982304506889104, 'w2': 0.04691074563007874, 'w3': 0.08403068148525213, 'w4': 0.018712127996863864}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:19,583]\u001b[0m Trial 696 finished with value: 0.7665351838142097 and parameters: {'w0': 0.8299403328473116, 'w1': 0.04941519762899402, 'w2': 0.019634270062402398, 'w3': 0.11755594438133088, 'w4': 0.06450072504634494}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:19,728]\u001b[0m Trial 697 finished with value: 0.7664330157707467 and parameters: {'w0': 0.9013681323489555, 'w1': 0.13034929589470678, 'w2': 0.001000628151046637, 'w3': 0.6417436142249546, 'w4': 0.03488118634252817}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:19,874]\u001b[0m Trial 698 finished with value: 0.7663514718677717 and parameters: {'w0': 0.9508043421319776, 'w1': 0.019764057377001355, 'w2': 0.7536496872312508, 'w3': 0.05026246754513237, 'w4': 5.919112526795757e-05}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:20,024]\u001b[0m Trial 699 finished with value: 0.7665915703676948 and parameters: {'w0': 0.8680585435361163, 'w1': 0.00023584068215588838, 'w2': 0.02908104235068172, 'w3': 0.09419385449023027, 'w4': 0.0006921451002683224}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:20,170]\u001b[0m Trial 700 finished with value: 0.7665094521117498 and parameters: {'w0': 0.8602363805233191, 'w1': 0.016087093941209805, 'w2': 0.0585807047206575, 'w3': 0.2899498748082079, 'w4': 0.19867782247293492}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:20,317]\u001b[0m Trial 701 finished with value: 0.7665655435176095 and parameters: {'w0': 0.8461502462303409, 'w1': 0.01581536254574685, 'w2': 0.03916754192027755, 'w3': 0.07014454627741656, 'w4': 0.013776655283349384}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:20,464]\u001b[0m Trial 702 finished with value: 0.7664727180813876 and parameters: {'w0': 0.8753070890828144, 'w1': 0.7985402956516929, 'w2': 0.05690966349413486, 'w3': 0.5119953194153417, 'w4': 0.00037554425668605285}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:20,612]\u001b[0m Trial 703 finished with value: 0.7665701090420444 and parameters: {'w0': 0.8190788015380812, 'w1': 0.0003887017127187503, 'w2': 0.0335131917450083, 'w3': 0.09013446460729048, 'w4': 0.03387099037017449}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:19:20,757]\u001b[0m Trial 704 finished with value: 0.7664367699623665 and parameters: {'w0': 0.886503513346481, 'w1': 0.00044564152213460415, 'w2': 0.03509293338082071, 'w3': 0.0007658948398624257, 'w4': 0.019750958232794796}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:20,903]\u001b[0m Trial 705 finished with value: 0.7665115888082082 and parameters: {'w0': 0.8615742049422908, 'w1': 0.01678219023020925, 'w2': 0.06459073648056032, 'w3': 0.028203914622375162, 'w4': 0.017479022261123002}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:21,050]\u001b[0m Trial 706 finished with value: 0.7665237588004383 and parameters: {'w0': 0.8331360117924816, 'w1': 0.033554853451395326, 'w2': 0.04734881906723466, 'w3': 0.05727472371994115, 'w4': 0.04250428777369462}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:21,194]\u001b[0m Trial 707 finished with value: 0.7665876235760918 and parameters: {'w0': 0.8751922567355517, 'w1': 0.0005434709709023246, 'w2': 0.01992071101988178, 'w3': 0.07992412103462408, 'w4': 0.015768580610705046}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:21,341]\u001b[0m Trial 708 finished with value: 0.7665601145247931 and parameters: {'w0': 0.848957221701992, 'w1': 0.01671546753900647, 'w2': 0.02262383175762148, 'w3': 0.0437620082469383, 'w4': 0.016991812098298004}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:21,494]\u001b[0m Trial 709 finished with value: 0.766564533983469 and parameters: {'w0': 0.8693953245392808, 'w1': 0.00020011486581865542, 'w2': 0.03401019704929046, 'w3': 0.07319232423837539, 'w4': 0.03634265757236388}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:21,645]\u001b[0m Trial 710 finished with value: 0.7665782413285857 and parameters: {'w0': 0.8787215430078533, 'w1': 0.00013057168328022738, 'w2': 0.05138855387382137, 'w3': 0.061163163958500535, 'w4': 0.0001365720339342666}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:21,789]\u001b[0m Trial 711 finished with value: 0.7663530932407852 and parameters: {'w0': 0.8795057042562255, 'w1': 0.000656076406737804, 'w2': 0.494674479073594, 'w3': 0.025645765001727973, 'w4': 0.002277044922393813}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:21,937]\u001b[0m Trial 712 finished with value: 0.766315585794383 and parameters: {'w0': 0.8914788952790582, 'w1': 0.03402259779237611, 'w2': 0.8523235111231406, 'w3': 0.04262204294539411, 'w4': 0.05255647239847774}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:22,086]\u001b[0m Trial 713 finished with value: 0.7665766828629493 and parameters: {'w0': 0.889098522066816, 'w1': 0.017164927690610267, 'w2': 0.01832925198285981, 'w3': 0.05581694681021221, 'w4': 0.0002821903245897013}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:22,235]\u001b[0m Trial 714 finished with value: 0.7664790131278199 and parameters: {'w0': 0.8705303443097409, 'w1': 0.04888291380401127, 'w2': 0.05476326812087186, 'w3': 0.020206569741385835, 'w4': 0.0006943541817760134}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:22,384]\u001b[0m Trial 715 finished with value: 0.7665336848089709 and parameters: {'w0': 0.8854970163554048, 'w1': 0.030799272159486343, 'w2': 0.05085332699972715, 'w3': 0.04534703736817483, 'w4': 0.01749068642374541}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:22,530]\u001b[0m Trial 716 finished with value: 0.7665714675828661 and parameters: {'w0': 0.8630244525822378, 'w1': 0.018232882213605264, 'w2': 0.031909146811845764, 'w3': 0.05958887610477149, 'w4': 0.0009068905424237986}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:22,684]\u001b[0m Trial 717 finished with value: 0.7662641409169783 and parameters: {'w0': 0.8937955804499071, 'w1': 0.04710359443388914, 'w2': 0.019656119118372464, 'w3': 0.029488350160835453, 'w4': 0.45283123509397416}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:22,829]\u001b[0m Trial 718 finished with value: 0.7665639764345242 and parameters: {'w0': 0.8519088490611469, 'w1': 0.01745801663547365, 'w2': 0.0663045710125116, 'w3': 0.07227399895587178, 'w4': 0.0004890798002837929}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:22,978]\u001b[0m Trial 719 finished with value: 0.7665153089609047 and parameters: {'w0': 0.8683844348323979, 'w1': 0.06528003547054924, 'w2': 0.04218713062199013, 'w3': 0.05140185782145151, 'w4': 0.019078174708522543}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:23,127]\u001b[0m Trial 720 finished with value: 0.7664647590055698 and parameters: {'w0': 0.9009513878025338, 'w1': 0.03406744830399382, 'w2': 0.29293037484463363, 'w3': 0.07147957535081437, 'w4': 0.022414271951357593}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:23,275]\u001b[0m Trial 721 finished with value: 0.7665643353512716 and parameters: {'w0': 0.878219116441638, 'w1': 0.017870151650904612, 'w2': 0.027501659033137695, 'w3': 0.034203049474019594, 'w4': 0.00027483416945406}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:23,423]\u001b[0m Trial 722 finished with value: 0.7665641074197478 and parameters: {'w0': 0.9033909631466307, 'w1': 0.03388249276964447, 'w2': 0.04842622958011502, 'w3': 0.08565806405355833, 'w4': 0.00024033830497702306}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:23,571]\u001b[0m Trial 723 finished with value: 0.7665531399925138 and parameters: {'w0': 0.8828323842456344, 'w1': 0.019057364055248684, 'w2': 0.014294783650587247, 'w3': 0.05556633230149047, 'w4': 0.03426455088098527}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:23,725]\u001b[0m Trial 724 finished with value: 0.7665634529245027 and parameters: {'w0': 0.8432758674896034, 'w1': 0.04930718346928117, 'w2': 0.015945371141029997, 'w3': 0.08532650064461404, 'w4': 6.829013492210684e-05}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:23,872]\u001b[0m Trial 725 finished with value: 0.7665026650089843 and parameters: {'w0': 0.9032614629355954, 'w1': 0.07728232778563332, 'w2': 0.06627630536113385, 'w3': 0.06331670717316655, 'w4': 0.03241161103359848}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:24,017]\u001b[0m Trial 726 finished with value: 0.7665604768885199 and parameters: {'w0': 0.8651124180719743, 'w1': 0.0005718271625039569, 'w2': 0.03544949644551032, 'w3': 0.03689590909846843, 'w4': 0.01910571372389147}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:24,165]\u001b[0m Trial 727 finished with value: 0.7665653711686311 and parameters: {'w0': 0.8881600395457958, 'w1': 0.000653905764914295, 'w2': 0.019068200172608383, 'w3': 0.08962142300054793, 'w4': 0.04892992796035843}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:24,314]\u001b[0m Trial 728 finished with value: 0.7663872467760697 and parameters: {'w0': 0.9049512182879149, 'w1': 0.4134718910784507, 'w2': 0.050581571322549146, 'w3': 0.0752183860386759, 'w4': 0.021198827845539395}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:24,461]\u001b[0m Trial 729 finished with value: 0.7663766602400777 and parameters: {'w0': 0.8449782536954632, 'w1': 0.030346494319836183, 'w2': 0.0330104482126419, 'w3': 0.6949170459285453, 'w4': 0.018110553436990418}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:24,610]\u001b[0m Trial 730 finished with value: 0.7665908723543327 and parameters: {'w0': 0.9145616507737429, 'w1': 0.0004194169862183262, 'w2': 0.017882718037420527, 'w3': 0.05440232446887075, 'w4': 0.00017913863949112945}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:24,760]\u001b[0m Trial 731 finished with value: 0.7665620612065029 and parameters: {'w0': 0.9211017833210593, 'w1': 0.0005458173376702495, 'w2': 0.0657387247560601, 'w3': 0.09965519948104873, 'w4': 0.035557249722790604}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:19:24,906]\u001b[0m Trial 732 finished with value: 0.7663717000364824 and parameters: {'w0': 0.9163569630721097, 'w1': 0.01807172406957348, 'w2': 0.21290963820329778, 'w3': 0.017935738533498467, 'w4': 0.06420278068371048}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:25,054]\u001b[0m Trial 733 finished with value: 0.7664544133272749 and parameters: {'w0': 0.921080575924765, 'w1': 0.0007854373670874295, 'w2': 0.0006202621926706987, 'w3': 0.0013836327355210148, 'w4': 0.03204807764575476}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:25,202]\u001b[0m Trial 734 finished with value: 0.7664869941781325 and parameters: {'w0': 0.8976692883498746, 'w1': 0.03696717093914796, 'w2': 0.0002882098875150552, 'w3': 0.42634871291377757, 'w4': 0.23921223644521397}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:25,354]\u001b[0m Trial 735 finished with value: 0.7662340151773164 and parameters: {'w0': 0.9130664270588638, 'w1': 0.01859906467046569, 'w2': 0.03424329248867031, 'w3': 0.05037853914746304, 'w4': 0.8568981805361171}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:25,500]\u001b[0m Trial 736 finished with value: 0.7665471745635024 and parameters: {'w0': 0.8606550702377544, 'w1': 0.058100528389125064, 'w2': 0.04981813337243922, 'w3': 0.08083676315057002, 'w4': 0.0007959220821581894}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:25,653]\u001b[0m Trial 737 finished with value: 0.7665740704833108 and parameters: {'w0': 0.8778055593233767, 'w1': 0.03534412326163966, 'w2': 0.021742283169680677, 'w3': 0.10073407320299153, 'w4': 0.00018204111898674838}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:25,805]\u001b[0m Trial 738 finished with value: 0.766559225204065 and parameters: {'w0': 0.9292829136334579, 'w1': 0.0008915512793868913, 'w2': 0.016122013629842988, 'w3': 0.06676712544067562, 'w4': 0.05040101249914562}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:25,955]\u001b[0m Trial 739 finished with value: 0.7665361084664782 and parameters: {'w0': 0.9009171472607367, 'w1': 0.018828430969283706, 'w2': 0.04450334312708125, 'w3': 0.03646230571619853, 'w4': 0.019790397686605538}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:26,102]\u001b[0m Trial 740 finished with value: 0.7665620232897277 and parameters: {'w0': 0.9134151198823938, 'w1': 0.00047594252178683946, 'w2': 0.06691200387988502, 'w3': 0.08459644094756588, 'w4': 0.03041787944143605}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:26,250]\u001b[0m Trial 741 finished with value: 0.7665557549573869 and parameters: {'w0': 0.8323150728744324, 'w1': 0.04989303736511465, 'w2': 0.000575638752186268, 'w3': 0.1127393330934914, 'w4': 0.01863523341987901}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:26,402]\u001b[0m Trial 742 finished with value: 0.7665306450038663 and parameters: {'w0': 0.8777814395152391, 'w1': 0.03139648623870378, 'w2': 0.036578245711237495, 'w3': 0.06100556937839237, 'w4': 0.04693861237557045}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:26,550]\u001b[0m Trial 743 finished with value: 0.7663670138677625 and parameters: {'w0': 0.9366604295434668, 'w1': 0.6366829123115231, 'w2': 0.01951940896737995, 'w3': 0.09468371582897639, 'w4': 0.00042842167303996584}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:26,699]\u001b[0m Trial 744 finished with value: 0.766321252197917 and parameters: {'w0': 0.8946984442338431, 'w1': 0.5099916224071845, 'w2': 1.1171479995298593e-05, 'w3': 0.04121781193637171, 'w4': 5.846695787892144e-06}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:26,848]\u001b[0m Trial 745 finished with value: 0.7663990216582672 and parameters: {'w0': 0.8599592366254688, 'w1': 0.021024287365098954, 'w2': 0.04921351931643027, 'w3': 0.07439150116890683, 'w4': 0.31194262787495697}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:26,997]\u001b[0m Trial 746 finished with value: 0.7665204910638098 and parameters: {'w0': 0.7620992341570423, 'w1': 0.04478962236396524, 'w2': 0.0717236068788167, 'w3': 0.11322649949657865, 'w4': 0.07347342648921595}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:27,143]\u001b[0m Trial 747 finished with value: 0.7665108425371322 and parameters: {'w0': 0.9145856757396993, 'w1': 0.0006840998004050657, 'w2': 0.03247039677425237, 'w3': 0.01962674022738586, 'w4': 0.0334339403659457}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:27,288]\u001b[0m Trial 748 finished with value: 0.766503826641098 and parameters: {'w0': 0.9316754732097567, 'w1': 0.019233020260752878, 'w2': 0.017995666338606754, 'w3': 0.34809070913915047, 'w4': 0.0164814064993148}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:27,439]\u001b[0m Trial 749 finished with value: 0.7663727087088779 and parameters: {'w0': 0.8767083187072088, 'w1': 0.00016575992358278113, 'w2': 0.03411271926909089, 'w3': 0.7617709711527852, 'w4': 0.05519918904792342}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:27,588]\u001b[0m Trial 750 finished with value: 0.766524262059455 and parameters: {'w0': 0.817784750767721, 'w1': 0.06764034179035872, 'w2': 4.669004861402107e-05, 'w3': 0.05635593202664054, 'w4': 0.032821328762961885}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:27,735]\u001b[0m Trial 751 finished with value: 0.7663437097006617 and parameters: {'w0': 0.8984650932930509, 'w1': 0.031945924649891634, 'w2': 0.056623894754869696, 'w3': 0.08019707461330876, 'w4': 0.4864371876020048}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:27,883]\u001b[0m Trial 752 finished with value: 0.76655672442039 and parameters: {'w0': 0.9278266666831035, 'w1': 0.05049680531642065, 'w2': 0.018775743468712233, 'w3': 0.09773593025447844, 'w4': 0.018497463260843866}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:28,037]\u001b[0m Trial 753 finished with value: 0.7664136265106881 and parameters: {'w0': 0.8462097987284085, 'w1': 0.4595269940388502, 'w2': 0.036639954181443855, 'w3': 0.11770237565304875, 'w4': 0.043038047471177523}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:28,184]\u001b[0m Trial 754 finished with value: 0.7665527315254351 and parameters: {'w0': 0.8707810489456139, 'w1': 0.018393970786633306, 'w2': 0.07089280057511776, 'w3': 0.05007999321843417, 'w4': 0.0002593521206173087}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:28,334]\u001b[0m Trial 755 finished with value: 0.7665598762523306 and parameters: {'w0': 0.9179417509943515, 'w1': 0.03140327684933438, 'w2': 0.01790060588209611, 'w3': 0.07157615824351432, 'w4': 0.0197616103785205}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:28,483]\u001b[0m Trial 756 finished with value: 0.7665578761424374 and parameters: {'w0': 0.8908425181201995, 'w1': 9.348355144365609e-06, 'w2': 0.0547426561942396, 'w3': 0.1275226017999173, 'w4': 0.052298212198135026}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:28,631]\u001b[0m Trial 757 finished with value: 0.7665312775246167 and parameters: {'w0': 0.9333317912233019, 'w1': 0.09020547260581181, 'w2': 0.03343678674340296, 'w3': 0.09588727791905594, 'w4': 0.0211291456399403}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:28,778]\u001b[0m Trial 758 finished with value: 0.7665730411290379 and parameters: {'w0': 0.9057353129334129, 'w1': 0.022473664081141022, 'w2': 0.00016475219585863204, 'w3': 0.02946337402341481, 'w4': 0.0003282255636511352}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:28,927]\u001b[0m Trial 759 finished with value: 0.7662551865258107 and parameters: {'w0': 0.9475226145678839, 'w1': 0.054372234997366625, 'w2': 0.018411643359888156, 'w3': 0.07119545923098239, 'w4': 0.8848705481975495}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:19:29,091]\u001b[0m Trial 760 finished with value: 0.7662989360213345 and parameters: {'w0': 0.855501415519173, 'w1': 0.8774083511912363, 'w2': 0.05122401526983658, 'w3': 0.08662562437975499, 'w4': 0.07306244328219562}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:29,237]\u001b[0m Trial 761 finished with value: 0.766542718911541 and parameters: {'w0': 0.8817760352441758, 'w1': 0.0172449522319002, 'w2': 0.03424620014916891, 'w3': 0.04603933773304493, 'w4': 0.03096097981008724}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:29,383]\u001b[0m Trial 762 finished with value: 0.7664671787852251 and parameters: {'w0': 0.9130218741827981, 'w1': 0.24222217143485636, 'w2': 0.07360960110739172, 'w3': 0.10303510988955229, 'w4': 0.01978622024391025}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:29,534]\u001b[0m Trial 763 finished with value: 0.7664300229307386 and parameters: {'w0': 0.9348838301076035, 'w1': 0.0002566831613827446, 'w2': 0.020760509562710874, 'w3': 0.5469938725233024, 'w4': 0.04535746967992566}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:29,681]\u001b[0m Trial 764 finished with value: 0.766552884054281 and parameters: {'w0': 0.7931987769423834, 'w1': 0.038740752392898786, 'w2': 0.047839473871958804, 'w3': 0.06580479294338289, 'w4': 8.708114986999017e-05}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:29,829]\u001b[0m Trial 765 finished with value: 0.7665476106064174 and parameters: {'w0': 0.8298734210321156, 'w1': 0.03330409970725761, 'w2': 0.01590616633843352, 'w3': 0.13409336784869283, 'w4': 0.03340086890371098}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:29,975]\u001b[0m Trial 766 finished with value: 0.7664481411170823 and parameters: {'w0': 0.8897988681073578, 'w1': 0.0662720589154599, 'w2': 0.033475840201348916, 'w3': 0.017349834262105138, 'w4': 0.01751934706500303}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:30,131]\u001b[0m Trial 767 finished with value: 0.7665436250362944 and parameters: {'w0': 0.8673617659825463, 'w1': 0.0001991338045743031, 'w2': 0.05656732613375839, 'w3': 0.08462590477665702, 'w4': 0.06281558267227824}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:30,281]\u001b[0m Trial 768 finished with value: 0.7665591467852799 and parameters: {'w0': 0.947158388496592, 'w1': 0.01788184819860047, 'w2': 0.015039401014504664, 'w3': 0.038202941482885916, 'w4': 0.017621929997128603}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:30,430]\u001b[0m Trial 769 finished with value: 0.7665454898522395 and parameters: {'w0': 0.9094440542670812, 'w1': 0.04494085376003216, 'w2': 0.03883717157443865, 'w3': 0.11580895704479804, 'w4': 0.04250756487506219}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:30,580]\u001b[0m Trial 770 finished with value: 0.7665431640027776 and parameters: {'w0': 0.47549872327190756, 'w1': 0.019859843565953248, 'w2': 0.07907756211986755, 'w3': 0.06238367673979005, 'w4': 8.060710944560873e-05}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:30,728]\u001b[0m Trial 771 finished with value: 0.766520083458476 and parameters: {'w0': 0.8458296573553916, 'w1': 0.1100365447992411, 'w2': 0.0002712973251096883, 'w3': 0.09583810457830892, 'w4': 0.03391565990849001}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:30,875]\u001b[0m Trial 772 finished with value: 0.7664987526871768 and parameters: {'w0': 0.9247512507324632, 'w1': 0.033841760301036215, 'w2': 0.01879688343555963, 'w3': 0.05175308321424337, 'w4': 0.08910352289070153}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:31,024]\u001b[0m Trial 773 finished with value: 0.7665803668223605 and parameters: {'w0': 0.8954085092831086, 'w1': 0.016939420020928752, 'w2': 8.865090735605722e-05, 'w3': 0.07982636332185775, 'w4': 0.020172983590323556}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:31,177]\u001b[0m Trial 774 finished with value: 0.7664997342146084 and parameters: {'w0': 0.8949662862027832, 'w1': 0.061459478698474096, 'w2': 0.0018652692688212883, 'w3': 0.2667964247459606, 'w4': 0.0645780849782735}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:31,326]\u001b[0m Trial 775 finished with value: 0.7663858106782081 and parameters: {'w0': 0.9087771505986714, 'w1': 0.5749604490570457, 'w2': 0.01666224799464534, 'w3': 0.11284878339730668, 'w4': 0.05317710551116708}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:31,475]\u001b[0m Trial 776 finished with value: 0.7665497063699936 and parameters: {'w0': 0.9381872771697255, 'w1': 0.05241206531523202, 'w2': 0.0009699404933411968, 'w3': 0.08527697788703886, 'w4': 0.03315512836511258}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:31,624]\u001b[0m Trial 777 finished with value: 0.7665053988946526 and parameters: {'w0': 0.8887503577993097, 'w1': 0.07680706899351547, 'w2': 0.0005130319143298867, 'w3': 0.07165121466077128, 'w4': 0.07819666913023367}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:31,772]\u001b[0m Trial 778 finished with value: 0.7664357315597723 and parameters: {'w0': 0.9181933657795892, 'w1': 0.019038072327637642, 'w2': 6.29488703483437e-05, 'w3': 0.47936397549557264, 'w4': 0.019567580716310335}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:31,920]\u001b[0m Trial 779 finished with value: 0.7663334855283965 and parameters: {'w0': 0.9029050136555938, 'w1': 0.03642349089096805, 'w2': 0.9223849223080128, 'w3': 0.12448357317830269, 'w4': 0.4064744128138053}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:32,067]\u001b[0m Trial 780 finished with value: 0.766555384837956 and parameters: {'w0': 0.9551575105915785, 'w1': 0.018825360247364583, 'w2': 0.031010804731960495, 'w3': 0.10020245002205118, 'w4': 0.04857079662193224}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:32,217]\u001b[0m Trial 781 finished with value: 0.7665377298394915 and parameters: {'w0': 0.9311682661228315, 'w1': 0.04592266523056247, 'w2': 0.01852737670488389, 'w3': 0.04484011159181416, 'w4': 0.01856670785999544}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:32,370]\u001b[0m Trial 782 finished with value: 0.7665554128446651 and parameters: {'w0': 0.8783737647106429, 'w1': 0.016387753254043336, 'w2': 0.03317851733840199, 'w3': 0.0785925286313253, 'w4': 0.03713825249786139}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:32,521]\u001b[0m Trial 783 finished with value: 0.7665149073877853 and parameters: {'w0': 0.9041118000790144, 'w1': 0.036353136490801706, 'w2': 0.01777345304836138, 'w3': 0.02449708825605082, 'w4': 0.018097283247772437}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:32,669]\u001b[0m Trial 784 finished with value: 0.766510378487508 and parameters: {'w0': 0.943163586230618, 'w1': 0.06468485337801098, 'w2': 0.00045879942093675656, 'w3': 0.05782396201294463, 'w4': 0.06279089654501102}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:32,820]\u001b[0m Trial 785 finished with value: 0.7664572924169575 and parameters: {'w0': 0.9202365661445652, 'w1': 0.02074127967327091, 'w2': 0.04142217687419874, 'w3': 0.8737250717575851, 'w4': 0.6207141197573082}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:32,969]\u001b[0m Trial 786 finished with value: 0.7665906444228089 and parameters: {'w0': 0.8805957812115222, 'w1': 0.0010028169018395574, 'w2': 0.019393410311149658, 'w3': 0.1003263356009405, 'w4': 0.00013698541904043002}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:33,117]\u001b[0m Trial 787 finished with value: 0.766445665324009 and parameters: {'w0': 0.8655668542047898, 'w1': 0.00024254355791292293, 'w2': 0.03426357400591916, 'w3': 0.13856899180182541, 'w4': 0.3681513143768167}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:19:33,267]\u001b[0m Trial 788 finished with value: 0.7663631816882299 and parameters: {'w0': 0.8816226110108045, 'w1': 0.01718639686201252, 'w2': 0.04961113351283144, 'w3': 0.8374242489262822, 'w4': 0.03508323961577032}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:33,415]\u001b[0m Trial 789 finished with value: 0.7661699142835627 and parameters: {'w0': 0.8612396175628543, 'w1': 0.0003404790620698154, 'w2': 0.017888275586285196, 'w3': 0.0013105756834023152, 'w4': 0.677601397967319}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:33,564]\u001b[0m Trial 790 finished with value: 0.7665683084260939 and parameters: {'w0': 0.8836928395579976, 'w1': 0.0175071378694658, 'w2': 0.03092110671706466, 'w3': 0.08036632008525184, 'w4': 0.017959909422998896}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:33,715]\u001b[0m Trial 791 finished with value: 0.7665623886695617 and parameters: {'w0': 0.9577148987930767, 'w1': 0.0007292450419518823, 'w2': 0.053284424653577175, 'w3': 0.11402463818210558, 'w4': 0.04722749479592535}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:33,866]\u001b[0m Trial 792 finished with value: 0.7665517267308917 and parameters: {'w0': 0.8683590293317044, 'w1': 0.035754066014003674, 'w2': 0.017042787368883292, 'w3': 0.05686320314433941, 'w4': 0.018139034094134605}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:34,015]\u001b[0m Trial 793 finished with value: 0.7665806055256954 and parameters: {'w0': 0.8891947666152552, 'w1': 0.01889748562637812, 'w2': 0.033463820332383515, 'w3': 0.09434967446781882, 'w4': 0.0004461406324760288}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:34,164]\u001b[0m Trial 794 finished with value: 0.7665514492490366 and parameters: {'w0': 0.8594289629454055, 'w1': 0.059043891064262, 'w2': 0.017154081818854063, 'w3': 0.1340927665071496, 'w4': 0.0005327676487671164}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:34,315]\u001b[0m Trial 795 finished with value: 0.7665579162135749 and parameters: {'w0': 0.8818243751333885, 'w1': 0.04592235257740392, 'w2': 0.03009300348688232, 'w3': 0.10501385865387575, 'w4': 0.015390263057828018}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:34,467]\u001b[0m Trial 796 finished with value: 0.7664099072197365 and parameters: {'w0': 0.8925400869304583, 'w1': 0.03177605619320569, 'w2': 0.63673072751174, 'w3': 0.09305491326546414, 'w4': 0.03181803458702474}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:34,617]\u001b[0m Trial 797 finished with value: 0.766545954332736 and parameters: {'w0': 0.8506068650343557, 'w1': 0.017862048079113596, 'w2': 0.00014167866792846873, 'w3': 0.15236641761472505, 'w4': 0.017605374375666654}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:34,766]\u001b[0m Trial 798 finished with value: 0.7664904648556831 and parameters: {'w0': 0.8871609807345643, 'w1': 0.08185429128160711, 'w2': 0.05642999349571044, 'w3': 0.03675554823916123, 'w4': 0.001259935978037678}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:34,917]\u001b[0m Trial 799 finished with value: 0.7663322170399164 and parameters: {'w0': 0.8440790046883158, 'w1': 0.9358052220055874, 'w2': 0.00013063041912332346, 'w3': 0.11983273375000296, 'w4': 0.039175840456442984}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:35,066]\u001b[0m Trial 800 finished with value: 0.766542983898095 and parameters: {'w0': 0.8697556623861011, 'w1': 0.05069835346789492, 'w2': 0.03091057655402323, 'w3': 0.06856974707422636, 'w4': 0.017598342105094623}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:35,214]\u001b[0m Trial 801 finished with value: 0.7665452153864916 and parameters: {'w0': 0.9232686479879427, 'w1': 0.03090098507558961, 'w2': 0.018287515864075087, 'w3': 0.08835603100092722, 'w4': 0.05409103404366618}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:35,363]\u001b[0m Trial 802 finished with value: 0.7665704287493993 and parameters: {'w0': 0.97251001719024, 'w1': 0.017441788746523322, 'w2': 0.04517078449460305, 'w3': 0.06516211917674215, 'w4': 0.00012682763085081206}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:35,514]\u001b[0m Trial 803 finished with value: 0.7665570385264029 and parameters: {'w0': 0.9073229802530098, 'w1': 0.017251530893270438, 'w2': 0.06714336395833052, 'w3': 0.11443911950533155, 'w4': 0.03229780000282226}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:35,663]\u001b[0m Trial 804 finished with value: 0.7664685403421536 and parameters: {'w0': 0.9414699395005147, 'w1': 0.00013544598155203896, 'w2': 0.0001122652271806344, 'w3': 0.03818579139612038, 'w4': 0.1404532641935924}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:35,812]\u001b[0m Trial 805 finished with value: 0.7665623162829909 and parameters: {'w0': 0.8798563031486676, 'w1': 0.04780672286183205, 'w2': 0.03459678399605823, 'w3': 0.09698937267636284, 'w4': 0.0004535915257230116}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:35,962]\u001b[0m Trial 806 finished with value: 0.7664762874287281 and parameters: {'w0': 0.8954902767081894, 'w1': 0.07086546037240259, 'w2': 0.023770282006592355, 'w3': 0.06426121930499862, 'w4': 0.11058100709128957}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:36,113]\u001b[0m Trial 807 finished with value: 0.7665421979867542 and parameters: {'w0': 0.8661651881688662, 'w1': 0.03321525974250862, 'w2': 0.05121361465797175, 'w3': 0.08003279967437016, 'w4': 0.033798187579565084}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:36,261]\u001b[0m Trial 808 finished with value: 0.7663788861271325 and parameters: {'w0': 0.5879279953192399, 'w1': 2.829268823237672e-05, 'w2': 0.0002795887709177644, 'w3': 0.12966182203351648, 'w4': 0.559360374206774}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:36,414]\u001b[0m Trial 809 finished with value: 0.7665398187091086 and parameters: {'w0': 0.9596910855279148, 'w1': 0.01975471786872607, 'w2': 0.017422406242888412, 'w3': 0.01937893544545969, 'w4': 0.00043917975163299607}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:36,566]\u001b[0m Trial 810 finished with value: 0.7664824648469829 and parameters: {'w0': 0.9265570172621312, 'w1': 0.03689000024191935, 'w2': 0.06649683053092592, 'w3': 0.044401919133490515, 'w4': 0.06645334646997908}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:36,718]\u001b[0m Trial 811 finished with value: 0.7665569820821125 and parameters: {'w0': 0.8418182177102012, 'w1': 0.057006327738170645, 'w2': 0.036683774130612495, 'w3': 0.10332178637978226, 'w4': 3.395538457016099e-05}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:36,867]\u001b[0m Trial 812 finished with value: 0.7665227841669658 and parameters: {'w0': 0.9032841602388454, 'w1': 0.09832836756559263, 'w2': 0.0002860490728499379, 'w3': 0.07881294636917162, 'w4': 0.0317805617815316}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:37,022]\u001b[0m Trial 813 finished with value: 0.7665059043080316 and parameters: {'w0': 0.3735449887617538, 'w1': 0.01933711945116462, 'w2': 0.047861534373091125, 'w3': 0.058012926597732536, 'w4': 0.052094492945316054}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:37,171]\u001b[0m Trial 814 finished with value: 0.7664746492516895 and parameters: {'w0': 0.6883855462515389, 'w1': 0.016746622854901312, 'w2': 0.3822253332820609, 'w3': 0.10385487423819743, 'w4': 0.0182686476503693}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:37,320]\u001b[0m Trial 815 finished with value: 0.7665405787681029 and parameters: {'w0': 0.940716158854519, 'w1': 0.00010261603094362248, 'w2': 0.030596561710152858, 'w3': 0.08057635719227486, 'w4': 0.08428540405539639}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:19:37,471]\u001b[0m Trial 816 finished with value: 0.7665588835222155 and parameters: {'w0': 0.9184687006898813, 'w1': 0.0409929491434725, 'w2': 0.018498002697197743, 'w3': 0.12822351440135252, 'w4': 0.019316261889836116}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:37,620]\u001b[0m Trial 817 finished with value: 0.7664397382426452 and parameters: {'w0': 0.8815816654344606, 'w1': 0.03439713333009971, 'w2': 0.25644132479289083, 'w3': 0.0545221486344277, 'w4': 0.04467357413657512}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:37,768]\u001b[0m Trial 818 finished with value: 0.7665141934321428 and parameters: {'w0': 0.9601083942210165, 'w1': 0.01579877820999135, 'w2': 0.07729476145618969, 'w3': 0.03402789924358759, 'w4': 0.021434695422522368}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:37,919]\u001b[0m Trial 819 finished with value: 0.7665498183968295 and parameters: {'w0': 0.8638225965948886, 'w1': 0.05899898365397255, 'w2': 0.017535281364017555, 'w3': 0.09258589387166447, 'w4': 0.017850228793093868}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:38,073]\u001b[0m Trial 820 finished with value: 0.7665546945802981 and parameters: {'w0': 0.8978087967293946, 'w1': 0.00030743173130619707, 'w2': 0.049356777698183224, 'w3': 0.07126812759295209, 'w4': 0.04380797802038075}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:38,221]\u001b[0m Trial 821 finished with value: 0.7664552910144469 and parameters: {'w0': 0.9329444347555369, 'w1': 0.03547631066818767, 'w2': 0.00039606963742107955, 'w3': 0.1140397350213585, 'w4': 0.281937954558915}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:38,371]\u001b[0m Trial 822 finished with value: 0.7665673742946314 and parameters: {'w0': 0.8257570725190648, 'w1': 0.019973211903647047, 'w2': 0.032766685534788655, 'w3': 0.05185626224464912, 'w4': 0.0004394203688473826}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:38,535]\u001b[0m Trial 823 finished with value: 0.766537440293208 and parameters: {'w0': 0.9696569936562246, 'w1': 0.0818924289336152, 'w2': 0.059583278016605914, 'w3': 0.1466647934633892, 'w4': 0.03211534852887674}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:38,697]\u001b[0m Trial 824 finished with value: 0.7664902817348935 and parameters: {'w0': 0.9041983800077839, 'w1': 0.14459175180225675, 'w2': 0.021001313644247076, 'w3': 0.08913390523975308, 'w4': 0.06114371820397467}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:38,861]\u001b[0m Trial 825 finished with value: 0.766561885410545 and parameters: {'w0': 0.8576381197771019, 'w1': 0.01609621929184158, 'w2': 0.03923313579213639, 'w3': 0.07024184059456146, 'w4': 0.01915938890255684}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:39,018]\u001b[0m Trial 826 finished with value: 0.7665039158316943 and parameters: {'w0': 0.8826029078929833, 'w1': 7.165557799876452e-05, 'w2': 0.017962810664216622, 'w3': 0.015040660473218129, 'w4': 0.035658834336660346}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:39,179]\u001b[0m Trial 827 finished with value: 0.7664846467850481 and parameters: {'w0': 0.9196744654533056, 'w1': 0.05432173984088216, 'w2': 0.345534901278455, 'w3': 0.10657480548223272, 'w4': 0.00037272787555377076}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:39,331]\u001b[0m Trial 828 finished with value: 0.7663598592308007 and parameters: {'w0': 0.9469869801804051, 'w1': 0.03528560928974325, 'w2': 0.5431584917546348, 'w3': 0.0411235475795636, 'w4': 0.018342439702732596}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:39,483]\u001b[0m Trial 829 finished with value: 0.7665636916278377 and parameters: {'w0': 0.889740177561588, 'w1': 0.018338145619960354, 'w2': 0.08148278047961642, 'w3': 0.0864509122101329, 'w4': 0.0003141524477825177}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:39,645]\u001b[0m Trial 830 finished with value: 0.7663511017483409 and parameters: {'w0': 0.975760765317988, 'w1': 5.107239250340921e-05, 'w2': 0.8181099381534989, 'w3': 0.061009711144164744, 'w4': 0.04789418399003467}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:39,802]\u001b[0m Trial 831 finished with value: 0.7665443351140849 and parameters: {'w0': 0.843215541676854, 'w1': 0.047516919043749474, 'w2': 0.04978374595592388, 'w3': 0.12130097596765096, 'w4': 0.03275492667154943}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:39,962]\u001b[0m Trial 832 finished with value: 0.7665351627014598 and parameters: {'w0': 0.9176156225803239, 'w1': 0.0324077670156046, 'w2': 0.017795289087944144, 'w3': 0.09797569308406585, 'w4': 0.07908218529576116}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:40,119]\u001b[0m Trial 833 finished with value: 0.7664333746874941 and parameters: {'w0': 0.04895466352660033, 'w1': 6.043206072160398e-05, 'w2': 0.00031712204428469606, 'w3': 0.027675632999244318, 'w4': 0.061818168369223436}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:40,269]\u001b[0m Trial 834 finished with value: 0.7665734090941065 and parameters: {'w0': 0.8704291459172887, 'w1': 0.02008698728987434, 'w2': 0.03317361108250673, 'w3': 0.07317560215479292, 'w4': 0.00031565504545871814}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:40,423]\u001b[0m Trial 835 finished with value: 0.7665467518776332 and parameters: {'w0': 0.9418934429500176, 'w1': 0.07061175530797337, 'w2': 0.04984970320668464, 'w3': 0.1377226706945695, 'w4': 0.01791824912940295}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:40,573]\u001b[0m Trial 836 finished with value: 0.7665429158202486 and parameters: {'w0': 0.8982799218523566, 'w1': 0.00019169571579819716, 'w2': 0.0664772443389109, 'w3': 0.05055961907272822, 'w4': 0.03365963419308153}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:40,726]\u001b[0m Trial 837 finished with value: 0.7664809714430859 and parameters: {'w0': 0.9277570775287067, 'w1': 0.03186101496653558, 'w2': 0.017917408724681637, 'w3': 0.08211183074670264, 'w4': 0.17556807015323178}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:40,878]\u001b[0m Trial 838 finished with value: 0.7665560311466246 and parameters: {'w0': 0.9592105880109363, 'w1': 0.052340453024286956, 'w2': 0.03459676087948924, 'w3': 0.10893034784650173, 'w4': 0.01639105299210898}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:41,031]\u001b[0m Trial 839 finished with value: 0.7663782346479946 and parameters: {'w0': 0.8738381234100405, 'w1': 0.3939773115449321, 'w2': 0.0005330453393567671, 'w3': 0.06572435314621031, 'w4': 0.047878034162959035}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:41,183]\u001b[0m Trial 840 finished with value: 0.766581990349736 and parameters: {'w0': 0.9136986738814811, 'w1': 0.019872098070731318, 'w2': 0.0002469738414441628, 'w3': 0.09360439238721174, 'w4': 0.017401377365787313}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:41,335]\u001b[0m Trial 841 finished with value: 0.7665425306202821 and parameters: {'w0': 0.917914386858951, 'w1': 0.07839734950988195, 'w2': 0.020491130215180932, 'w3': 0.15801257662358092, 'w4': 0.0005464689910291436}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:41,486]\u001b[0m Trial 842 finished with value: 0.7665527879697255 and parameters: {'w0': 0.9469210897555048, 'w1': 0.0541500061875144, 'w2': 0.01400090185153989, 'w3': 0.12473911805132806, 'w4': 0.030632590749294357}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:41,637]\u001b[0m Trial 843 finished with value: 0.7665412035331494 and parameters: {'w0': 0.9287183414973572, 'w1': 0.038494433931287264, 'w2': 0.01637543432915353, 'w3': 0.09915035930546731, 'w4': 0.0615856981235816}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:19:41,789]\u001b[0m Trial 844 finished with value: 0.766393328109769 and parameters: {'w0': 0.9141058862048154, 'w1': 0.2711668311384049, 'w2': 0.0018123017134167412, 'w3': 0.040884307279827885, 'w4': 0.018583803252410148}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:41,938]\u001b[0m Trial 845 finished with value: 0.7663682336676564 and parameters: {'w0': 0.8982257851135561, 'w1': 0.6875139616873034, 'w2': 0.016843372461208542, 'w3': 0.11559849295249276, 'w4': 0.04157851080416345}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:42,091]\u001b[0m Trial 846 finished with value: 0.7665670145161392 and parameters: {'w0': 0.9377448847959429, 'w1': 0.030142671434653635, 'w2': 0.00027259761790702976, 'w3': 0.0686330696183221, 'w4': 0.018061312572432646}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:42,244]\u001b[0m Trial 847 finished with value: 0.7665432600873328 and parameters: {'w0': 0.9826387973675146, 'w1': 0.05779820320602887, 'w2': 0.029196033472008838, 'w3': 0.09276101190705097, 'w4': 0.03261395487995411}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:42,396]\u001b[0m Trial 848 finished with value: 0.7665037452062058 and parameters: {'w0': 0.4310710369818787, 'w1': 0.023268199203505043, 'w2': 0.03156252403484472, 'w3': 0.14101502084382866, 'w4': 0.0001800464817078979}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:42,548]\u001b[0m Trial 849 finished with value: 0.7665428697168969 and parameters: {'w0': 0.9081304792598643, 'w1': 0.019006237789182468, 'w2': 0.015730609776210068, 'w3': 0.05809260461197176, 'w4': 0.05087547312900574}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:42,698]\u001b[0m Trial 850 finished with value: 0.7662075104896887 and parameters: {'w0': 0.9552729270394044, 'w1': 0.04387348582464834, 'w2': 0.031756180875328, 'w3': 0.026145910302132362, 'w4': 0.7739289436594691}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:42,850]\u001b[0m Trial 851 finished with value: 0.76656156915017 and parameters: {'w0': 0.9290886988381899, 'w1': 0.06929768080966411, 'w2': 0.0015200376117388266, 'w3': 0.10569958488585808, 'w4': 1.9727670728872382e-05}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:43,002]\u001b[0m Trial 852 finished with value: 0.7664625619869688 and parameters: {'w0': 0.8939971409785209, 'w1': 0.02058482511853464, 'w2': 0.00014999266312770208, 'w3': 0.00019220437868969903, 'w4': 0.00011413716338862928}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:43,158]\u001b[0m Trial 853 finished with value: 0.7664186517760229 and parameters: {'w0': 0.9088858129573648, 'w1': 0.33600689291342734, 'w2': 0.04693831772047602, 'w3': 0.08314749174643407, 'w4': 0.03167245187962123}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:43,310]\u001b[0m Trial 854 finished with value: 0.7665073886636071 and parameters: {'w0': 0.9704903296076395, 'w1': 0.041083472365462184, 'w2': 0.017701485537480403, 'w3': 0.05131895867758763, 'w4': 0.07080069332415265}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:43,459]\u001b[0m Trial 855 finished with value: 0.7665604195824848 and parameters: {'w0': 0.9419587098931436, 'w1': 0.02108640403459335, 'w2': 0.03408792490392075, 'w3': 0.0759345291748106, 'w4': 0.02406033185154328}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:43,609]\u001b[0m Trial 856 finished with value: 0.7665639997016365 and parameters: {'w0': 0.8896777206853832, 'w1': 0.019185288073532963, 'w2': 0.06213427563699092, 'w3': 0.1078504019153728, 'w4': 0.017357826775199824}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:43,759]\u001b[0m Trial 857 finished with value: 0.7665463882212891 and parameters: {'w0': 0.919267557227191, 'w1': 0.048566491568025866, 'w2': 0.017466715354180037, 'w3': 0.13393481737253338, 'w4': 0.04764012019762446}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:43,913]\u001b[0m Trial 858 finished with value: 0.7665374433093153 and parameters: {'w0': 0.9487990370507319, 'w1': 0.016995952041532866, 'w2': 0.0008837974893062921, 'w3': 0.08994736831503283, 'w4': 0.09514825558720233}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:44,062]\u001b[0m Trial 859 finished with value: 0.7665214187321854 and parameters: {'w0': 0.9073190300495038, 'w1': 0.0349519255476164, 'w2': 0.04214605715964274, 'w3': 0.03597927473685941, 'w4': 0.020317526469732058}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:44,214]\u001b[0m Trial 860 finished with value: 0.7665119063612007 and parameters: {'w0': 0.9291726438728908, 'w1': 0.08969217879927342, 'w2': 0.019350532048312125, 'w3': 0.06724060949780244, 'w4': 0.038784616767751745}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:44,366]\u001b[0m Trial 861 finished with value: 0.7665568812579602 and parameters: {'w0': 0.8864706710622466, 'w1': 0.06197042423421065, 'w2': 0.03483757609856127, 'w3': 0.12055006086587136, 'w4': 6.920073828650675e-05}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:44,518]\u001b[0m Trial 862 finished with value: 0.7665481005083883 and parameters: {'w0': 0.9653530461654144, 'w1': 0.016356996946173204, 'w2': 0.05735017047506129, 'w3': 0.04991344402880783, 'w4': 0.017474829171387624}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:44,668]\u001b[0m Trial 863 finished with value: 0.7665565533640288 and parameters: {'w0': 0.908284345124363, 'w1': 0.0008847600817237043, 'w2': 0.019774906388500057, 'w3': 0.08119425066715631, 'w4': 0.06003078856829539}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:44,818]\u001b[0m Trial 864 finished with value: 0.7665605565999224 and parameters: {'w0': 0.8760016085551797, 'w1': 0.03443299060672171, 'w2': 0.0014387920555608696, 'w3': 0.10456081463329721, 'w4': 0.03440442476713854}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:44,971]\u001b[0m Trial 865 finished with value: 0.7665681033308096 and parameters: {'w0': 0.9339153608466428, 'w1': 0.01808118635108704, 'w2': 0.0471075223939621, 'w3': 0.06206810458211712, 'w4': 5.603131710795947e-05}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:45,124]\u001b[0m Trial 866 finished with value: 0.7665158927930686 and parameters: {'w0': 0.8969797146836805, 'w1': 0.04545362642692384, 'w2': 0.03324985750081767, 'w3': 0.025434062142919434, 'w4': 7.944955281476043e-05}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:45,278]\u001b[0m Trial 867 finished with value: 0.7664875082089604 and parameters: {'w0': 0.985673545956329, 'w1': 0.18916147740712966, 'w2': 0.0006962583693835721, 'w3': 0.09441051451021792, 'w4': 0.04776460555543934}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:45,434]\u001b[0m Trial 868 finished with value: 0.7665582945195822 and parameters: {'w0': 0.9587407972631641, 'w1': 0.01595465880500854, 'w2': 0.07663520901740359, 'w3': 0.15833231648122498, 'w4': 0.020992733308318603}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:45,583]\u001b[0m Trial 869 finished with value: 0.7665275263491039 and parameters: {'w0': 0.9304878376123712, 'w1': 0.06743668837463984, 'w2': 0.018723526686353704, 'w3': 0.12523387602125233, 'w4': 0.07994301189810786}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:45,736]\u001b[0m Trial 870 finished with value: 0.7663297524495267 and parameters: {'w0': 0.8771071493610064, 'w1': 0.0007220380142410134, 'w2': 0.05578703842203314, 'w3': 0.07231341045889304, 'w4': 0.5168193251164537}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:45,887]\u001b[0m Trial 871 finished with value: 0.766552058502675 and parameters: {'w0': 0.9108394859978458, 'w1': 0.03737184732806717, 'w2': 0.00021100699991364463, 'w3': 0.04301477653894854, 'w4': 0.019396171372449464}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:19:46,039]\u001b[0m Trial 872 finished with value: 0.7664177521143561 and parameters: {'w0': 0.9481298398123827, 'w1': 0.018023574800179066, 'w2': 0.03166241332413211, 'w3': 0.09395756437708397, 'w4': 0.34581730644478087}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:46,187]\u001b[0m Trial 873 finished with value: 0.7665426896122147 and parameters: {'w0': 0.8907083896159089, 'w1': 0.0462614298759121, 'w2': 0.00021186728922351715, 'w3': 0.06561079522615096, 'w4': 0.0365373978278687}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:46,338]\u001b[0m Trial 874 finished with value: 0.7665648640317625 and parameters: {'w0': 0.8632685699312058, 'w1': 0.030802282659252337, 'w2': 0.029499990419408866, 'w3': 0.10707941710805133, 'w4': 0.017076309290449943}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:46,493]\u001b[0m Trial 875 finished with value: 0.7665359636933365 and parameters: {'w0': 0.919707027887155, 'w1': 0.018347848255196513, 'w2': 0.04833698492503915, 'w3': 0.08298967546089203, 'w4': 0.06441207882887434}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:46,644]\u001b[0m Trial 876 finished with value: 0.7661805835470643 and parameters: {'w0': 0.9708040330604781, 'w1': 0.06450840506867966, 'w2': 0.019560822271590155, 'w3': 0.021684748795813544, 'w4': 0.9957432410472862}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:46,811]\u001b[0m Trial 877 finished with value: 0.7665518486677938 and parameters: {'w0': 0.9382362558685499, 'w1': 0.016108748485872078, 'w2': 0.08434605450918059, 'w3': 0.053746308475173775, 'w4': 0.0001510481190264909}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:46,960]\u001b[0m Trial 878 finished with value: 0.7663334661391366 and parameters: {'w0': 0.8988244012091504, 'w1': 0.03441314577062688, 'w2': 0.06411609146710068, 'w3': 0.12214259464286198, 'w4': 0.7437199483723661}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:47,115]\u001b[0m Trial 879 finished with value: 0.766508648103766 and parameters: {'w0': 0.8722483557402486, 'w1': 0.10012658768008006, 'w2': 0.03610409779175146, 'w3': 0.07890692081927286, 'w4': 0.03720130011437703}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:47,264]\u001b[0m Trial 880 finished with value: 0.7665772869461183 and parameters: {'w0': 0.9220936019831035, 'w1': 4.911359670620275e-05, 'w2': 0.018718117672881254, 'w3': 0.050586431990001055, 'w4': 0.01988176443218136}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:47,417]\u001b[0m Trial 881 finished with value: 0.7664561208747775 and parameters: {'w0': 0.9537160379584125, 'w1': 0.05337086516294208, 'w2': 0.0471306973071855, 'w3': 0.5797527237613823, 'w4': 0.052625589950126776}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:47,574]\u001b[0m Trial 882 finished with value: 0.7665746426819187 and parameters: {'w0': 0.8917553984676053, 'w1': 0.01612924257826752, 'w2': 0.02275399822389021, 'w3': 0.0994352080037191, 'w4': 0.02031537169585843}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:47,725]\u001b[0m Trial 883 finished with value: 0.7665694351575395 and parameters: {'w0': 0.9116958270235899, 'w1': 0.0340661524783349, 'w2': 0.018295654080002607, 'w3': 0.07420027163512688, 'w4': 0.00018105586857450687}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:47,875]\u001b[0m Trial 884 finished with value: 0.7665415008351367 and parameters: {'w0': 0.6550001151898315, 'w1': 0.01637911981506673, 'w2': 0.06239933276768806, 'w3': 0.134559150170135, 'w4': 0.036249417118168495}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:48,028]\u001b[0m Trial 885 finished with value: 0.7662700348211635 and parameters: {'w0': 0.9794389375035504, 'w1': 0.7998408728017193, 'w2': 0.04004419505953078, 'w3': 0.042390014655081854, 'w4': 0.02039824192025127}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:48,179]\u001b[0m Trial 886 finished with value: 0.7664981964308495 and parameters: {'w0': 0.9992674318740729, 'w1': 1.6749652363140218e-05, 'w2': 0.0008322564400756911, 'w3': 0.01345252000486069, 'w4': 0.04666684202054418}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:48,331]\u001b[0m Trial 887 finished with value: 0.7665477665822429 and parameters: {'w0': 0.9373883914052479, 'w1': 0.07840986022421596, 'w2': 0.0006624407099777902, 'w3': 0.09586259173688753, 'w4': 0.016205705208549893}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:48,482]\u001b[0m Trial 888 finished with value: 0.7664222142294044 and parameters: {'w0': 0.143581124535957, 'w1': 0.04774896154916677, 'w2': 0.03506604931543358, 'w3': 0.3959300474467917, 'w4': 0.8280073513263848}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:48,639]\u001b[0m Trial 889 finished with value: 0.7665668723282322 and parameters: {'w0': 0.8579031005338037, 'w1': 0.03270457981264937, 'w2': 0.01973251437027641, 'w3': 0.0644471543476905, 'w4': 0.00023580486897379854}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:48,788]\u001b[0m Trial 890 finished with value: 0.7664078579903844 and parameters: {'w0': 0.8811917579788094, 'w1': 0.01768767872070507, 'w2': 0.7337079769579149, 'w3': 0.11244359186730626, 'w4': 0.06970631592082524}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:48,938]\u001b[0m Trial 891 finished with value: 0.7665505775940789 and parameters: {'w0': 0.9126856430588279, 'w1': 8.317669848941292e-05, 'w2': 0.090752053174386, 'w3': 0.08228329282708999, 'w4': 0.0346147780405678}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:49,088]\u001b[0m Trial 892 finished with value: 0.7665496473404687 and parameters: {'w0': 0.9432622057313721, 'w1': 0.05609513833827164, 'w2': 0.06323858361217523, 'w3': 0.14492821318757995, 'w4': 0.019328716231329247}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:49,240]\u001b[0m Trial 893 finished with value: 0.7665426538498017 and parameters: {'w0': 0.8938416884420433, 'w1': 0.00041260861950053384, 'w2': 0.017525927862359167, 'w3': 0.03780751545233422, 'w4': 0.049199856320934154}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:49,389]\u001b[0m Trial 894 finished with value: 0.7665390664058184 and parameters: {'w0': 0.9636322522193479, 'w1': 0.03133481423115483, 'w2': 0.0458213133395818, 'w3': 0.059084850775320163, 'w4': 0.03103324342959549}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:49,551]\u001b[0m Trial 895 finished with value: 0.7665737339719305 and parameters: {'w0': 0.9246494875153201, 'w1': 0.033028473948076176, 'w2': 0.0005099219184803701, 'w3': 0.09494396988944585, 'w4': 0.018005745699843794}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:49,708]\u001b[0m Trial 896 finished with value: 0.7664840982844245 and parameters: {'w0': 0.8658044123956642, 'w1': 0.01672855187085064, 'w2': 0.03116134881093204, 'w3': 0.12516589082915358, 'w4': 0.21846922809264335}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:49,857]\u001b[0m Trial 897 finished with value: 0.7665434897423463 and parameters: {'w0': 0.9035481810478165, 'w1': 0.00014961708422077738, 'w2': 0.05100687122033058, 'w3': 0.07579105624613822, 'w4': 0.061724218316630275}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:50,007]\u001b[0m Trial 898 finished with value: 0.7665630547983628 and parameters: {'w0': 0.8812441980450152, 'w1': 0.048180592565357915, 'w2': 0.00037326159435556103, 'w3': 0.10487502779037591, 'w4': 0.016407087220886123}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:50,159]\u001b[0m Trial 899 finished with value: 0.7665065415683787 and parameters: {'w0': 0.6258944960930863, 'w1': 0.06996965317025626, 'w2': 0.020183885699293188, 'w3': 0.058035187293008536, 'w4': 0.03649233142730712}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:19:50,310]\u001b[0m Trial 900 finished with value: 0.7665380551481882 and parameters: {'w0': 0.9506452494911016, 'w1': 0.0322486592896249, 'w2': 0.07456023159581404, 'w3': 0.1681675645610213, 'w4': 0.08585991452070546}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:50,461]\u001b[0m Trial 901 finished with value: 0.766560463531474 and parameters: {'w0': 0.9190586800896934, 'w1': 0.0008836793558728122, 'w2': 0.020499917793878823, 'w3': 0.02698446764833142, 'w4': 0.018103344645567367}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:50,614]\u001b[0m Trial 902 finished with value: 0.7665899502872988 and parameters: {'w0': 0.8543321059543755, 'w1': 0.0001623860804127041, 'w2': 0.03751363762424728, 'w3': 0.0878443481703346, 'w4': 0.0009369102590273265}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:50,768]\u001b[0m Trial 903 finished with value: 0.7665759512415364 and parameters: {'w0': 0.8432262132512212, 'w1': 0.01669194056474432, 'w2': 0.03768533411471668, 'w3': 0.07953718024437278, 'w4': 0.0003560700778076815}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:50,920]\u001b[0m Trial 904 finished with value: 0.7663543798259083 and parameters: {'w0': 0.8337279426497569, 'w1': 0.0005634411209424008, 'w2': 0.6072595830194164, 'w3': 0.046894748048153904, 'w4': 0.04855667980744715}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:51,070]\u001b[0m Trial 905 finished with value: 0.7665713796848871 and parameters: {'w0': 0.8550703807146272, 'w1': 0.00047771914713018654, 'w2': 0.020119844591844963, 'w3': 0.0718693289972265, 'w4': 0.03302171758914714}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:51,223]\u001b[0m Trial 906 finished with value: 0.7665633008265293 and parameters: {'w0': 0.8527461908569793, 'w1': 0.019719509688927182, 'w2': 0.05487911470760093, 'w3': 0.119273155958639, 'w4': 0.018369921270933585}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:51,376]\u001b[0m Trial 907 finished with value: 0.7665403133506763 and parameters: {'w0': 0.8166908590672317, 'w1': 0.034697268508680656, 'w2': 0.017347427384387982, 'w3': 0.09325211793428245, 'w4': 0.05607342164087882}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:51,527]\u001b[0m Trial 908 finished with value: 0.7664951837707088 and parameters: {'w0': 0.8701372415479499, 'w1': 0.019637239649442886, 'w2': 0.034518609635760665, 'w3': 0.017182471629658087, 'w4': 0.018730478659346732}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:51,679]\u001b[0m Trial 909 finished with value: 0.7663971857107759 and parameters: {'w0': 0.8290868825505806, 'w1': 0.04662437314672849, 'w2': 0.0011420363938236672, 'w3': 0.059549183147259516, 'w4': 0.25994226928704456}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:51,838]\u001b[0m Trial 910 finished with value: 0.766356004645901 and parameters: {'w0': 0.8567270116475761, 'w1': 0.019025650879599086, 'w2': 0.0687927014952628, 'w3': 0.963550408026552, 'w4': 0.03822804618392646}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:51,988]\u001b[0m Trial 911 finished with value: 0.7665718549371946 and parameters: {'w0': 0.8765233312987168, 'w1': 0.03458896774422453, 'w2': 0.00014110357633787923, 'w3': 0.10964985834300911, 'w4': 0.0009874896351526434}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:52,138]\u001b[0m Trial 912 finished with value: 0.7665261492807673 and parameters: {'w0': 0.886580986305481, 'w1': 0.019226322520195623, 'w2': 0.03606539160994207, 'w3': 0.0359148753999204, 'w4': 0.033618321352171805}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:52,291]\u001b[0m Trial 913 finished with value: 0.7665127353597863 and parameters: {'w0': 0.8545119823595013, 'w1': 0.11699528220153466, 'w2': 0.047707003241591536, 'w3': 0.08982049509339235, 'w4': 0.0167787336379938}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:52,445]\u001b[0m Trial 914 finished with value: 0.7665494543096127 and parameters: {'w0': 0.8947476759405231, 'w1': 0.0006269763988302594, 'w2': 0.022264307219581524, 'w3': 0.14429699948491825, 'w4': 0.07027586555064039}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:52,595]\u001b[0m Trial 915 finished with value: 0.7663710968150583 and parameters: {'w0': 0.8727839029673193, 'w1': 0.47957878244240343, 'w2': 0.01654837875797092, 'w3': 0.0695382531495164, 'w4': 0.000387597280783081}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:52,746]\u001b[0m Trial 916 finished with value: 0.766502040243938 and parameters: {'w0': 0.8362603883994587, 'w1': 0.05174891341458908, 'w2': 0.034664589365035005, 'w3': 0.049833163792005024, 'w4': 0.04995235830970357}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:52,903]\u001b[0m Trial 917 finished with value: 0.766558653005457 and parameters: {'w0': 0.8994904654009493, 'w1': 0.01705141795099977, 'w2': 0.06342677491520674, 'w3': 0.1132982930832793, 'w4': 0.030278048953873142}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:53,054]\u001b[0m Trial 918 finished with value: 0.7665919684938347 and parameters: {'w0': 0.8733291838784379, 'w1': 0.0003904723901891444, 'w2': 0.00010959826876841272, 'w3': 0.09326132364470813, 'w4': 0.01861537213786077}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:53,207]\u001b[0m Trial 919 finished with value: 0.7665333379566521 and parameters: {'w0': 0.9066663528358841, 'w1': 0.0007536161327525819, 'w2': 0.09349725449883954, 'w3': 0.21907124612189638, 'w4': 0.0006131947103190268}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:53,360]\u001b[0m Trial 920 finished with value: 0.7664807116270012 and parameters: {'w0': 0.7167647401520851, 'w1': 0.22221206536051757, 'w2': 0.045897953905726395, 'w3': 0.13195629841882295, 'w4': 0.0351613031578104}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:53,510]\u001b[0m Trial 921 finished with value: 0.7665320897191767 and parameters: {'w0': 0.8507380707150765, 'w1': 0.018701032372825038, 'w2': 0.018805155745175085, 'w3': 0.10451418855003874, 'w4': 0.10106108596502035}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:53,663]\u001b[0m Trial 922 finished with value: 0.7664899663362633 and parameters: {'w0': 0.27665934538325543, 'w1': 0.034251361881223366, 'w2': 0.03263053085759505, 'w3': 0.12354056327453915, 'w4': 0.01606161543754073}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:53,816]\u001b[0m Trial 923 finished with value: 0.7665654827645947 and parameters: {'w0': 0.8844442557129653, 'w1': 0.0002595780327288819, 'w2': 0.016583334045383973, 'w3': 0.09539555967675901, 'w4': 0.052333873197348085}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:53,974]\u001b[0m Trial 924 finished with value: 0.7664213486066607 and parameters: {'w0': 0.9137236758438343, 'w1': 0.0005203525296961556, 'w2': 0.05551987181950404, 'w3': 7.235768523364272e-05, 'w4': 0.018710843598346204}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:54,125]\u001b[0m Trial 925 finished with value: 0.7662470667345705 and parameters: {'w0': 0.0101656475667522, 'w1': 0.03251870715139593, 'w2': 0.08061592166406176, 'w3': 0.9075082459031305, 'w4': 0.00011226307059605811}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:54,274]\u001b[0m Trial 926 finished with value: 0.7665781258547701 and parameters: {'w0': 0.8059736905631888, 'w1': 0.0006647255486930274, 'w2': 0.0006444713256571334, 'w3': 0.08520961445290912, 'w4': 0.03843951417156101}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:54,430]\u001b[0m Trial 927 finished with value: 0.7665367939845396 and parameters: {'w0': 0.8697089750813876, 'w1': 0.052359405485596304, 'w2': 0.03213445076009566, 'w3': 0.14672079748022654, 'w4': 0.06274209916140995}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:19:54,580]\u001b[0m Trial 928 finished with value: 0.7665809200625808 and parameters: {'w0': 0.8938380467769685, 'w1': 0.016198229971742143, 'w2': 0.016737171738512965, 'w3': 0.06544945448208554, 'w4': 2.6252707095343736e-05}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:54,897]\u001b[0m Trial 929 finished with value: 0.766438024232056 and parameters: {'w0': 0.3192527502375042, 'w1': 0.07001955436961713, 'w2': 0.46516982410752905, 'w3': 0.10943802576024046, 'w4': 0.0005650572011478838}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:55,050]\u001b[0m Trial 930 finished with value: 0.7665152848320479 and parameters: {'w0': 0.925878015002446, 'w1': 0.04408000364637361, 'w2': 0.6596976492282598, 'w3': 0.6159850823130596, 'w4': 0.030424414728573244}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:55,203]\u001b[0m Trial 931 finished with value: 0.7665612800347588 and parameters: {'w0': 0.8958783720308239, 'w1': 0.0315051076247885, 'w2': 0.02062138988706813, 'w3': 0.07791157418617695, 'w4': 0.018856376834078818}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:55,355]\u001b[0m Trial 932 finished with value: 0.7665865877587321 and parameters: {'w0': 0.9245704103516275, 'w1': 0.018892760387385476, 'w2': 0.016170777420055127, 'w3': 0.09272743860234363, 'w4': 0.00013019804396875322}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:55,512]\u001b[0m Trial 933 finished with value: 0.766377540081612 and parameters: {'w0': 0.933587090085063, 'w1': 0.07364583542031074, 'w2': 0.0013082218908767324, 'w3': 0.7159075995305806, 'w4': 0.0005579026662262537}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:55,664]\u001b[0m Trial 934 finished with value: 0.7665535053723478 and parameters: {'w0': 0.9108606579197404, 'w1': 0.05691381615714352, 'w2': 0.018836208564462217, 'w3': 0.12314009925315034, 'w4': 0.02205908589674105}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:55,818]\u001b[0m Trial 935 finished with value: 0.7664559476640543 and parameters: {'w0': 0.9359353780867938, 'w1': 0.6204806011485942, 'w2': 0.0008483517367383292, 'w3': 0.7445978405319349, 'w4': 0.01751808117897659}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:55,969]\u001b[0m Trial 936 finished with value: 0.7665316213608282 and parameters: {'w0': 0.8952219912646502, 'w1': 0.04767087636361014, 'w2': 0.017200240935193702, 'w3': 0.17715716129723552, 'w4': 0.04213659407751345}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:56,128]\u001b[0m Trial 937 finished with value: 0.7665422677880902 and parameters: {'w0': 0.9252416478581289, 'w1': 0.09738426532778467, 'w2': 0.018537383563078373, 'w3': 0.1005636953514559, 'w4': 0.0006241908667390659}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:56,280]\u001b[0m Trial 938 finished with value: 0.7664650989639294 and parameters: {'w0': 0.5459012793761544, 'w1': 0.03558730775258541, 'w2': 0.5170308436351536, 'w3': 0.13483645128112917, 'w4': 0.0003151759643497825}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:56,431]\u001b[0m Trial 939 finished with value: 0.7665831726637271 and parameters: {'w0': 0.9077284180453411, 'w1': 0.029359282484818755, 'w2': 0.0015424419194478723, 'w3': 0.09660022021107104, 'w4': 0.0001363312265285463}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:56,588]\u001b[0m Trial 940 finished with value: 0.7665364962516794 and parameters: {'w0': 0.8884539783918727, 'w1': 0.08381209829307318, 'w2': 0.002355339564124999, 'w3': 0.14404660948652775, 'w4': 0.03277698583257675}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:56,741]\u001b[0m Trial 941 finished with value: 0.7665376436650025 and parameters: {'w0': 0.9024594357915083, 'w1': 0.06180523990504894, 'w2': 0.01541879640972461, 'w3': 0.16346785020935065, 'w4': 0.01961719050751307}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:56,895]\u001b[0m Trial 942 finished with value: 0.7665533929146394 and parameters: {'w0': 0.8648645542547092, 'w1': 0.03119868208804437, 'w2': 0.00018290141849006472, 'w3': 0.11383513327693098, 'w4': 0.04931802102464952}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:57,047]\u001b[0m Trial 943 finished with value: 0.7665637622909187 and parameters: {'w0': 0.8832933014159783, 'w1': 0.028868252931773013, 'w2': 0.0012162668157658348, 'w3': 0.11442488754813054, 'w4': 0.029583048140502423}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:57,205]\u001b[0m Trial 944 finished with value: 0.7665583139088423 and parameters: {'w0': 0.9061556860053344, 'w1': 0.04340275442207371, 'w2': 0.030504587795244047, 'w3': 0.1261418519984716, 'w4': 0.016972711030163297}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:57,356]\u001b[0m Trial 945 finished with value: 0.7663786310506446 and parameters: {'w0': 0.8544966841576609, 'w1': 0.017596752906420078, 'w2': 0.033259000573832714, 'w3': 0.8014355281390935, 'w4': 0.07554440760860236}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:57,508]\u001b[0m Trial 946 finished with value: 0.7665428494658919 and parameters: {'w0': 0.8816155829230268, 'w1': 0.06166159998536121, 'w2': 0.00017140551334645884, 'w3': 0.09917489037620496, 'w4': 0.03955464114942232}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:57,664]\u001b[0m Trial 947 finished with value: 0.7665752015234808 and parameters: {'w0': 0.9110727453539972, 'w1': 0.01982373065666905, 'w2': 0.017413734547586497, 'w3': 0.09239107457671678, 'w4': 0.017097897652272022}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:57,817]\u001b[0m Trial 948 finished with value: 0.7665387527306778 and parameters: {'w0': 0.8308939104461786, 'w1': 0.04672374084518469, 'w2': 0.03553181388438153, 'w3': 0.14543962638616464, 'w4': 0.054945203984288996}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:57,971]\u001b[0m Trial 949 finished with value: 0.7664902015926186 and parameters: {'w0': 0.8952174931005213, 'w1': 0.30432271681847156, 'w2': 0.0184862354393505, 'w3': 0.32930385591214767, 'w4': 0.00046921401871321796}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:58,139]\u001b[0m Trial 950 finished with value: 0.7665745435812562 and parameters: {'w0': 0.8656006607275799, 'w1': 0.01731893507250219, 'w2': 0.04146934700399677, 'w3': 0.11266047278426314, 'w4': 2.5919797744695288e-05}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:58,297]\u001b[0m Trial 951 finished with value: 0.7665800544398373 and parameters: {'w0': 0.9184743718000148, 'w1': 2.3306576320547556e-05, 'w2': 0.020333332368563495, 'w3': 0.08943441989622, 'w4': 0.02925777053272714}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:58,449]\u001b[0m Trial 952 finished with value: 0.7664571816827388 and parameters: {'w0': 0.8848841827096812, 'w1': 0.35956548674485894, 'w2': 0.016733067469575237, 'w3': 0.1276987413600129, 'w4': 0.0183787071017015}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:58,604]\u001b[0m Trial 953 finished with value: 0.766542770185362 and parameters: {'w0': 0.9245018223815673, 'w1': 0.036600469142113574, 'w2': 0.04296584107602489, 'w3': 0.09816363089361677, 'w4': 0.04663705299131431}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:58,760]\u001b[0m Trial 954 finished with value: 0.7665577253370814 and parameters: {'w0': 0.8516367958399552, 'w1': 0.02163318279829728, 'w2': 0.01714733554119679, 'w3': 0.07371312286430179, 'w4': 0.03344088768334597}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:58,913]\u001b[0m Trial 955 finished with value: 0.7665656645927668 and parameters: {'w0': 0.901696245542377, 'w1': 0.059012445844085826, 'w2': 0.0017509784024863475, 'w3': 0.10640116318884327, 'w4': 0.00028240418099683036}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:19:59,065]\u001b[0m Trial 956 finished with value: 0.7665817046813046 and parameters: {'w0': 0.8784132087197367, 'w1': 0.03167222940378581, 'w2': 0.0005215580767107013, 'w3': 0.08130174731871184, 'w4': 9.113996715945891e-05}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:59,219]\u001b[0m Trial 957 finished with value: 0.7665338149324497 and parameters: {'w0': 0.8402399412378546, 'w1': 0.09037743325057015, 'w2': 0.03478938887949369, 'w3': 0.15900860348490978, 'w4': 0.016906113877484807}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:59,380]\u001b[0m Trial 958 finished with value: 0.7664356833020585 and parameters: {'w0': 0.8619257055222395, 'w1': 0.4357266298030198, 'w2': 0.047092482065194494, 'w3': 0.126151027186957, 'w4': 0.0001616408997320779}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:59,532]\u001b[0m Trial 959 finished with value: 0.7665316304091496 and parameters: {'w0': 0.8145703789558291, 'w1': 0.06831466875960734, 'w2': 0.032285732571084164, 'w3': 0.0913408187602973, 'w4': 0.03154858600675617}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:59,687]\u001b[0m Trial 960 finished with value: 0.766567098536266 and parameters: {'w0': 0.8557247217060355, 'w1': 0.04419669847428889, 'w2': 0.00020926348113283963, 'w3': 0.06992572640811831, 'w4': 0.00044098823225713}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:59,841]\u001b[0m Trial 961 finished with value: 0.7665810467390799 and parameters: {'w0': 0.8744716562542793, 'w1': 0.0001410820977340131, 'w2': 0.01934785476580897, 'w3': 0.10576093609331089, 'w4': 0.01837396869245742}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:19:59,993]\u001b[0m Trial 962 finished with value: 0.7665662712611704 and parameters: {'w0': 0.8743945795499022, 'w1': 0.017260008916458357, 'w2': 0.06178063370574807, 'w3': 0.13368589498806993, 'w4': 5.3140404324750895e-05}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:00,152]\u001b[0m Trial 963 finished with value: 0.7665644891727347 and parameters: {'w0': 0.8233174389674078, 'w1': 0.017557458399714204, 'w2': 0.05349147687638998, 'w3': 0.11006746362380873, 'w4': 0.018561901285893374}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:00,311]\u001b[0m Trial 964 finished with value: 0.7665038494773375 and parameters: {'w0': 0.8476427015527311, 'w1': 0.036790357935138886, 'w2': 0.28205177965117856, 'w3': 0.11673075594528823, 'w4': 0.01894090730902695}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:00,469]\u001b[0m Trial 965 finished with value: 0.7665454558133163 and parameters: {'w0': 0.8708040141411748, 'w1': 0.01914591038488071, 'w2': 0.03259806178247368, 'w3': 0.15153466035043617, 'w4': 0.045407348067620666}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:00,621]\u001b[0m Trial 966 finished with value: 0.7665833381187463 and parameters: {'w0': 0.8733716294050654, 'w1': 0.0014557354970484541, 'w2': 0.051699952936407965, 'w3': 0.08494598909065292, 'w4': 0.0006714468376220345}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:00,778]\u001b[0m Trial 967 finished with value: 0.7665498076250182 and parameters: {'w0': 0.828816409078603, 'w1': 0.0007422452133235627, 'w2': 0.06367126769204709, 'w3': 0.06750880190424112, 'w4': 0.03704970928818555}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:00,931]\u001b[0m Trial 968 finished with value: 0.7662585391443109 and parameters: {'w0': 0.841178630294965, 'w1': 0.0016698387981437177, 'w2': 0.07702516332590448, 'w3': 0.08208647288022655, 'w4': 0.9543875441218806}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:01,085]\u001b[0m Trial 969 finished with value: 0.7665279055168562 and parameters: {'w0': 0.8604978852861487, 'w1': 0.03306211952396096, 'w2': 0.050624036946242956, 'w3': 0.1938705983505713, 'w4': 0.01728622026582493}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:01,238]\u001b[0m Trial 970 finished with value: 0.7665490346398508 and parameters: {'w0': 0.8681050299606536, 'w1': 0.00040319945220913085, 'w2': 0.00010718492299213961, 'w3': 0.0510584589351086, 'w4': 0.06250523630215434}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:01,396]\u001b[0m Trial 971 finished with value: 0.7665150861998503 and parameters: {'w0': 0.8421897227684538, 'w1': 4.794347722632069e-05, 'w2': 0.19078383501136664, 'w3': 0.06953715812150273, 'w4': 0.01885652499368277}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:01,549]\u001b[0m Trial 972 finished with value: 0.7663120242027464 and parameters: {'w0': 0.8774797419975247, 'w1': 0.8718758302412883, 'w2': 0.031859083060427895, 'w3': 0.09056941080679282, 'w4': 0.035365155512570405}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:01,702]\u001b[0m Trial 973 finished with value: 0.76656814038584 and parameters: {'w0': 0.8778377806304595, 'w1': 0.01827629391277091, 'w2': 0.050724030070951595, 'w3': 0.10675110851926736, 'w4': 0.016594667231325067}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:01,862]\u001b[0m Trial 974 finished with value: 0.7664386545984442 and parameters: {'w0': 0.8544530645784166, 'w1': 0.0008148974135317143, 'w2': 0.22585594157131506, 'w3': 0.04135288624374826, 'w4': 0.051095447608967594}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:02,018]\u001b[0m Trial 975 finished with value: 0.7663251080754341 and parameters: {'w0': 0.8233093831989571, 'w1': 0.035204628139799965, 'w2': 0.018535892157813705, 'w3': 0.061982277942524554, 'w4': 0.45183502079547316}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:02,171]\u001b[0m Trial 976 finished with value: 0.7665865373466559 and parameters: {'w0': 0.7898354994632033, 'w1': 0.00016443906082417518, 'w2': 0.018749489992102377, 'w3': 0.08296225914427763, 'w4': 0.017242576142858165}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:02,326]\u001b[0m Trial 977 finished with value: 0.766544159318127 and parameters: {'w0': 0.814288184385463, 'w1': 0.0011119677234016651, 'w2': 0.07055421858503436, 'w3': 0.1297345786228305, 'w4': 0.07574540375451617}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:02,482]\u001b[0m Trial 978 finished with value: 0.7665116952337022 and parameters: {'w0': 0.782320229342487, 'w1': 0.017255297072900994, 'w2': 0.04349259101023342, 'w3': 0.10273257630711463, 'w4': 0.12628780206967347}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:02,640]\u001b[0m Trial 979 finished with value: 0.766541043679472 and parameters: {'w0': 0.7686057211391809, 'w1': 0.03126272480142201, 'w2': 0.01966909838180243, 'w3': 0.12109962577254245, 'w4': 0.06211750954802649}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:02,792]\u001b[0m Trial 980 finished with value: 0.76656262090981 and parameters: {'w0': 0.8439829162962236, 'w1': 0.0010327957522592575, 'w2': 0.0326847168354203, 'w3': 0.08371073569523485, 'w4': 0.042926066401712634}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:02,947]\u001b[0m Trial 981 finished with value: 0.7663305301742912 and parameters: {'w0': 0.40771195955282286, 'w1': 0.7565034389720328, 'w2': 0.0005774549568090003, 'w3': 0.10442581150966193, 'w4': 0.03323853713064916}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:03,100]\u001b[0m Trial 982 finished with value: 0.7665296471032819 and parameters: {'w0': 0.8391549617148845, 'w1': 0.03300072795136286, 'w2': 0.05564692692360492, 'w3': 0.13705977340600614, 'w4': 0.09340986383599496}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:03,253]\u001b[0m Trial 983 finished with value: 0.7665854007051442 and parameters: {'w0': 0.8330546720366537, 'w1': 0.0004989240593758734, 'w2': 0.00023232847093274887, 'w3': 0.08517908478713848, 'w4': 0.030695549116035586}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:20:03,407]\u001b[0m Trial 984 finished with value: 0.7665524626610289 and parameters: {'w0': 0.7974492622749629, 'w1': 0.015984490934812464, 'w2': 0.0007156244606915035, 'w3': 0.08307653810374599, 'w4': 0.05640681851253353}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:03,563]\u001b[0m Trial 985 finished with value: 0.7665478587889463 and parameters: {'w0': 0.8103364088088209, 'w1': 0.04759658474601314, 'w2': 0.01915725695829839, 'w3': 0.11492233526576952, 'w4': 0.03327679414833463}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:03,714]\u001b[0m Trial 986 finished with value: 0.7665861887708474 and parameters: {'w0': 0.8281419886669777, 'w1': 0.0005717547286033199, 'w2': 0.017086957925461676, 'w3': 0.0909676436071718, 'w4': 0.0172925176626342}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:03,867]\u001b[0m Trial 987 finished with value: 0.7665115271934484 and parameters: {'w0': 0.7924795079970481, 'w1': 0.03100379303460305, 'w2': 0.033169863149149714, 'w3': 0.058799350146559924, 'w4': 0.07264963261541912}. Best is trial 516 with value: 0.7665950294116892.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:04,023]\u001b[0m Trial 988 finished with value: 0.7665963698558678 and parameters: {'w0': 0.836673999422235, 'w1': 0.00015435340094474212, 'w2': 0.001237320352105978, 'w3': 0.07595700978859143, 'w4': 0.01645339246244691}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:04,177]\u001b[0m Trial 989 finished with value: 0.7663576372215981 and parameters: {'w0': 0.8032050685708944, 'w1': 0.5503883698579913, 'w2': 0.0009678708180554177, 'w3': 0.08576472800757898, 'w4': 0.05986746352910221}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:04,331]\u001b[0m Trial 990 finished with value: 0.7665571001411626 and parameters: {'w0': 0.7864414693620854, 'w1': 0.018659014868547603, 'w2': 0.0002935822594671854, 'w3': 0.08354445213449543, 'w4': 0.04638783192206444}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:04,489]\u001b[0m Trial 991 finished with value: 0.7665482853526675 and parameters: {'w0': 0.8108675396790254, 'w1': 0.053578334464536914, 'w2': 0.00044368598330208475, 'w3': 0.09774413891029504, 'w4': 0.030852829548241374}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:04,644]\u001b[0m Trial 992 finished with value: 0.7662716441297484 and parameters: {'w0': 0.8226840836429893, 'w1': 0.9779104394710392, 'w2': 0.01857095846185511, 'w3': 0.0727516827508103, 'w4': 0.08257629062080388}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:04,806]\u001b[0m Trial 993 finished with value: 0.7665456501367893 and parameters: {'w0': 0.7770750582560756, 'w1': 0.03142866660863493, 'w2': 0.0006295571200632556, 'w3': 0.11979418683505763, 'w4': 0.04552987973000227}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:04,959]\u001b[0m Trial 994 finished with value: 0.7665789604546975 and parameters: {'w0': 0.8201096170489929, 'w1': 0.01652069474006067, 'w2': 1.1627571476569357e-05, 'w3': 0.09098416225139118, 'w4': 0.019711342349428965}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:05,116]\u001b[0m Trial 995 finished with value: 0.7665504319591923 and parameters: {'w0': 0.7981130877891136, 'w1': 0.04761815314295262, 'w2': 0.02209644317359377, 'w3': 0.07730524039931579, 'w4': 0.016295367339653328}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:05,285]\u001b[0m Trial 996 finished with value: 0.7665612899448251 and parameters: {'w0': 0.8051086143432653, 'w1': 0.01884912974699171, 'w2': 0.020246897513493973, 'w3': 0.10267219001269567, 'w4': 0.03552942446106938}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:05,440]\u001b[0m Trial 997 finished with value: 0.7665579114739779 and parameters: {'w0': 0.758265217335529, 'w1': 0.0009604519715862498, 'w2': 1.5724326041699445e-05, 'w3': 0.07113978283381335, 'w4': 0.057491363850424505}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:05,596]\u001b[0m Trial 998 finished with value: 0.7665461477944642 and parameters: {'w0': 0.8260705136206422, 'w1': 0.03316949400278698, 'w2': 0.03101342762157531, 'w3': 0.14448272538367612, 'w4': 0.016601794696067537}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:05,749]\u001b[0m Trial 999 finished with value: 0.766543965856399 and parameters: {'w0': 0.8261492979632188, 'w1': 0.05952022760951665, 'w2': 0.01866344246768439, 'w3': 0.11564776964506543, 'w4': 0.03123222075483003}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:05,902]\u001b[0m Trial 1000 finished with value: 0.7665783649889775 and parameters: {'w0': 0.8046296291567991, 'w1': 0.000974963301226095, 'w2': 0.019540769592812507, 'w3': 0.05950250651619156, 'w4': 0.01764649566120006}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:06,054]\u001b[0m Trial 1001 finished with value: 0.7665872043372021 and parameters: {'w0': 0.8286729453445011, 'w1': 0.00038901676687012833, 'w2': 0.0421676899124265, 'w3': 0.09362472975875112, 'w4': 0.0008748296040905616}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:06,212]\u001b[0m Trial 1002 finished with value: 0.7665510468141723 and parameters: {'w0': 0.7919151155033908, 'w1': 0.032417019140420104, 'w2': 0.017487848354928393, 'w3': 0.12958112487773915, 'w4': 0.0007790187531229106}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:06,367]\u001b[0m Trial 1003 finished with value: 0.7663681500784018 and parameters: {'w0': 0.8101046673408973, 'w1': 0.01906720516073452, 'w2': 0.03512188262305616, 'w3': 0.15268117391602226, 'w4': 0.7045215113697181}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:06,520]\u001b[0m Trial 1004 finished with value: 0.7665454997623058 and parameters: {'w0': 0.8159552649248031, 'w1': 0.0475784455747955, 'w2': 0.0006583505265709277, 'w3': 0.10567563014218581, 'w4': 0.04446055382261322}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:06,675]\u001b[0m Trial 1005 finished with value: 0.7665399018674907 and parameters: {'w0': 0.8247958384667291, 'w1': 0.018522346125498086, 'w2': 0.039276681778961986, 'w3': 0.09613110394559271, 'w4': 0.06505865171062253}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:06,829]\u001b[0m Trial 1006 finished with value: 0.7665352152678981 and parameters: {'w0': 0.7759472662700375, 'w1': 0.07253320726131025, 'w2': 0.017522626922660704, 'w3': 0.13052405285461383, 'w4': 0.03521353842752206}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:06,986]\u001b[0m Trial 1007 finished with value: 0.7663370811589563 and parameters: {'w0': 0.8313179159425712, 'w1': 0.03529216304682805, 'w2': 0.0007716497283586643, 'w3': 0.0928418232607601, 'w4': 0.5861412911554932}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:07,142]\u001b[0m Trial 1008 finished with value: 0.7665744259530786 and parameters: {'w0': 0.83420152539205, 'w1': 0.00040710996280961834, 'w2': 0.04407836663614969, 'w3': 0.11824169503761069, 'w4': 0.0008801507519368183}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:07,298]\u001b[0m Trial 1009 finished with value: 0.7665853787306494 and parameters: {'w0': 0.8408990176118691, 'w1': 0.000132611870580222, 'w2': 0.01983689772288906, 'w3': 0.08491977300895184, 'w4': 0.020097537103496786}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:07,452]\u001b[0m Trial 1010 finished with value: 0.7663336173753651 and parameters: {'w0': 0.8024796942935762, 'w1': 0.7308015985113642, 'w2': 0.05460601348837191, 'w3': 0.10698252009067423, 'w4': 0.09660923040402333}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:07,607]\u001b[0m Trial 1011 finished with value: 0.7665345948115764 and parameters: {'w0': 0.8284970589097699, 'w1': 0.0013180307502377322, 'w2': 0.03347664051902978, 'w3': 0.17564165462435002, 'w4': 0.07893230206546437}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:20:07,761]\u001b[0m Trial 1012 finished with value: 0.7665460508481639 and parameters: {'w0': 0.7899543869091428, 'w1': 0.016896538803865255, 'w2': 0.06360838024156584, 'w3': 0.12902894851634097, 'w4': 0.0529254320581515}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:07,914]\u001b[0m Trial 1013 finished with value: 0.7664498137639166 and parameters: {'w0': 0.8362899194765021, 'w1': 0.016784736175911766, 'w2': 0.4121580806366579, 'w3': 0.09134302177374465, 'w4': 0.04787925782401828}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:08,069]\u001b[0m Trial 1014 finished with value: 0.7663888095504304 and parameters: {'w0': 0.8179144597439818, 'w1': 0.01702080782892592, 'w2': 0.0343518784953152, 'w3': 0.9982555594505558, 'w4': 0.03206197074150985}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:08,227]\u001b[0m Trial 1015 finished with value: 0.7663806798491241 and parameters: {'w0': 0.8360353608112, 'w1': 0.016363161198532053, 'w2': 0.9106318473450323, 'w3': 0.10749046530234421, 'w4': 0.06174039722553991}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:08,381]\u001b[0m Trial 1016 finished with value: 0.7664642915089662 and parameters: {'w0': 0.7404509840067457, 'w1': 0.018118831698597702, 'w2': 0.3122061743528164, 'w3': 0.07863450195077883, 'w4': 0.03204024309078946}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:08,536]\u001b[0m Trial 1017 finished with value: 0.766536027893331 and parameters: {'w0': 0.7714182182989664, 'w1': 0.03579339401197144, 'w2': 0.019217665434683354, 'w3': 0.14689789851044063, 'w4': 0.021934287164669095}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:08,704]\u001b[0m Trial 1018 finished with value: 0.7663612259581987 and parameters: {'w0': 0.841831883652289, 'w1': 0.0005921249317046095, 'w2': 0.0476483507039093, 'w3': 0.8289690476800696, 'w4': 0.04710117346162327}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:08,860]\u001b[0m Trial 1019 finished with value: 0.7665722323814572 and parameters: {'w0': 0.7987542047933431, 'w1': 0.0014021220585675829, 'w2': 0.03199399835624278, 'w3': 0.0594824310313601, 'w4': 0.01736899916341477}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:09,016]\u001b[0m Trial 1020 finished with value: 0.7664696713823237 and parameters: {'w0': 0.8149575833272965, 'w1': 0.01802786465624239, 'w2': 0.36642690825264035, 'w3': 0.11578948832001822, 'w4': 0.07665170083157874}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:09,172]\u001b[0m Trial 1021 finished with value: 0.7665498912142729 and parameters: {'w0': 0.8401533672656446, 'w1': 0.03982329753660968, 'w2': 0.017959025444234535, 'w3': 0.09057080170704519, 'w4': 0.034441363727572734}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:09,327]\u001b[0m Trial 1022 finished with value: 0.7665585633839884 and parameters: {'w0': 0.8201210366837574, 'w1': 0.0014127777653415077, 'w2': 0.05141304299722342, 'w3': 0.04374490322435803, 'w4': 0.016185727703067983}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:09,479]\u001b[0m Trial 1023 finished with value: 0.766528375167822 and parameters: {'w0': 0.8441942204147553, 'w1': 0.05003971637066179, 'w2': 0.07371999830891285, 'w3': 0.0708462610503003, 'w4': 0.01921077847784581}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:09,640]\u001b[0m Trial 1024 finished with value: 0.7662897274154239 and parameters: {'w0': 0.7961565345055035, 'w1': 0.029392366234660017, 'w2': 0.9703238696364523, 'w3': 0.09774450800153885, 'w4': 0.5351418595316255}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:09,795]\u001b[0m Trial 1025 finished with value: 0.766551596607413 and parameters: {'w0': 0.8403476166681362, 'w1': 0.0012695655147823455, 'w2': 0.018096667549679105, 'w3': 0.13748370733683746, 'w4': 0.04975550827315559}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:09,951]\u001b[0m Trial 1026 finished with value: 0.7665755108898968 and parameters: {'w0': 0.8171369403867654, 'w1': 0.00032949796207155924, 'w2': 0.035731852556787846, 'w3': 0.07158445702395415, 'w4': 0.017114514879451204}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:10,109]\u001b[0m Trial 1027 finished with value: 0.7665643797311334 and parameters: {'w0': 0.8313457410019258, 'w1': 0.03002828414646175, 'w2': 0.018261688210803314, 'w3': 0.1175227220905807, 'w4': 0.00044054321773286673}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:10,263]\u001b[0m Trial 1028 finished with value: 0.7665637497956178 and parameters: {'w0': 0.8469182411535517, 'w1': 0.017881711980297844, 'w2': 0.05131855397207519, 'w3': 0.05556959127640547, 'w4': 0.0002803948987045316}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:10,423]\u001b[0m Trial 1029 finished with value: 0.7664658616081585 and parameters: {'w0': 0.8501713374027509, 'w1': 0.05055780811260273, 'w2': 0.03568012016276241, 'w3': 0.46682836947274703, 'w4': 0.03315202822551946}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:10,576]\u001b[0m Trial 1030 finished with value: 0.7664873539566248 and parameters: {'w0': 0.8103801678512188, 'w1': 0.018811329066754943, 'w2': 0.01940551873745962, 'w3': 0.37514177749995137, 'w4': 0.06239858269487787}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:10,730]\u001b[0m Trial 1031 finished with value: 0.7664221069421653 and parameters: {'w0': 0.7891924585644117, 'w1': 0.033809949902152386, 'w2': 0.0006617001193045187, 'w3': 0.500764889919268, 'w4': 0.038108394340679905}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:10,887]\u001b[0m Trial 1032 finished with value: 0.7665180441391903 and parameters: {'w0': 0.8454301972609608, 'w1': 0.00012290042435859227, 'w2': 0.06459745350026794, 'w3': 0.0866088288698291, 'w4': 0.11136821024833325}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:11,041]\u001b[0m Trial 1033 finished with value: 0.7665504448853656 and parameters: {'w0': 0.8263745046433877, 'w1': 0.05126016621041969, 'w2': 0.03691691949330697, 'w3': 0.1016904071722925, 'w4': 0.01646268740563211}. Best is trial 988 with value: 0.7665963698558678.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:11,196]\u001b[0m Trial 1034 finished with value: 0.7666002003119106 and parameters: {'w0': 0.8535318456738976, 'w1': 0.0005804260245392991, 'w2': 0.0005338456556189634, 'w3': 0.03947761812798651, 'w4': 0.00029262889516829937}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:11,356]\u001b[0m Trial 1035 finished with value: 0.766258714078524 and parameters: {'w0': 0.8515197911354354, 'w1': 1.1908278820593169e-05, 'w2': 0.0003656721271724562, 'w3': 0.028848405585721784, 'w4': 0.4951098787930499}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:11,510]\u001b[0m Trial 1036 finished with value: 0.7665231456689481 and parameters: {'w0': 0.7514032449933118, 'w1': 0.021084046835233638, 'w2': 0.017871315492751363, 'w3': 0.02155351926833567, 'w4': 0.01856610110857058}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:11,664]\u001b[0m Trial 1037 finished with value: 0.7665491613163496 and parameters: {'w0': 0.8501721424968156, 'w1': 0.0002725954815595431, 'w2': 0.0892954727064287, 'w3': 0.041688825026778446, 'w4': 0.0010042484050067496}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:11,818]\u001b[0m Trial 1038 finished with value: 0.7665438262537265 and parameters: {'w0': 0.826213402727827, 'w1': 0.033363767756480985, 'w2': 0.045751990918574646, 'w3': 0.04071364761197751, 'w4': 0.00015642917821583058}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:11,981]\u001b[0m Trial 1039 finished with value: 0.7664460871481333 and parameters: {'w0': 0.8594823519468708, 'w1': 0.07339411932181956, 'w2': 0.02282833567759212, 'w3': 0.01692934298174236, 'w4': 0.016962701035086205}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:20:12,137]\u001b[0m Trial 1040 finished with value: 0.7665200295994204 and parameters: {'w0': 0.8085085972276933, 'w1': 0.020058461697382398, 'w2': 0.06428397503760368, 'w3': 0.034724906341450874, 'w4': 0.017790361374061342}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:12,290]\u001b[0m Trial 1041 finished with value: 0.766575727618737 and parameters: {'w0': 0.85771066859617, 'w1': 0.000282198366587022, 'w2': 2.7697715792773716e-05, 'w3': 0.05772425895043288, 'w4': 0.03324863741281611}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:12,446]\u001b[0m Trial 1042 finished with value: 0.7665318566171836 and parameters: {'w0': 0.8577268648298961, 'w1': 0.044073456684016, 'w2': 0.03401297452302636, 'w3': 0.04668188033503354, 'w4': 0.017809208571312664}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:12,600]\u001b[0m Trial 1043 finished with value: 0.7664632612929484 and parameters: {'w0': 0.7980695867673456, 'w1': 0.03195167308190494, 'w2': 0.01894043955149984, 'w3': 0.062157855154849534, 'w4': 0.15621952796547478}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:12,753]\u001b[0m Trial 1044 finished with value: 0.7665372351979238 and parameters: {'w0': 0.8320118630371726, 'w1': 0.05608548017627358, 'w2': 0.04989900486405527, 'w3': 0.16459916658720247, 'w4': 0.018835818459051253}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:12,908]\u001b[0m Trial 1045 finished with value: 0.7665643892103273 and parameters: {'w0': 0.7719810984661646, 'w1': 0.0191777431536842, 'w2': 0.020929590154914038, 'w3': 0.033086698682313606, 'w4': 0.0011464698535584086}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:13,066]\u001b[0m Trial 1046 finished with value: 0.7662691670440578 and parameters: {'w0': 0.8287211502848612, 'w1': 0.032412405627223195, 'w2': 0.00035219948391803507, 'w3': 0.0738554985528857, 'w4': 0.8016142981190719}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:13,220]\u001b[0m Trial 1047 finished with value: 0.7665405309412615 and parameters: {'w0': 0.8565812533267902, 'w1': 0.018632205907593683, 'w2': 0.03564215269145211, 'w3': 0.054526123665929696, 'w4': 0.039175788946399004}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:13,376]\u001b[0m Trial 1048 finished with value: 0.7663712545143735 and parameters: {'w0': 0.8558119449473891, 'w1': 0.06646289631811585, 'w2': 0.8171624946053918, 'w3': 0.08687488256797149, 'w4': 0.018819952537654876}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:13,538]\u001b[0m Trial 1049 finished with value: 0.7664013363050457 and parameters: {'w0': 0.8371289682227978, 'w1': 0.018589441081092662, 'w2': 0.6928817839367798, 'w3': 0.281076972560195, 'w4': 0.6581202630134901}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:13,693]\u001b[0m Trial 1050 finished with value: 0.7664325107882404 and parameters: {'w0': 0.8137333833539027, 'w1': 0.0007408515010334836, 'w2': 0.07533835872530234, 'w3': 0.013010820319776146, 'w4': 0.048389233219570116}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:13,849]\u001b[0m Trial 1051 finished with value: 0.766528137326232 and parameters: {'w0': 0.8566387763296055, 'w1': 0.00017680526136305036, 'w2': 0.019748064490863828, 'w3': 0.24704291696226693, 'w4': 0.016066894422052325}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:14,006]\u001b[0m Trial 1052 finished with value: 0.7665495004129645 and parameters: {'w0': 0.8664404280762334, 'w1': 0.03859230464780511, 'w2': 0.04943333194614604, 'w3': 0.11978492487891637, 'w4': 0.03335439425054654}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:14,162]\u001b[0m Trial 1053 finished with value: 0.7665529922032648 and parameters: {'w0': 0.8400383813126351, 'w1': 0.050323529472991124, 'w2': 0.029313916761092806, 'w3': 0.06878584270256347, 'w4': 0.0012526583627845964}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:14,316]\u001b[0m Trial 1054 finished with value: 0.7665642418519509 and parameters: {'w0': 0.819075271926589, 'w1': 0.0187674031978482, 'w2': 0.0167287041493249, 'w3': 0.10101913606457355, 'w4': 0.03252801620013228}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:14,471]\u001b[0m Trial 1055 finished with value: 0.7663654778074933 and parameters: {'w0': 0.7919249269550691, 'w1': 0.00022933308389130278, 'w2': 0.5599606267805332, 'w3': 0.050869462695930304, 'w4': 0.05333245141712389}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:14,628]\u001b[0m Trial 1056 finished with value: 0.7665528112368376 and parameters: {'w0': 0.86217925808977, 'w1': 0.03187416194392201, 'w2': 0.059322250194101325, 'w3': 0.14224874821186523, 'w4': 0.019129772754425744}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:14,781]\u001b[0m Trial 1057 finished with value: 0.7665465123125532 and parameters: {'w0': 0.8395268964625493, 'w1': 0.05270815444679425, 'w2': 0.034345015161503345, 'w3': 0.08311428722345247, 'w4': 0.016680148420001657}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:14,935]\u001b[0m Trial 1058 finished with value: 0.7665271299464538 and parameters: {'w0': 0.862646712973025, 'w1': 0.019341502789736457, 'w2': 0.01611712920630752, 'w3': 0.030227225443032357, 'w4': 0.035353437252125294}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:15,096]\u001b[0m Trial 1059 finished with value: 0.7665186452062521 and parameters: {'w0': 0.8664932742170731, 'w1': 0.07890611372774976, 'w2': 0.046508851124875614, 'w3': 0.11813739565368743, 'w4': 0.06873136320387632}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:15,250]\u001b[0m Trial 1060 finished with value: 0.7665653366988354 and parameters: {'w0': 0.8293628742177754, 'w1': 0.0333277894678339, 'w2': 0.017894339498507234, 'w3': 0.10262618992519515, 'w4': 0.01615773904846315}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:15,422]\u001b[0m Trial 1061 finished with value: 0.7665419071478531 and parameters: {'w0': 0.8129526773807256, 'w1': 0.018090329719897914, 'w2': 0.03482145091854246, 'w3': 0.06985074130897986, 'w4': 0.04806051616346631}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:15,582]\u001b[0m Trial 1062 finished with value: 0.7665067229656783 and parameters: {'w0': 0.8461740659733493, 'w1': 0.04516743445150125, 'w2': 0.0948186958643048, 'w3': 0.05080667595659187, 'w4': 0.018270126613150063}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:15,739]\u001b[0m Trial 1063 finished with value: 0.7665906642429414 and parameters: {'w0': 0.8664731677998871, 'w1': 0.017902636496722985, 'w2': 0.00011001993157378279, 'w3': 0.08736870520334702, 'w4': 0.00022482497862114204}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:15,895]\u001b[0m Trial 1064 finished with value: 0.7663991543669804 and parameters: {'w0': 0.8454825058917009, 'w1': 0.021303470043723557, 'w2': 0.0001813640677517396, 'w3': 0.07098965603370076, 'w4': 0.31847973136234276}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:16,050]\u001b[0m Trial 1065 finished with value: 0.766283273377059 and parameters: {'w0': 0.8694991557075477, 'w1': 0.5884912135796712, 'w2': 0.06159412713748151, 'w3': 0.032968435191805895, 'w4': 5.71908969928675e-05}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:16,207]\u001b[0m Trial 1066 finished with value: 0.7665931352964178 and parameters: {'w0': 0.8334422674945292, 'w1': 0.000779078003019524, 'w2': 0.017231472257646218, 'w3': 0.09004120954955072, 'w4': 0.0022073237696957223}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:16,362]\u001b[0m Trial 1067 finished with value: 0.7665674264301974 and parameters: {'w0': 0.7879427368489456, 'w1': 0.0013386070159467512, 'w2': 0.07096499054600253, 'w3': 0.057233222609394854, 'w4': 0.0005743615607784004}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:20:16,519]\u001b[0m Trial 1068 finished with value: 0.7665726322310868 and parameters: {'w0': 0.8097997025218314, 'w1': 0.017055710502520992, 'w2': 0.04791797779245717, 'w3': 0.08074729755163902, 'w4': 0.00041291847735516404}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:16,676]\u001b[0m Trial 1069 finished with value: 0.7664283360651134 and parameters: {'w0': 0.825086276826176, 'w1': 0.017909628594074686, 'w2': 0.03519249376143055, 'w3': 0.002466605588968551, 'w4': 0.015761679818749375}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:16,831]\u001b[0m Trial 1070 finished with value: 0.7665680106932338 and parameters: {'w0': 0.8037947968633153, 'w1': 0.0013717686489251747, 'w2': 0.07698627595152675, 'w3': 0.12933611907649875, 'w4': 0.00011377014130184275}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:16,987]\u001b[0m Trial 1071 finished with value: 0.7665630289460161 and parameters: {'w0': 0.7793518927686511, 'w1': 0.036622818523007694, 'w2': 0.048883274798010516, 'w3': 0.10473099533708208, 'w4': 0.00037841301170769837}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:17,140]\u001b[0m Trial 1072 finished with value: 0.7663451582938243 and parameters: {'w0': 0.8182217753718182, 'w1': 0.00022994456477016677, 'w2': 0.03151711015583526, 'w3': 0.06377208424254963, 'w4': 0.42397302148220917}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:17,303]\u001b[0m Trial 1073 finished with value: 0.7665597883543518 and parameters: {'w0': 0.83544614848596, 'w1': 0.00035724558125520495, 'w2': 0.01847619051182811, 'w3': 0.041630541713399, 'w4': 0.03390673167535252}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:17,459]\u001b[0m Trial 1074 finished with value: 0.7665627557728854 and parameters: {'w0': 0.8393373733616845, 'w1': 0.0337337259445436, 'w2': 0.05649738297988799, 'w3': 0.0934971071997663, 'w4': 0.00020435240713729253}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:17,614]\u001b[0m Trial 1075 finished with value: 0.7665839443562774 and parameters: {'w0': 0.8274450640517466, 'w1': 0.018112159235510603, 'w2': 0.016498284675031186, 'w3': 0.0784528626959445, 'w4': 0.0005864755031728136}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:17,778]\u001b[0m Trial 1076 finished with value: 0.7664182174565976 and parameters: {'w0': 0.7766975386842552, 'w1': 0.060051882668156975, 'w2': 0.07799605271929319, 'w3': 0.02007322747161281, 'w4': 0.0322108792078788}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:17,934]\u001b[0m Trial 1077 finished with value: 0.7662861119647317 and parameters: {'w0': 0.8061230396963927, 'w1': 0.6596020223441192, 'w2': 0.046510455561705265, 'w3': 0.0460941808793322, 'w4': 0.018486681723701052}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:18,089]\u001b[0m Trial 1078 finished with value: 0.7665621943460887 and parameters: {'w0': 0.7949915249850616, 'w1': 0.0004269189597115984, 'w2': 0.037410187407830725, 'w3': 0.06144762101069039, 'w4': 0.030224930326538762}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:18,244]\u001b[0m Trial 1079 finished with value: 0.766546375725988 and parameters: {'w0': 0.8218670516746398, 'w1': 0.03375143702917471, 'w2': 0.05953438429198438, 'w3': 0.07647818094934059, 'w4': 0.017484306524445926}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:18,404]\u001b[0m Trial 1080 finished with value: 0.7665603148804803 and parameters: {'w0': 0.8052258901327028, 'w1': 0.01791954637436038, 'w2': 0.029411895740128195, 'w3': 0.033445695694984505, 'w4': 0.0016185057904123709}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:18,557]\u001b[0m Trial 1081 finished with value: 0.766572233243202 and parameters: {'w0': 0.8307425774839243, 'w1': 0.0002616141313202709, 'w2': 0.020956214705515067, 'w3': 0.07795809780357048, 'w4': 0.03315045923968887}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:18,712]\u001b[0m Trial 1082 finished with value: 0.7664922934783429 and parameters: {'w0': 0.8283498375695574, 'w1': 0.04627147486984476, 'w2': 0.08624852832350831, 'w3': 0.05575579378665191, 'w4': 0.051411289238961766}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:18,870]\u001b[0m Trial 1083 finished with value: 0.7665828538181173 and parameters: {'w0': 0.7907020470631827, 'w1': 0.00033780547450609186, 'w2': 0.057435159965430874, 'w3': 0.08443261120855058, 'w4': 3.7035473455994394e-05}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:19,025]\u001b[0m Trial 1084 finished with value: 0.7664554590547008 and parameters: {'w0': 0.7696635977080809, 'w1': 0.1555295152555267, 'w2': 0.03419460200800836, 'w3': 0.050225050620260586, 'w4': 0.018163348722548236}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:19,179]\u001b[0m Trial 1085 finished with value: 0.7665754216993006 and parameters: {'w0': 0.843036332991842, 'w1': 0.021712697168040525, 'w2': 0.01886709136083721, 'w3': 0.06615763176415232, 'w4': 0.0003849755494294907}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:19,339]\u001b[0m Trial 1086 finished with value: 0.766483059450958 and parameters: {'w0': 0.8099147377134995, 'w1': 0.0338200892394204, 'w2': 0.045525647977558044, 'w3': 0.024976546966670142, 'w4': 0.030079269419536203}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:19,493]\u001b[0m Trial 1087 finished with value: 0.766587923463314 and parameters: {'w0': 0.8353803532921567, 'w1': 0.019122836950401834, 'w2': 9.102219655201735e-05, 'w3': 0.08810369439959372, 'w4': 0.0004063567210515193}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:19,647]\u001b[0m Trial 1088 finished with value: 0.7664936438325877 and parameters: {'w0': 0.7884750551358407, 'w1': 0.06519233268061739, 'w2': 0.017875487511914926, 'w3': 0.04520427378190707, 'w4': 0.04826930915218621}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:19,802]\u001b[0m Trial 1089 finished with value: 0.7663772647541192 and parameters: {'w0': 0.8177939548103663, 'w1': 0.01752487727843552, 'w2': 0.06158430538960849, 'w3': 0.6755297159268999, 'w4': 0.0007142745902373286}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:19,963]\u001b[0m Trial 1090 finished with value: 0.7665323659084146 and parameters: {'w0': 0.8188182488911488, 'w1': 0.04809559332537111, 'w2': 0.034428176266684506, 'w3': 0.07247207128173766, 'w4': 0.03536973747413349}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:20,118]\u001b[0m Trial 1091 finished with value: 0.7664808551075255 and parameters: {'w0': 0.8397525495247526, 'w1': 0.018335276788207375, 'w2': 0.10676176115930933, 'w3': 0.30677113151920365, 'w4': 0.3922819844453247}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:20,272]\u001b[0m Trial 1092 finished with value: 0.7665689366381196 and parameters: {'w0': 0.8035633989844257, 'w1': 0.0171938535735937, 'w2': 0.019536815660731604, 'w3': 0.08508929728745576, 'w4': 0.023007590179385622}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:20,433]\u001b[0m Trial 1093 finished with value: 0.7665789475285242 and parameters: {'w0': 0.8339606506970255, 'w1': 0.0006497950580554453, 'w2': 0.01727185335735363, 'w3': 0.06094990309374736, 'w4': 0.019685570432466135}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:20,588]\u001b[0m Trial 1094 finished with value: 0.7664756600784471 and parameters: {'w0': 0.7559205460382438, 'w1': 0.042238008626235536, 'w2': 0.044129181140793686, 'w3': 0.03424802741082844, 'w4': 0.0516171338308782}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:20,742]\u001b[0m Trial 1095 finished with value: 0.766554784632639 and parameters: {'w0': 0.8279090630001181, 'w1': 0.018454802042051265, 'w2': 0.06350624744222415, 'w3': 0.11553429220746238, 'w4': 0.032835039323753895}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:20:20,898]\u001b[0m Trial 1096 finished with value: 0.766449180812294 and parameters: {'w0': 0.850013780753245, 'w1': 0.00038476038587640477, 'w2': 0.032570299432666656, 'w3': 0.43667118234501845, 'w4': 0.016865609864978797}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:21,057]\u001b[0m Trial 1097 finished with value: 0.766522907827358 and parameters: {'w0': 0.8090225746013767, 'w1': 0.04806342652705506, 'w2': 0.020119078639354457, 'w3': 0.08170560765991136, 'w4': 0.0677774847177304}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:21,211]\u001b[0m Trial 1098 finished with value: 0.7665762886146615 and parameters: {'w0': 0.8496964720679405, 'w1': 0.03161415639952362, 'w2': 0.01636200619944627, 'w3': 0.09680122872696256, 'w4': 0.00035368959242996345}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:21,365]\u001b[0m Trial 1099 finished with value: 0.7665107908324387 and parameters: {'w0': 0.8257405871490704, 'w1': 0.06284668496779214, 'w2': 0.04386594221706775, 'w3': 0.06394800177951898, 'w4': 0.04365931145339655}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:21,526]\u001b[0m Trial 1100 finished with value: 0.766548023813093 and parameters: {'w0': 0.8522261167054332, 'w1': 0.017749537159122728, 'w2': 0.07618285385400472, 'w3': 0.04744634930099707, 'w4': 0.0002492515041894081}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:21,682]\u001b[0m Trial 1101 finished with value: 0.7665632133594228 and parameters: {'w0': 0.8000875849592027, 'w1': 0.03069511854037985, 'w2': 0.0004353423376925597, 'w3': 0.10639828011613287, 'w4': 0.0186928074659245}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:21,839]\u001b[0m Trial 1102 finished with value: 0.7664725461632818 and parameters: {'w0': 0.8313372643849833, 'w1': 0.08238165174698373, 'w2': 0.016998033081949887, 'w3': 0.020981485074166775, 'w4': 0.00021923967350646997}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:21,998]\u001b[0m Trial 1103 finished with value: 0.7665504043833556 and parameters: {'w0': 0.8526379247806752, 'w1': 0.017453081697899466, 'w2': 0.045476350439052585, 'w3': 0.07349802261376671, 'w4': 0.03468762561940211}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:22,159]\u001b[0m Trial 1104 finished with value: 0.7665583096001178 and parameters: {'w0': 0.7808857455985998, 'w1': 0.046619763690848505, 'w2': 0.00016397921829923144, 'w3': 0.09433995759093095, 'w4': 0.01909580949335471}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:22,313]\u001b[0m Trial 1105 finished with value: 0.766552292466413 and parameters: {'w0': 0.854947519857616, 'w1': 0.01658843743961884, 'w2': 0.0003710568450308075, 'w3': 0.12316465893908723, 'w4': 0.05755624240229327}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:22,468]\u001b[0m Trial 1106 finished with value: 0.7663980323751316 and parameters: {'w0': 0.8234176371032308, 'w1': 0.03753182254505068, 'w2': 0.031894842353612625, 'w3': 0.6525401971470455, 'w4': 0.033146637281264234}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:22,625]\u001b[0m Trial 1107 finished with value: 0.7662290614368077 and parameters: {'w0': 0.5655111476293944, 'w1': 0.0006426648467028731, 'w2': 0.06149498598289745, 'w3': 0.06083861537308238, 'w4': 0.9064920958242597}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:22,779]\u001b[0m Trial 1108 finished with value: 0.7665787079634444 and parameters: {'w0': 0.8373520237746181, 'w1': 0.00032124712621110335, 'w2': 0.030736109407238858, 'w3': 0.08140857028853017, 'w4': 0.020560639513965976}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:22,934]\u001b[0m Trial 1109 finished with value: 0.7662398039486251 and parameters: {'w0': 0.8570487040519672, 'w1': 0.8417327782196105, 'w2': 0.0185678921321865, 'w3': 0.046865763370441564, 'w4': 0.20235879742669052}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:23,094]\u001b[0m Trial 1110 finished with value: 0.7665469449084887 and parameters: {'w0': 0.8078763891879802, 'w1': 0.00041706562590089133, 'w2': 0.09878119321868245, 'w3': 0.11139858257459015, 'w4': 0.04646877798745516}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:23,250]\u001b[0m Trial 1111 finished with value: 0.7663086319439811 and parameters: {'w0': 0.8392507415092829, 'w1': 0.06312762310599836, 'w2': 0.48059723414932515, 'w3': 0.01449830150299218, 'w4': 0.016029932956807016}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:23,405]\u001b[0m Trial 1112 finished with value: 0.7664360460966576 and parameters: {'w0': 0.35216952447057037, 'w1': 0.2570140624697983, 'w2': 0.04631175417282328, 'w3': 0.08790191553621568, 'w4': 0.00022918723031154176}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:23,564]\u001b[0m Trial 1113 finished with value: 0.766539276671572 and parameters: {'w0': 0.8646061451770658, 'w1': 0.03504472454094222, 'w2': 0.01755679388569553, 'w3': 0.1350271209882142, 'w4': 0.08003891625595243}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:23,722]\u001b[0m Trial 1114 finished with value: 0.7665667646101206 and parameters: {'w0': 0.8180184344986827, 'w1': 0.018224236926807358, 'w2': 6.713804592724248e-07, 'w3': 0.07546774185780768, 'w4': 0.03181530487839174}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:23,878]\u001b[0m Trial 1115 finished with value: 0.7662989144777123 and parameters: {'w0': 0.7906480406425469, 'w1': 0.5181542416241031, 'w2': 0.038613043144970216, 'w3': 0.03847361484450691, 'w4': 0.01742929907727046}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:24,035]\u001b[0m Trial 1116 finished with value: 0.7664593537107378 and parameters: {'w0': 0.8621558111013019, 'w1': 5.768214546088625e-05, 'w2': 0.4373337994058189, 'w3': 0.1051447661390262, 'w4': 0.0589406021524196}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:24,194]\u001b[0m Trial 1117 finished with value: 0.7664334522445342 and parameters: {'w0': 0.8396898810960264, 'w1': 0.04777380305982748, 'w2': 0.328845462938808, 'w3': 0.05598604814262539, 'w4': 0.0008734011854828001}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:24,353]\u001b[0m Trial 1118 finished with value: 0.7665627876574463 and parameters: {'w0': 0.8570670325260908, 'w1': 0.03309477123870652, 'w2': 0.0001477858549384925, 'w3': 0.09008310739034704, 'w4': 0.02897351210078223}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:24,509]\u001b[0m Trial 1119 finished with value: 0.7664488563653421 and parameters: {'w0': 0.67814667857138, 'w1': 0.021292352970004067, 'w2': 0.0738458942220108, 'w3': 0.4108036490738471, 'w4': 0.00048057814817405045}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:24,666]\u001b[0m Trial 1120 finished with value: 0.7665389091373758 and parameters: {'w0': 0.7343408746530106, 'w1': 0.018204650511582952, 'w2': 0.03290346104258088, 'w3': 0.06685055828349255, 'w4': 0.04767969853287798}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:24,820]\u001b[0m Trial 1121 finished with value: 0.76656323576479 and parameters: {'w0': 0.8200149022183959, 'w1': 0.0007108681135947464, 'w2': 0.050637592924110415, 'w3': 0.12256113490748134, 'w4': 0.028780101200306763}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:24,976]\u001b[0m Trial 1122 finished with value: 0.7665492569700327 and parameters: {'w0': 0.8457962813306825, 'w1': 0.058154276905878155, 'w2': 0.023978838921724893, 'w3': 0.10196158426345243, 'w4': 0.01929795314887021}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:25,133]\u001b[0m Trial 1123 finished with value: 0.7664415655726877 and parameters: {'w0': 0.8654347204912348, 'w1': 0.11764746689437194, 'w2': 0.018914363021462117, 'w3': 0.034149768941007796, 'w4': 0.04271017183620502}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:20:25,292]\u001b[0m Trial 1124 finished with value: 0.766524984201674 and parameters: {'w0': 0.8050394464503696, 'w1': 0.08935741154540124, 'w2': 0.0002063249374205621, 'w3': 0.15553621740131435, 'w4': 0.06442044997059483}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:25,448]\u001b[0m Trial 1125 finished with value: 0.7665577361088924 and parameters: {'w0': 0.8326932182974462, 'w1': 0.029492510869159452, 'w2': 0.06044228871949727, 'w3': 0.07235043430638778, 'w4': 0.0006482146357663544}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:25,603]\u001b[0m Trial 1126 finished with value: 0.7665157536212689 and parameters: {'w0': 0.8686109004712131, 'w1': 0.0004543832505978268, 'w2': 0.2427865296980995, 'w3': 0.09114912063187716, 'w4': 0.017961576254998765}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:25,764]\u001b[0m Trial 1127 finished with value: 0.7665836733375091 and parameters: {'w0': 0.8397026978222866, 'w1': 0.00013620172154918397, 'w2': 0.03178792105562955, 'w3': 0.05368000355861244, 'w4': 2.8539870918889773e-05}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:25,918]\u001b[0m Trial 1128 finished with value: 0.7664720179136633 and parameters: {'w0': 0.7593205742809558, 'w1': 0.03750213457293022, 'w2': 0.00011452208923529644, 'w3': 0.016083857223863074, 'w4': 0.03634568909531518}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:26,071]\u001b[0m Trial 1129 finished with value: 0.7664284511080566 and parameters: {'w0': 0.7979619784432526, 'w1': 0.02765834532087182, 'w2': 0.03238855303554537, 'w3': 0.004629798260689211, 'w4': 0.01671039064147627}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:26,230]\u001b[0m Trial 1130 finished with value: 0.7662527072857578 and parameters: {'w0': 0.7819546885198211, 'w1': 0.7066594902439919, 'w2': 0.021466242409427277, 'w3': 0.030993078787594316, 'w4': 0.03694615472225383}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:26,388]\u001b[0m Trial 1131 finished with value: 0.7665722353975644 and parameters: {'w0': 0.8159087446363924, 'w1': 0.01830642301366033, 'w2': 0.019662413783705705, 'w3': 0.04321777925313379, 'w4': 0.0006306516949376511}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:26,547]\u001b[0m Trial 1132 finished with value: 0.7664614012166001 and parameters: {'w0': 0.8297305093167352, 'w1': 0.056397423000999335, 'w2': 0.03663572623309177, 'w3': 0.042394118638082005, 'w4': 0.08485033737722336}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:26,703]\u001b[0m Trial 1133 finished with value: 0.7664037974484557 and parameters: {'w0': 0.8128809119167016, 'w1': 0.017764691929270496, 'w2': 0.017609572763864746, 'w3': 0.5354660883430821, 'w4': 0.018271772235453246}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:26,862]\u001b[0m Trial 1134 finished with value: 0.7662742353966371 and parameters: {'w0': 0.8400459453925708, 'w1': 0.7845715218428192, 'w2': 0.041592336251073586, 'w3': 0.05339443175465734, 'w4': 0.05405081296187818}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:27,019]\u001b[0m Trial 1135 finished with value: 0.7663493295699715 and parameters: {'w0': 0.5933748907716657, 'w1': 0.2062917184425078, 'w2': 0.01762226728495539, 'w3': 0.024520313815572004, 'w4': 0.031997410696171916}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:27,173]\u001b[0m Trial 1136 finished with value: 0.7662681949958201 and parameters: {'w0': 0.8271871253492279, 'w1': 0.041649486012346075, 'w2': 0.07125701967940248, 'w3': 0.05689181260891094, 'w4': 0.6337177162017321}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:27,334]\u001b[0m Trial 1137 finished with value: 0.7664749340583761 and parameters: {'w0': 0.7858573974765216, 'w1': 0.0004203792323212289, 'w2': 0.016711205991271735, 'w3': 0.004460632891235168, 'w4': 0.017868895962444665}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:27,489]\u001b[0m Trial 1138 finished with value: 0.7665331449257964 and parameters: {'w0': 0.48542515395538355, 'w1': 0.0004070763035905706, 'w2': 0.04758321403940089, 'w3': 0.06400322290984314, 'w4': 0.0511484599236543}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:27,646]\u001b[0m Trial 1139 finished with value: 0.7665484982036558 and parameters: {'w0': 0.8468568364849446, 'w1': 0.03314163855673353, 'w2': 0.03327286643522141, 'w3': 0.03771181963770844, 'w4': 0.00033135206897563145}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:27,806]\u001b[0m Trial 1140 finished with value: 0.7665744302618029 and parameters: {'w0': 0.8466179550709907, 'w1': 0.018944068484802033, 'w2': 0.0005691981420449799, 'w3': 0.06816657383448435, 'w4': 0.017829671843096258}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:27,961]\u001b[0m Trial 1141 finished with value: 0.7665166601768947 and parameters: {'w0': 0.8063678348461751, 'w1': 0.07167631341644021, 'w2': 0.016665194928082504, 'w3': 0.0612118890219098, 'w4': 0.036496580136063356}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:28,261]\u001b[0m Trial 1142 finished with value: 0.7664239347030801 and parameters: {'w0': 0.8257299133951258, 'w1': 0.04603916419509251, 'w2': 0.39458357541324374, 'w3': 0.0796066488870469, 'w4': 0.0643862625395133}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:28,423]\u001b[0m Trial 1143 finished with value: 0.7665190562585654 and parameters: {'w0': 0.8546975443727759, 'w1': 0.018117033525145338, 'w2': 0.05703606208333578, 'w3': 0.031240009528738427, 'w4': 0.020107123490707715}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:28,582]\u001b[0m Trial 1144 finished with value: 0.7665640789821664 and parameters: {'w0': 0.796294946261025, 'w1': 0.0003071476563717192, 'w2': 0.03497033092041466, 'w3': 0.11336983822659638, 'w4': 0.03400830839964661}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:28,744]\u001b[0m Trial 1145 finished with value: 0.7665007084172082 and parameters: {'w0': 0.17923981718384224, 'w1': 0.048887927768009196, 'w2': 0.00042030223197083924, 'w3': 0.051099742256848726, 'w4': 0.017795996128293537}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:28,905]\u001b[0m Trial 1146 finished with value: 0.7665702512299517 and parameters: {'w0': 0.8281073946865047, 'w1': 0.029781860214698246, 'w2': 0.0329168668107002, 'w3': 0.0841627209528247, 'w4': 0.0006105641715398794}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:29,060]\u001b[0m Trial 1147 finished with value: 0.7663093700284807 and parameters: {'w0': 0.860688120672151, 'w1': 0.9110519902595726, 'w2': 0.021889217581215488, 'w3': 0.09903091902932797, 'w4': 0.07155616342478334}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:29,217]\u001b[0m Trial 1148 finished with value: 0.7665476338735295 and parameters: {'w0': 0.8405571056532859, 'w1': 0.018368958822509225, 'w2': 0.07779574445414311, 'w3': 0.13326869661743668, 'w4': 0.046750381324913395}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:29,375]\u001b[0m Trial 1149 finished with value: 0.7663600027113253 and parameters: {'w0': 0.8076222125580853, 'w1': 0.06507149516308783, 'w2': 0.7137931769121499, 'w3': 0.06963040275890751, 'w4': 0.032132457200964186}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:29,533]\u001b[0m Trial 1150 finished with value: 0.7665731893491593 and parameters: {'w0': 0.8701917747865698, 'w1': 0.021216134510274466, 'w2': 0.017144953076357026, 'w3': 0.05099453209896379, 'w4': 0.0004420344179220226}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:29,689]\u001b[0m Trial 1151 finished with value: 0.7664728154585603 and parameters: {'w0': 0.8223903724283217, 'w1': 0.0453740822707234, 'w2': 0.05193076158354067, 'w3': 0.0229073273168357, 'w4': 0.018481470960512354}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:20:29,844]\u001b[0m Trial 1152 finished with value: 0.7665577903988207 and parameters: {'w0': 0.8518345334740489, 'w1': 0.016465333542408943, 'w2': 0.01665653803705709, 'w3': 0.09485024326054951, 'w4': 0.04642226195382913}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:30,007]\u001b[0m Trial 1153 finished with value: 0.7665761808965501 and parameters: {'w0': 0.8659556386102818, 'w1': 0.0007046160361064355, 'w2': 0.0397285882011348, 'w3': 0.11831244929377749, 'w4': 0.00042082879270218757}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:30,166]\u001b[0m Trial 1154 finished with value: 0.7665783244869675 and parameters: {'w0': 0.8346577437521384, 'w1': 0.03423966432908002, 'w2': 0.0007621841846633917, 'w3': 0.07698156995015122, 'w4': 1.5452337111323557e-05}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:30,322]\u001b[0m Trial 1155 finished with value: 0.7663941678801658 and parameters: {'w0': 0.8705762160648186, 'w1': 0.020861807182693353, 'w2': 0.052753954045753434, 'w3': 0.0014124566040510378, 'w4': 0.03136550882830867}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:30,481]\u001b[0m Trial 1156 finished with value: 0.7665154140937815 and parameters: {'w0': 0.5170072764690329, 'w1': 0.044919005337175376, 'w2': 0.03430903343348929, 'w3': 0.051754852936926304, 'w4': 0.026644218722416683}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:30,637]\u001b[0m Trial 1157 finished with value: 0.7665825345416349 and parameters: {'w0': 0.76881970117937, 'w1': 2.2181814800438515e-05, 'w2': 1.936864813165129e-05, 'w3': 0.10347745523546859, 'w4': 0.00036236128566641615}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:30,803]\u001b[0m Trial 1158 finished with value: 0.7665261669465376 and parameters: {'w0': 0.8168445827516764, 'w1': 0.000505238426311478, 'w2': 0.08604921542459895, 'w3': 0.06891397084627371, 'w4': 0.06169434171610584}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:30,961]\u001b[0m Trial 1159 finished with value: 0.76631253220136 and parameters: {'w0': 0.8445295440186807, 'w1': 0.07050697817259113, 'w2': 0.7757928374659276, 'w3': 0.03693410429825439, 'w4': 0.022056567354919274}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:31,124]\u001b[0m Trial 1160 finished with value: 0.7665890071075151 and parameters: {'w0': 0.8720269185915446, 'w1': 4.853742135825577e-05, 'w2': 0.016644910879143736, 'w3': 0.08680867311135532, 'w4': 0.01808379895426694}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:31,280]\u001b[0m Trial 1161 finished with value: 0.7665399225493681 and parameters: {'w0': 0.8733446760244832, 'w1': 0.03133925457621604, 'w2': 6.733860895380482e-05, 'w3': 0.14383223270859585, 'w4': 0.07417857900324239}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:31,436]\u001b[0m Trial 1162 finished with value: 0.7665227798582416 and parameters: {'w0': 0.45972272560967814, 'w1': 0.02240058123751388, 'w2': 0.017549774114435826, 'w3': 0.11298766771357446, 'w4': 0.048407150615962506}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:31,599]\u001b[0m Trial 1163 finished with value: 0.7665279921222177 and parameters: {'w0': 0.878519057644305, 'w1': 0.055575618786189385, 'w2': 0.01657531586265411, 'w3': 0.13419144585576173, 'w4': 0.09459014134161708}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:31,756]\u001b[0m Trial 1164 finished with value: 0.7665566524646914 and parameters: {'w0': 0.8749319693533776, 'w1': 0.019034948615970375, 'w2': 0.01699144699415213, 'w3': 0.09494788222014858, 'w4': 0.047273540816455545}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:31,913]\u001b[0m Trial 1165 finished with value: 0.7664470936661667 and parameters: {'w0': 0.8615886335830993, 'w1': 0.034543938762001375, 'w2': 0.03241408485937153, 'w3': 0.11786376652343292, 'w4': 0.29247128358134833}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:32,073]\u001b[0m Trial 1166 finished with value: 0.7665612179891266 and parameters: {'w0': 0.8808628944885364, 'w1': 0.019852181973793327, 'w2': 0.016669994276243032, 'w3': 0.0921173881868045, 'w4': 0.0384651665375374}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:32,229]\u001b[0m Trial 1167 finished with value: 0.766456768045191 and parameters: {'w0': 0.8583529636715965, 'w1': 0.00045609904071437703, 'w2': 0.05069128555387477, 'w3': 0.7803282359557752, 'w4': 0.374193871276142}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:32,388]\u001b[0m Trial 1168 finished with value: 0.7665255469210882 and parameters: {'w0': 0.8811227071694033, 'w1': 0.08726754224941141, 'w2': 0.0006548229305579772, 'w3': 0.11412337128170902, 'w4': 0.06131486545819555}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:32,545]\u001b[0m Trial 1169 finished with value: 0.7665388087440957 and parameters: {'w0': 0.8521361504564562, 'w1': 0.042929870014327014, 'w2': 0.03554203499176356, 'w3': 0.1598377452884467, 'w4': 0.031322947675994334}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:32,703]\u001b[0m Trial 1170 finished with value: 0.7665600098227887 and parameters: {'w0': 0.8677944502905248, 'w1': 0.035023117092296684, 'w2': 0.017656864453802334, 'w3': 0.08387094170517263, 'w4': 0.02050889144153857}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:32,862]\u001b[0m Trial 1171 finished with value: 0.7665491832908444 and parameters: {'w0': 0.846046422748827, 'w1': 0.018241935616790866, 'w2': 0.0001232225721481975, 'w3': 0.13336047715740715, 'w4': 0.04842780595640664}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:33,023]\u001b[0m Trial 1172 finished with value: 0.7665532701159923 and parameters: {'w0': 0.8804082913488711, 'w1': 0.061598628533954924, 'w2': 0.0001657989823316877, 'w3': 0.10441078892937902, 'w4': 0.020188669254705964}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:33,184]\u001b[0m Trial 1173 finished with value: 0.7665688349522225 and parameters: {'w0': 0.7971118250623924, 'w1': 0.015345475835364008, 'w2': 0.060047051767303745, 'w3': 0.08081844371267245, 'w4': 4.785671228697911e-05}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:33,342]\u001b[0m Trial 1174 finished with value: 0.7665409273439115 and parameters: {'w0': 0.824224663156885, 'w1': 0.01837488957139895, 'w2': 0.0346094899619776, 'w3': 0.1072346462883035, 'w4': 0.07202511454711306}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:33,499]\u001b[0m Trial 1175 finished with value: 0.7665834139522969 and parameters: {'w0': 0.8510746970997557, 'w1': 0.0004735465170735796, 'w2': 3.6619459626568572e-06, 'w3': 0.07978633239319284, 'w4': 0.03335885184014298}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:33,656]\u001b[0m Trial 1176 finished with value: 0.7665540258662622 and parameters: {'w0': 0.8832135633946778, 'w1': 0.049227830791490665, 'w2': 0.03253663997523889, 'w3': 0.12608403186314543, 'w4': 0.01892671890608167}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:33,818]\u001b[0m Trial 1177 finished with value: 0.7665345629270154 and parameters: {'w0': 0.8617610286228439, 'w1': 0.0331483580925501, 'w2': 0.06560365468116032, 'w3': 0.09241646182054039, 'w4': 0.04774790017685207}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:33,976]\u001b[0m Trial 1178 finished with value: 0.7665690917522001 and parameters: {'w0': 0.8274735755406767, 'w1': 0.016879489498158103, 'w2': 0.017803823977265126, 'w3': 0.07464965938053317, 'w4': 0.019878524260862354}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:34,133]\u001b[0m Trial 1179 finished with value: 0.7664124713416611 and parameters: {'w0': 0.8822650541593281, 'w1': 0.4500051770124062, 'w2': 0.04750165134033811, 'w3': 0.10094584436427724, 'w4': 1.4647259964388785e-05}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:20:34,296]\u001b[0m Trial 1180 finished with value: 0.7664007417010705 and parameters: {'w0': 0.8435055058421861, 'w1': 0.32666745660044816, 'w2': 0.030500028938762067, 'w3': 0.0675762213619223, 'w4': 0.03624287626632708}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:34,454]\u001b[0m Trial 1181 finished with value: 0.7665412397264346 and parameters: {'w0': 0.8107539073509215, 'w1': 0.038723111032003696, 'w2': 0.01837216948364893, 'w3': 0.1455370359330109, 'w4': 0.01763091718169366}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:34,612]\u001b[0m Trial 1182 finished with value: 0.7664237675245712 and parameters: {'w0': 0.8700176360227534, 'w1': 0.41242758597163304, 'w2': 0.04706400359575623, 'w3': 0.12143361615941595, 'w4': 0.05744287889789569}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:34,772]\u001b[0m Trial 1183 finished with value: 0.7665889338591994 and parameters: {'w0': 0.8322616095630013, 'w1': 0.01695808573927225, 'w2': 0.0003826176178444589, 'w3': 0.08839662919769359, 'w4': 6.406341223909705e-05}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:34,931]\u001b[0m Trial 1184 finished with value: 0.7664142000019134 and parameters: {'w0': 0.8167697015128789, 'w1': 0.058411051732696576, 'w2': 0.00010434656900816991, 'w3': 0.06501665604185114, 'w4': 0.2333679664872381}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:35,093]\u001b[0m Trial 1185 finished with value: 0.7665776333675647 and parameters: {'w0': 0.7892882306662159, 'w1': 3.67789663963626e-05, 'w2': 0.030972503567293405, 'w3': 0.07698742550210354, 'w4': 0.01977406043938834}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:35,255]\u001b[0m Trial 1186 finished with value: 0.7665476916104372 and parameters: {'w0': 0.7704383931940583, 'w1': 0.02981179963696977, 'w2': 0.06657533829562859, 'w3': 0.055434998189150785, 'w4': 0.00018818724805952716}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:35,414]\u001b[0m Trial 1187 finished with value: 0.7663533164327121 and parameters: {'w0': 0.11244036793218215, 'w1': 0.01801138484488605, 'w2': 0.8504288513201297, 'w3': 0.08692836996196916, 'w4': 0.018018141520373877}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:35,570]\u001b[0m Trial 1188 finished with value: 0.7665336636962211 and parameters: {'w0': 0.8309376556762247, 'w1': 0.0750329596149775, 'w2': 0.017787495989118395, 'w3': 0.10052329289097311, 'w4': 0.033888776058417405}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:35,729]\u001b[0m Trial 1189 finished with value: 0.7665398747225265 and parameters: {'w0': 0.8083456131990304, 'w1': 0.04763899666946821, 'w2': 0.04232061824107567, 'w3': 0.06684912439633178, 'w4': 0.016058071211872454}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:35,889]\u001b[0m Trial 1190 finished with value: 0.7665747745288871 and parameters: {'w0': 0.8309435268509046, 'w1': 0.0008037746099727089, 'w2': 0.018463279952529776, 'w3': 0.0423851057619555, 'w4': 0.017446047164627273}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:36,060]\u001b[0m Trial 1191 finished with value: 0.7662655227249117 and parameters: {'w0': 0.7832502002799056, 'w1': 0.4775351963713568, 'w2': 0.04764925072796235, 'w3': 0.08619283801249078, 'w4': 0.5596206680630726}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:36,219]\u001b[0m Trial 1192 finished with value: 0.7665670476933175 and parameters: {'w0': 0.8485869427347538, 'w1': 0.035020235177632086, 'w2': 0.015531484002586396, 'w3': 0.11404257449135521, 'w4': 7.1831380324930034e-06}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:36,385]\u001b[0m Trial 1193 finished with value: 0.7665431450443898 and parameters: {'w0': 0.8073001709933795, 'w1': 0.021258708089410414, 'w2': 0.03381597482383125, 'w3': 0.06365174276459996, 'w4': 0.039296251990563975}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:36,541]\u001b[0m Trial 1194 finished with value: 0.7664028534069272 and parameters: {'w0': 0.8439310680418203, 'w1': 0.37657996720529724, 'w2': 0.07339316632011125, 'w3': 0.08263251279077553, 'w4': 0.01914288260818023}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:36,699]\u001b[0m Trial 1195 finished with value: 0.7665683200596498 and parameters: {'w0': 0.8263885674049614, 'w1': 0.0003041980460328423, 'w2': 0.023718829351370325, 'w3': 0.10554287792062318, 'w4': 0.03985462482069992}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:36,857]\u001b[0m Trial 1196 finished with value: 0.7665565964512735 and parameters: {'w0': 0.7932520524229699, 'w1': 0.019025434180672037, 'w2': 0.054811413293800494, 'w3': 0.04687654594772497, 'w4': 0.0007338591126564268}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:37,016]\u001b[0m Trial 1197 finished with value: 0.7665377587079455 and parameters: {'w0': 0.8557388679245326, 'w1': 0.1048867067776214, 'w2': 0.00020807796343566152, 'w3': 0.08878748039587261, 'w4': 1.676351765116796e-05}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:37,176]\u001b[0m Trial 1198 finished with value: 0.7665229565159443 and parameters: {'w0': 0.39064377556192603, 'w1': 0.04883115840436754, 'w2': 0.00024035094649549555, 'w3': 0.06593156914746877, 'w4': 0.028531250992166742}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:37,338]\u001b[0m Trial 1199 finished with value: 0.7665494853324288 and parameters: {'w0': 0.8365999160965334, 'w1': 0.0004187557230623222, 'w2': 0.019870428688707063, 'w3': 0.12618331489376036, 'w4': 0.0810060965647996}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:37,499]\u001b[0m Trial 1200 finished with value: 0.7664784064594163 and parameters: {'w0': 0.7605996146733488, 'w1': 0.03391311047129243, 'w2': 0.036613310698039664, 'w3': 0.030837139675286694, 'w4': 0.0527533451884441}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:37,655]\u001b[0m Trial 1201 finished with value: 0.7664440685107251 and parameters: {'w0': 0.8101578049291979, 'w1': 2.1551920046504068e-05, 'w2': 0.6052653789772579, 'w3': 0.10466411670451267, 'w4': 0.0001555020375941207}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:37,813]\u001b[0m Trial 1202 finished with value: 0.7665786678923069 and parameters: {'w0': 0.8611359247206389, 'w1': 0.019609028494213317, 'w2': 0.018343797381806057, 'w3': 0.07196621870262666, 'w4': 5.329832468016493e-05}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:37,972]\u001b[0m Trial 1203 finished with value: 0.7664722936720285 and parameters: {'w0': 0.8339240953974427, 'w1': 0.0691345446212152, 'w2': 0.09422312309179388, 'w3': 0.04534408349427171, 'w4': 0.03189287278165698}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:38,132]\u001b[0m Trial 1204 finished with value: 0.7665694407588812 and parameters: {'w0': 0.7080161449984878, 'w1': 0.0003295759089310399, 'w2': 0.05859032140583098, 'w3': 0.09197911894312928, 'w4': 0.01859182223673284}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:38,290]\u001b[0m Trial 1205 finished with value: 0.766547555023872 and parameters: {'w0': 0.8558888380828812, 'w1': 0.03226855277422136, 'w2': 0.034328663762918085, 'w3': 0.13189703981533263, 'w4': 0.04592175393200907}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:38,451]\u001b[0m Trial 1206 finished with value: 0.7665378552233734 and parameters: {'w0': 0.8275063410196277, 'w1': 0.05013270607840335, 'w2': 0.01862216448215464, 'w3': 0.05559701967994893, 'w4': 0.020655240519386237}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:38,609]\u001b[0m Trial 1207 finished with value: 0.7665385588380773 and parameters: {'w0': 0.8670465592437413, 'w1': 8.496330802538874e-05, 'w2': 0.050005123062910495, 'w3': 0.1789387065720909, 'w4': 0.0611383162191585}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:20:38,766]\u001b[0m Trial 1208 finished with value: 0.7665569928539236 and parameters: {'w0': 0.8020669457283156, 'w1': 0.020009721063749857, 'w2': 0.01834880542205015, 'w3': 0.0820890908198086, 'w4': 0.03683839496285056}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:38,927]\u001b[0m Trial 1209 finished with value: 0.7665535816367708 and parameters: {'w0': 0.84634710455134, 'w1': 0.03237674007484137, 'w2': 0.06779134542732916, 'w3': 0.1134381968990554, 'w4': 0.019549216387915794}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:39,086]\u001b[0m Trial 1210 finished with value: 0.7663848804245976 and parameters: {'w0': 0.8221118380636595, 'w1': 0.018490064850971204, 'w2': 0.26774014455626866, 'w3': 0.02223280422411615, 'w4': 0.018071742001548298}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:39,244]\u001b[0m Trial 1211 finished with value: 0.7665337666747356 and parameters: {'w0': 0.8596463254150848, 'w1': 0.04823222848322917, 'w2': 0.03637125656784696, 'w3': 0.06959087681128043, 'w4': 0.0325470804065772}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:39,414]\u001b[0m Trial 1212 finished with value: 0.7665824880074109 and parameters: {'w0': 0.8816059382633559, 'w1': 0.020348837984637956, 'w2': 0.02014658647933293, 'w3': 0.09903925437618692, 'w4': 0.0005338060589415087}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:39,726]\u001b[0m Trial 1213 finished with value: 0.7664804694766866 and parameters: {'w0': 0.8407946443688981, 'w1': 0.07960136335123745, 'w2': 0.03972108874447483, 'w3': 0.05531847974850062, 'w4': 0.06405948099419367}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:39,884]\u001b[0m Trial 1214 finished with value: 0.7664262588290525 and parameters: {'w0': 0.78942524831142, 'w1': 5.906506323136233e-05, 'w2': 0.01670720158759034, 'w3': 0.8940434949894148, 'w4': 0.00016112647794738755}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:40,046]\u001b[0m Trial 1215 finished with value: 0.766542476330354 and parameters: {'w0': 0.8822748402677058, 'w1': 0.040022442664721485, 'w2': 0.0004935177590297407, 'w3': 0.1458085354860642, 'w4': 0.043876250133241326}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:40,204]\u001b[0m Trial 1216 finished with value: 0.7665323758184808 and parameters: {'w0': 0.8650743103523673, 'w1': 0.060889937334337174, 'w2': 0.05691749362463984, 'w3': 0.0792345160972486, 'w4': 0.018964686966475273}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:40,362]\u001b[0m Trial 1217 finished with value: 0.7665585969920392 and parameters: {'w0': 0.8160230713123567, 'w1': 0.031193576050219104, 'w2': 0.034760011836512575, 'w3': 0.11732487642694417, 'w4': 0.01742611210562086}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:40,528]\u001b[0m Trial 1218 finished with value: 0.7662504404658208 and parameters: {'w0': 0.8343481035923626, 'w1': 0.28624959527532484, 'w2': 0.017187648592343154, 'w3': 0.09502626989564325, 'w4': 0.9341680350829209}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:40,685]\u001b[0m Trial 1219 finished with value: 0.766488753861201 and parameters: {'w0': 0.8567714742532139, 'w1': 0.01864508025651337, 'w2': 0.0895730003816752, 'w3': 0.03513341480853299, 'w4': 0.037759517508051656}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:40,845]\u001b[0m Trial 1220 finished with value: 0.7662512418885699 and parameters: {'w0': 0.8863206188165578, 'w1': 0.01773667650880661, 'w2': 0.00017978591494074644, 'w3': 0.06512752272130203, 'w4': 0.8742266360958082}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:41,004]\u001b[0m Trial 1221 finished with value: 0.7665484930331864 and parameters: {'w0': 0.8441117848198729, 'w1': 0.00037775435639325334, 'w2': 0.00020148805248741548, 'w3': 0.08550109947229251, 'w4': 0.08313654364763595}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:41,163]\u001b[0m Trial 1222 finished with value: 0.766485309897742 and parameters: {'w0': 0.8711096802327887, 'w1': 8.351067034111208e-05, 'w2': 0.20218392592416062, 'w3': 0.5663315022712411, 'w4': 0.4655983552673805}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:41,323]\u001b[0m Trial 1223 finished with value: 0.7665108959653153 and parameters: {'w0': 0.8278165221441034, 'w1': 0.04803748303336424, 'w2': 0.04726579603991959, 'w3': 0.10753669397223908, 'w4': 0.10603349752173978}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:41,480]\u001b[0m Trial 1224 finished with value: 0.7665415852861361 and parameters: {'w0': 0.8004806566961437, 'w1': 0.03526917600095904, 'w2': 0.030917454440332632, 'w3': 0.04899990775137174, 'w4': 0.018044653878665596}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:41,648]\u001b[0m Trial 1225 finished with value: 0.7665287866510077 and parameters: {'w0': 0.816750290272963, 'w1': 0.017974759807753895, 'w2': 0.06749853496056626, 'w3': 0.07318136261240146, 'w4': 0.054787155349478055}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:41,805]\u001b[0m Trial 1226 finished with value: 0.7665417856418235 and parameters: {'w0': 0.7797533175345882, 'w1': 0.060877633742747045, 'w2': 0.00014885099840884417, 'w3': 0.1267323253736973, 'w4': 0.018301597976654357}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:41,965]\u001b[0m Trial 1227 finished with value: 0.7665587684792725 and parameters: {'w0': 0.8863236951014044, 'w1': 0.018572923913129303, 'w2': 0.03783655088324357, 'w3': 0.09543306196961798, 'w4': 0.03509206221990878}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:42,127]\u001b[0m Trial 1228 finished with value: 0.7664327852539883 and parameters: {'w0': 0.8415811297517332, 'w1': 0.03703854540733767, 'w2': 0.8727839073498689, 'w3': 0.16051670597588574, 'w4': 0.018251854922530196}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:42,286]\u001b[0m Trial 1229 finished with value: 0.7664965802283056 and parameters: {'w0': 0.8643482872608227, 'w1': 0.017351763939936603, 'w2': 0.00014303190998960977, 'w3': 0.3574439632882313, 'w4': 0.04711798044679642}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:42,446]\u001b[0m Trial 1230 finished with value: 0.7665500730424448 and parameters: {'w0': 0.8905182650121228, 'w1': 0.03523652351000825, 'w2': 0.023733477770083167, 'w3': 0.05641078759057298, 'w4': 0.018939618844509537}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:42,604]\u001b[0m Trial 1231 finished with value: 0.7664888577014604 and parameters: {'w0': 0.813981433125781, 'w1': 0.06121680248270028, 'w2': 0.05059668534509844, 'w3': 0.027062423283750588, 'w4': 0.0006452126436365829}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:42,767]\u001b[0m Trial 1232 finished with value: 0.7665680188798103 and parameters: {'w0': 0.7452514897791824, 'w1': 0.0005706002181721044, 'w2': 0.018539269616893346, 'w3': 0.11483141006657599, 'w4': 0.0002361266172144741}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:42,924]\u001b[0m Trial 1233 finished with value: 0.7665301753529002 and parameters: {'w0': 0.851785500978134, 'w1': 0.034040831979657654, 'w2': 0.07574940793556477, 'w3': 0.07890553170549541, 'w4': 0.038742694517059445}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:43,081]\u001b[0m Trial 1234 finished with value: 0.7665671691993472 and parameters: {'w0': 0.8686590253304264, 'w1': 0.00014504190789388013, 'w2': 0.017894563398452436, 'w3': 0.13803469855693104, 'w4': 0.00028632027317120274}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:43,242]\u001b[0m Trial 1235 finished with value: 0.7664934529560943 and parameters: {'w0': 0.6231210048171955, 'w1': 0.09233031972774645, 'w2': 0.0438140913139196, 'w3': 0.09325714183111654, 'w4': 0.06895205294081293}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 13:20:43,400]\u001b[0m Trial 1236 finished with value: 0.7665535570770412 and parameters: {'w0': 0.8394989668491387, 'w1': 3.6091311674332966e-05, 'w2': 0.03175670266457446, 'w3': 0.04407277516447674, 'w4': 0.03546728923685548}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:43,557]\u001b[0m Trial 1237 finished with value: 0.7663727319759899 and parameters: {'w0': 0.8890793556878573, 'w1': 0.17015423711668692, 'w2': 0.01658056865701167, 'w3': 0.015548093062181509, 'w4': 0.018648416414385242}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:43,721]\u001b[0m Trial 1238 finished with value: 0.7665638816425862 and parameters: {'w0': 0.820813216954248, 'w1': 0.01946265135857179, 'w2': 0.059195429883945994, 'w3': 0.0691870752802783, 'w4': 6.914365506598087e-07}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:43,881]\u001b[0m Trial 1239 finished with value: 0.7665149802052287 and parameters: {'w0': 0.857624612904231, 'w1': 0.05035546657925373, 'w2': 0.017475103019740586, 'w3': 0.2125836485887087, 'w4': 0.05168168717742669}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:44,039]\u001b[0m Trial 1240 finished with value: 0.7665625911796113 and parameters: {'w0': 0.7999461223193335, 'w1': 0.020204626395309514, 'w2': 0.00028309527684727587, 'w3': 0.10802056706664953, 'w4': 0.030605240473844383}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:44,198]\u001b[0m Trial 1241 finished with value: 0.7665674570221411 and parameters: {'w0': 0.8736656452535466, 'w1': 0.017564466174455836, 'w2': 0.034920917579074964, 'w3': 0.08606683309125657, 'w4': 0.018272078453674522}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:44,357]\u001b[0m Trial 1242 finished with value: 0.7665255102969302 and parameters: {'w0': 0.8378837707984021, 'w1': 0.03743069117270289, 'w2': 0.049735614433752066, 'w3': 0.05642316616075642, 'w4': 0.03390896287625229}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:44,515]\u001b[0m Trial 1243 finished with value: 0.7665522928972854 and parameters: {'w0': 0.8929381986641618, 'w1': 0.01596404271489514, 'w2': 0.017058318304346048, 'w3': 0.11844299642137329, 'w4': 0.06452645473409127}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:44,675]\u001b[0m Trial 1244 finished with value: 0.7665274380202526 and parameters: {'w0': 0.8518714808400982, 'w1': 0.07544641813030085, 'w2': 0.03811468087335594, 'w3': 0.0730998051152729, 'w4': 0.01813492196042652}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:44,837]\u001b[0m Trial 1245 finished with value: 0.7665232245186056 and parameters: {'w0': 0.7801591135714688, 'w1': 0.051132831963998746, 'w2': 0.07522136135672242, 'w3': 0.09740548888572581, 'w4': 0.045739871351728745}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:44,996]\u001b[0m Trial 1246 finished with value: 0.7664161376353019 and parameters: {'w0': 0.8202299975411544, 'w1': 0.0316930839130941, 'w2': 0.00034583945744364993, 'w3': 0.04259609449582965, 'w4': 0.18413482350073823}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:45,153]\u001b[0m Trial 1247 finished with value: 0.7665645930129942 and parameters: {'w0': 0.8631329257205815, 'w1': 0.00015377674526048898, 'w2': 0.03225579087943476, 'w3': 0.131729136002531, 'w4': 0.015106266082047891}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:45,314]\u001b[0m Trial 1248 finished with value: 0.7665617311582096 and parameters: {'w0': 0.8940365312623847, 'w1': 0.018390369070510115, 'w2': 8.358587745278649e-05, 'w3': 0.06298312336463363, 'w4': 0.034425813569156666}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 13:20:45,474]\u001b[0m Trial 1249 finished with value: 0.7665476519701723 and parameters: {'w0': 0.8386369722039596, 'w1': 0.040993233331998696, 'w2': 0.05208217636803161, 'w3': 0.08731436233899938, 'w4': 0.019315357072564647}. Best is trial 1034 with value: 0.7666002003119106.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(run, n_trials=1250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e5042474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w0': 0.8535318456738976,\n",
       " 'w1': 0.0005804260245392991,\n",
       " 'w2': 0.0005338456556189634,\n",
       " 'w3': 0.03947761812798651,\n",
       " 'w4': 0.00029262889516829937}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c6c0ca8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7666002003119106"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "19d281d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF score: 0.7666002003119106\n"
     ]
    }
   ],
   "source": [
    "#Checking OOF score\n",
    "oof_blend = (0.8535318456738976 * tr_l2_log + 0.0005804260245392991 * tr_l2_rr + 0.0005338456556189634 * tr_l2_lassor + 0.03947761812798651 * tr_l2_HistReg + 0.00029262889516829937 * tr_l2_LR) \n",
    "print('OOF score: {}'.format(roc_auc_score(y_train.values, oof_blend)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d4849f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1d09bdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>cancelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130231</td>\n",
       "      <td>0.006940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130232</td>\n",
       "      <td>0.007129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130233</td>\n",
       "      <td>0.006625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130234</td>\n",
       "      <td>0.007099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130235</td>\n",
       "      <td>0.006610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  cancelled\n",
       "0    130231   0.006940\n",
       "1    130232   0.007129\n",
       "2    130233   0.006625\n",
       "3    130234   0.007099\n",
       "4    130235   0.006610"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_blend = (0.8535318456738976 * te_l2_log + 0.0005804260245392991 * te_l2_rr + 0.0005338456556189634 * te_l2_lassor + 0.03947761812798651 * te_l2_HistReg + 0.00029262889516829937 * te_l2_LR) \n",
    "sample_submission.cancelled = sub_blend\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9823d82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>cancelled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130231</td>\n",
       "      <td>0.006940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>130232</td>\n",
       "      <td>0.007129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130233</td>\n",
       "      <td>0.006625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130234</td>\n",
       "      <td>0.007099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130235</td>\n",
       "      <td>0.006610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  cancelled\n",
       "0    130231   0.006940\n",
       "1    130232   0.007129\n",
       "2    130233   0.006625\n",
       "3    130234   0.007099\n",
       "4    130235   0.006610"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.to_csv(\"D:\\\\COMPI-TOP\\\\cascade-cup-22\\\\L2_Blend_Meta.csv\", index=False)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc787de5",
   "metadata": {},
   "source": [
    "## *Checking the diff b/w public lb & CV to select best submission*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "47b9256b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Average Meta Blend': 0.00458979968808948,\n",
       " 'L0_LGBMCLF': 0.0020684926732363884,\n",
       " 'L0_LGBMCLF_TUNED': 0.0014770974729031439,\n",
       " 'L1-Model: LogR': 0.0027410445579530984,\n",
       " 'L1-Model: RidgeR': 0.005801141897702422,\n",
       " 'L2-Model: LogR': 0.004455591470675202,\n",
       " 'L2-Model: RidgeR': 0.005277689668866659,\n",
       " 'L2-Model: LassoR': 0.005285927410675018,\n",
       " 'L2-Model: HistGBREG': 0.0014781087906097223,\n",
       " 'L2-Model: LinearREG': 0.005406327896585794,\n",
       " 'Average L2': 0.0051176249365800786}"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "de6a83a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = dict(sorted(score_dict.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "b5bad375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L0_LGBMCLF_TUNED': 0.0014770974729031439,\n",
       " 'L2-Model: HistGBREG': 0.0014781087906097223,\n",
       " 'L0_LGBMCLF': 0.0020684926732363884,\n",
       " 'L1-Model: LogR': 0.0027410445579530984,\n",
       " 'L2-Model: LogR': 0.004455591470675202,\n",
       " 'Average Meta Blend': 0.00458979968808948,\n",
       " 'Average L2': 0.0051176249365800786,\n",
       " 'L2-Model: RidgeR': 0.005277689668866659,\n",
       " 'L2-Model: LassoR': 0.005285927410675018,\n",
       " 'L2-Model: LinearREG': 0.005406327896585794,\n",
       " 'L1-Model: RidgeR': 0.005801141897702422}"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc294f6",
   "metadata": {},
   "source": [
    "# OPTUNAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04480c7",
   "metadata": {},
   "source": [
    "# L0 MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9891ff0c",
   "metadata": {},
   "source": [
    "## Lgbm-clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "6186aa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(trial):\n",
    "    fold = 0\n",
    "    fold = 0\n",
    "    \n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[features]\n",
    "    xvalid = xvalid[features]\n",
    "    xtest = xtest[features]\n",
    "    \n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\" : trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**param, random_state=RANDOM_SEED, n_estimators=10000)\n",
    "    model.fit(xtrain, ytrain, early_stopping_rounds=500, eval_set=[(xvalid, yvalid)], verbose=False)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "184abe81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 23:21:27,760]\u001b[0m A new study created in memory with name: no-name-83ff9f10-22a3-4772-81d0-b773eeb7a2a1\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:21:37,697]\u001b[0m Trial 0 finished with value: 0.782317722744881 and parameters: {'learning_rate': 0.014593188532828101, 'lambda_l1': 1.2309450344540292e-05, 'lambda_l2': 0.005209005156413746, 'num_leaves': 133, 'feature_fraction': 0.9155328407461846, 'bagging_fraction': 0.6504575125283558, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 0 with value: 0.782317722744881.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:21:46,404]\u001b[0m Trial 1 finished with value: 0.7878223574986166 and parameters: {'learning_rate': 0.019337647832064497, 'lambda_l1': 7.924774655944152e-06, 'lambda_l2': 0.6490527173061319, 'num_leaves': 31, 'feature_fraction': 0.6955358995484817, 'bagging_fraction': 0.9042447853300857, 'bagging_freq': 3, 'min_child_samples': 66}. Best is trial 1 with value: 0.7878223574986166.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:21:56,484]\u001b[0m Trial 2 finished with value: 0.7723242079413393 and parameters: {'learning_rate': 0.07977048332929303, 'lambda_l1': 1.7539669781452695e-07, 'lambda_l2': 0.00018994978366629887, 'num_leaves': 247, 'feature_fraction': 0.5555155711029435, 'bagging_fraction': 0.857370762334597, 'bagging_freq': 7, 'min_child_samples': 52}. Best is trial 1 with value: 0.7878223574986166.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:22:05,244]\u001b[0m Trial 3 finished with value: 0.7897779468732706 and parameters: {'learning_rate': 0.03120580181714717, 'lambda_l1': 1.771747555228799e-07, 'lambda_l2': 5.919580934425124, 'num_leaves': 64, 'feature_fraction': 0.6079826511230386, 'bagging_fraction': 0.8748233855632749, 'bagging_freq': 7, 'min_child_samples': 44}. Best is trial 3 with value: 0.7897779468732706.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:22:10,707]\u001b[0m Trial 4 finished with value: 0.7773998685666851 and parameters: {'learning_rate': 0.1555898852931226, 'lambda_l1': 0.0004341676831633037, 'lambda_l2': 6.2118880312080144e-06, 'num_leaves': 81, 'feature_fraction': 0.5274256290681107, 'bagging_fraction': 0.41037237698689993, 'bagging_freq': 5, 'min_child_samples': 56}. Best is trial 3 with value: 0.7897779468732706.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:22:16,495]\u001b[0m Trial 5 finished with value: 0.7867290398450469 and parameters: {'learning_rate': 0.08903569972074812, 'lambda_l1': 0.11806110691631978, 'lambda_l2': 6.097556194976289e-06, 'num_leaves': 43, 'feature_fraction': 0.8284750731856853, 'bagging_fraction': 0.7322759355444636, 'bagging_freq': 6, 'min_child_samples': 82}. Best is trial 3 with value: 0.7897779468732706.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:22:31,394]\u001b[0m Trial 6 finished with value: 0.7872769092418372 and parameters: {'learning_rate': 0.010185070628496488, 'lambda_l1': 0.00010596440785280303, 'lambda_l2': 0.05372451087476995, 'num_leaves': 213, 'feature_fraction': 0.9182024043117728, 'bagging_fraction': 0.6039054789393852, 'bagging_freq': 1, 'min_child_samples': 55}. Best is trial 3 with value: 0.7897779468732706.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:22:41,852]\u001b[0m Trial 7 finished with value: 0.7682456246541228 and parameters: {'learning_rate': 0.10619934938476266, 'lambda_l1': 0.037146184603221194, 'lambda_l2': 0.6595469346864167, 'num_leaves': 201, 'feature_fraction': 0.8266784586156735, 'bagging_fraction': 0.6696708848275414, 'bagging_freq': 7, 'min_child_samples': 57}. Best is trial 3 with value: 0.7897779468732706.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:22:48,617]\u001b[0m Trial 8 finished with value: 0.7623323360542336 and parameters: {'learning_rate': 0.17403756818814647, 'lambda_l1': 2.7378783509207122e-06, 'lambda_l2': 9.451714771922298e-07, 'num_leaves': 120, 'feature_fraction': 0.6165687758480903, 'bagging_fraction': 0.6988071560888013, 'bagging_freq': 2, 'min_child_samples': 59}. Best is trial 3 with value: 0.7897779468732706.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:22:53,938]\u001b[0m Trial 9 finished with value: 0.7740607706142778 and parameters: {'learning_rate': 0.09068146597450742, 'lambda_l1': 5.975711005080834e-07, 'lambda_l2': 3.595497526619606e-07, 'num_leaves': 75, 'feature_fraction': 0.6775149176180024, 'bagging_fraction': 0.48996972965517743, 'bagging_freq': 4, 'min_child_samples': 84}. Best is trial 3 with value: 0.7897779468732706.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:23:05,588]\u001b[0m Trial 10 finished with value: 0.7909100027670172 and parameters: {'learning_rate': 0.031287157473648075, 'lambda_l1': 1.5131817257858032e-08, 'lambda_l2': 1.7405291353204662e-08, 'num_leaves': 8, 'feature_fraction': 0.40455846600846734, 'bagging_fraction': 0.9984956935784959, 'bagging_freq': 5, 'min_child_samples': 24}. Best is trial 10 with value: 0.7909100027670172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:23:13,126]\u001b[0m Trial 11 finished with value: 0.7986787493082456 and parameters: {'learning_rate': 0.033393159236481285, 'lambda_l1': 3.346640904962391e-08, 'lambda_l2': 3.908099023297473e-08, 'num_leaves': 16, 'feature_fraction': 0.43480396855094344, 'bagging_fraction': 0.9883525790842624, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:23:19,554]\u001b[0m Trial 12 finished with value: 0.7863419168511344 and parameters: {'learning_rate': 0.036010054400791, 'lambda_l1': 2.2517515767279466e-08, 'lambda_l2': 4.8331243548798065e-08, 'num_leaves': 6, 'feature_fraction': 0.40255692407902094, 'bagging_fraction': 0.9843236795250603, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:23:27,850]\u001b[0m Trial 13 finished with value: 0.7836635307138904 and parameters: {'learning_rate': 0.04716778822680263, 'lambda_l1': 1.0512948396587895e-08, 'lambda_l2': 1.1956767024898136e-08, 'num_leaves': 3, 'feature_fraction': 0.4097919939244699, 'bagging_fraction': 0.9878879667397698, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:23:38,847]\u001b[0m Trial 14 finished with value: 0.7878375760929718 and parameters: {'learning_rate': 0.024422844669014142, 'lambda_l1': 3.8437238635939863, 'lambda_l2': 0.00015584382695128278, 'num_leaves': 119, 'feature_fraction': 0.48122910838934974, 'bagging_fraction': 0.7840485185834178, 'bagging_freq': 4, 'min_child_samples': 35}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:23:44,063]\u001b[0m Trial 15 finished with value: 0.7890391532927504 and parameters: {'learning_rate': 0.05122951504203233, 'lambda_l1': 0.0010040352142534669, 'lambda_l2': 1.50547326411356e-07, 'num_leaves': 40, 'feature_fraction': 0.47007026360125237, 'bagging_fraction': 0.9296671255281173, 'bagging_freq': 6, 'min_child_samples': 7}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:23:51,139]\u001b[0m Trial 16 finished with value: 0.7821373478140565 and parameters: {'learning_rate': 0.04975915361137165, 'lambda_l1': 1.1179040960287138e-08, 'lambda_l2': 1.0762749033247944e-08, 'num_leaves': 152, 'feature_fraction': 0.48627946931501853, 'bagging_fraction': 0.8312453156674922, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:24:00,309]\u001b[0m Trial 17 finished with value: 0.7858441131710018 and parameters: {'learning_rate': 0.019297961477295112, 'lambda_l1': 2.2501914563087465e-07, 'lambda_l2': 1.8535218089045556e-05, 'num_leaves': 93, 'feature_fraction': 0.7726894396013277, 'bagging_fraction': 0.9984493164623992, 'bagging_freq': 3, 'min_child_samples': 38}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:24:08,871]\u001b[0m Trial 18 finished with value: 0.7831976342003321 and parameters: {'learning_rate': 0.03191644533083918, 'lambda_l1': 3.6836166287508724e-05, 'lambda_l2': 1.0178084640229173e-06, 'num_leaves': 24, 'feature_fraction': 0.9894213648046111, 'bagging_fraction': 0.8128857620791102, 'bagging_freq': 5, 'min_child_samples': 17}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:24:17,829]\u001b[0m Trial 19 finished with value: 0.787295586607637 and parameters: {'learning_rate': 0.012563896897384805, 'lambda_l1': 0.004096218008327144, 'lambda_l2': 0.0035220393466107855, 'num_leaves': 54, 'feature_fraction': 0.5844839402685216, 'bagging_fraction': 0.5801215357563975, 'bagging_freq': 4, 'min_child_samples': 34}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 23:24:24,894]\u001b[0m Trial 20 finished with value: 0.7912280368013281 and parameters: {'learning_rate': 0.06319057715939608, 'lambda_l1': 1.309741410804374e-06, 'lambda_l2': 6.082090256108576e-08, 'num_leaves': 156, 'feature_fraction': 0.4473400351629755, 'bagging_fraction': 0.9309823812150928, 'bagging_freq': 6, 'min_child_samples': 96}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:24:32,356]\u001b[0m Trial 21 finished with value: 0.7825524003873825 and parameters: {'learning_rate': 0.06778640114480021, 'lambda_l1': 1.1578733756415979e-06, 'lambda_l2': 6.231236339214873e-08, 'num_leaves': 168, 'feature_fraction': 0.4366377119289849, 'bagging_fraction': 0.937122047471401, 'bagging_freq': 6, 'min_child_samples': 98}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:24:41,039]\u001b[0m Trial 22 finished with value: 0.7835168788046485 and parameters: {'learning_rate': 0.03959031599902426, 'lambda_l1': 5.691305462632434e-08, 'lambda_l2': 1.0594929343518959e-08, 'num_leaves': 185, 'feature_fraction': 0.505393143100218, 'bagging_fraction': 0.9418762744307074, 'bagging_freq': 5, 'min_child_samples': 71}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:24:47,307]\u001b[0m Trial 23 finished with value: 0.7541942791920311 and parameters: {'learning_rate': 0.24202549721178837, 'lambda_l1': 5.604131477560961e-08, 'lambda_l2': 1.8912060854471257e-07, 'num_leaves': 108, 'feature_fraction': 0.449884896407752, 'bagging_fraction': 0.7644038506701888, 'bagging_freq': 6, 'min_child_samples': 97}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:24:54,902]\u001b[0m Trial 24 finished with value: 0.784082214997233 and parameters: {'learning_rate': 0.024592611393964795, 'lambda_l1': 2.102714850617266e-06, 'lambda_l2': 1.3904316708466782e-06, 'num_leaves': 145, 'feature_fraction': 0.5403248782449687, 'bagging_fraction': 0.8965597317734688, 'bagging_freq': 5, 'min_child_samples': 46}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:25:00,368]\u001b[0m Trial 25 finished with value: 0.7865867114001108 and parameters: {'learning_rate': 0.06823257222051272, 'lambda_l1': 6.67232500208816e-08, 'lambda_l2': 5.013368765818351e-08, 'num_leaves': 17, 'feature_fraction': 0.6513863654455182, 'bagging_fraction': 0.9519574900310159, 'bagging_freq': 4, 'min_child_samples': 28}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:25:07,520]\u001b[0m Trial 26 finished with value: 0.7851015149418926 and parameters: {'learning_rate': 0.025086801321986017, 'lambda_l1': 3.9910052475230175e-07, 'lambda_l2': 3.4550559139648244e-05, 'num_leaves': 95, 'feature_fraction': 0.40822454931247537, 'bagging_fraction': 0.9994577756283887, 'bagging_freq': 6, 'min_child_samples': 15}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:25:15,402]\u001b[0m Trial 27 finished with value: 0.7834617114001106 and parameters: {'learning_rate': 0.05896393071616633, 'lambda_l1': 6.464802425487069e-06, 'lambda_l2': 3.983475812037757e-06, 'num_leaves': 167, 'feature_fraction': 0.4491786230069349, 'bagging_fraction': 0.8740262212925479, 'bagging_freq': 7, 'min_child_samples': 87}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:25:25,076]\u001b[0m Trial 28 finished with value: 0.793794964028777 and parameters: {'learning_rate': 0.044250306521839464, 'lambda_l1': 4.032245197997341e-08, 'lambda_l2': 2.4721356842182233e-07, 'num_leaves': 219, 'feature_fraction': 0.7441968104583432, 'bagging_fraction': 0.9468380986007409, 'bagging_freq': 5, 'min_child_samples': 42}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:25:35,503]\u001b[0m Trial 29 finished with value: 0.7755741560597675 and parameters: {'learning_rate': 0.04165220407937613, 'lambda_l1': 1.0836649301951323e-05, 'lambda_l2': 0.0017804817693406303, 'num_leaves': 243, 'feature_fraction': 0.7677276323924244, 'bagging_fraction': 0.8356685901483746, 'bagging_freq': 2, 'min_child_samples': 73}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:25:44,836]\u001b[0m Trial 30 finished with value: 0.7634299771721085 and parameters: {'learning_rate': 0.11419814435738021, 'lambda_l1': 6.166797977418536e-05, 'lambda_l2': 4.170711919353792e-07, 'num_leaves': 225, 'feature_fraction': 0.7584354304533055, 'bagging_fraction': 0.7856029002797421, 'bagging_freq': 4, 'min_child_samples': 43}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:25:55,365]\u001b[0m Trial 31 finished with value: 0.7848599197565025 and parameters: {'learning_rate': 0.03061256541155047, 'lambda_l1': 4.6610545412456933e-08, 'lambda_l2': 4.5313871105035255e-08, 'num_leaves': 193, 'feature_fraction': 0.8345997471675786, 'bagging_fraction': 0.9483692260780151, 'bagging_freq': 5, 'min_child_samples': 28}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:26:05,523]\u001b[0m Trial 32 finished with value: 0.7794877559490869 and parameters: {'learning_rate': 0.020314626437374105, 'lambda_l1': 1.0620375364602388e-08, 'lambda_l2': 1.3959687676488502e-07, 'num_leaves': 174, 'feature_fraction': 0.7159217628255369, 'bagging_fraction': 0.9135504314272173, 'bagging_freq': 6, 'min_child_samples': 16}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:26:16,670]\u001b[0m Trial 33 finished with value: 0.7827184214167128 and parameters: {'learning_rate': 0.01646389409394754, 'lambda_l1': 1.2763527281063456e-07, 'lambda_l2': 2.8175396048891052e-08, 'num_leaves': 141, 'feature_fraction': 0.5651518674104791, 'bagging_fraction': 0.963823919510719, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:26:25,222]\u001b[0m Trial 34 finished with value: 0.7819332802988378 and parameters: {'learning_rate': 0.060424017154493234, 'lambda_l1': 6.728636287296369e-07, 'lambda_l2': 4.400510400748753e-07, 'num_leaves': 213, 'feature_fraction': 0.511866751713538, 'bagging_fraction': 0.8960089061325879, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:26:35,174]\u001b[0m Trial 35 finished with value: 0.7869715861925844 and parameters: {'learning_rate': 0.03411079458507687, 'lambda_l1': 1.7837334466897895e-07, 'lambda_l2': 2.464133806679722e-06, 'num_leaves': 256, 'feature_fraction': 0.7285009585849475, 'bagging_fraction': 0.8776154902960932, 'bagging_freq': 7, 'min_child_samples': 40}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:26:40,895]\u001b[0m Trial 36 finished with value: 0.7879174737133371 and parameters: {'learning_rate': 0.027640328173318775, 'lambda_l1': 3.5827679546408436e-08, 'lambda_l2': 8.977177450162757e-08, 'num_leaves': 53, 'feature_fraction': 0.6446905041139169, 'bagging_fraction': 0.8489839444123554, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:26:51,077]\u001b[0m Trial 37 finished with value: 0.7796824847814057 and parameters: {'learning_rate': 0.04289579484645204, 'lambda_l1': 4.863520367969708e-06, 'lambda_l2': 1.9452925464369757e-05, 'num_leaves': 234, 'feature_fraction': 0.43833603144767785, 'bagging_fraction': 0.9639667571635964, 'bagging_freq': 3, 'min_child_samples': 65}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:26:56,669]\u001b[0m Trial 38 finished with value: 0.779257401770891 and parameters: {'learning_rate': 0.05439808297817481, 'lambda_l1': 2.3888434297031777e-05, 'lambda_l2': 0.02943783918360777, 'num_leaves': 35, 'feature_fraction': 0.8619701137022261, 'bagging_fraction': 0.9113433664143137, 'bagging_freq': 6, 'min_child_samples': 51}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:27:02,511]\u001b[0m Trial 39 finished with value: 0.794060078859989 and parameters: {'learning_rate': 0.07379954049635414, 'lambda_l1': 1.280634556184973e-06, 'lambda_l2': 2.557983866596462e-08, 'num_leaves': 19, 'feature_fraction': 0.595944240821474, 'bagging_fraction': 0.966838264830482, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 23:27:08,762]\u001b[0m Trial 40 finished with value: 0.7867541159380189 and parameters: {'learning_rate': 0.07760434169067681, 'lambda_l1': 1.5208209170631646e-06, 'lambda_l2': 0.0005041248660315732, 'num_leaves': 75, 'feature_fraction': 0.5989626380318095, 'bagging_fraction': 0.6237968716666642, 'bagging_freq': 7, 'min_child_samples': 64}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:27:13,609]\u001b[0m Trial 41 finished with value: 0.7871600027670171 and parameters: {'learning_rate': 0.11465161784428113, 'lambda_l1': 3.0787204707997535e-07, 'lambda_l2': 2.5063033093509944e-08, 'num_leaves': 19, 'feature_fraction': 0.5321642832710635, 'bagging_fraction': 0.9697797631031012, 'bagging_freq': 7, 'min_child_samples': 23}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:27:19,035]\u001b[0m Trial 42 finished with value: 0.7877409034311013 and parameters: {'learning_rate': 0.07910780192968316, 'lambda_l1': 1.1422662396349559e-07, 'lambda_l2': 2.1198015863323896e-07, 'num_leaves': 53, 'feature_fraction': 0.42565640506765756, 'bagging_fraction': 0.9234596326845252, 'bagging_freq': 6, 'min_child_samples': 5}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:27:25,254]\u001b[0m Trial 43 finished with value: 0.7896790260099612 and parameters: {'learning_rate': 0.04067354633569018, 'lambda_l1': 0.0002543201043082585, 'lambda_l2': 2.2839654726829384e-08, 'num_leaves': 28, 'feature_fraction': 0.4673460684270874, 'bagging_fraction': 0.9668443327113819, 'bagging_freq': 7, 'min_child_samples': 12}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:27:29,315]\u001b[0m Trial 44 finished with value: 0.7863579136690647 and parameters: {'learning_rate': 0.14124529266866923, 'lambda_l1': 1.9772692502077362e-08, 'lambda_l2': 3.473734186074558e-07, 'num_leaves': 9, 'feature_fraction': 0.6723413177844979, 'bagging_fraction': 0.8770431517113646, 'bagging_freq': 6, 'min_child_samples': 24}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:27:32,632]\u001b[0m Trial 45 finished with value: 0.7834662942722745 and parameters: {'learning_rate': 0.09451304432587465, 'lambda_l1': 6.846883784501283e-07, 'lambda_l2': 9.676376437051254e-08, 'num_leaves': 13, 'feature_fraction': 0.5601089451490064, 'bagging_fraction': 0.43475396022210167, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:27:40,172]\u001b[0m Trial 46 finished with value: 0.7838914637520753 and parameters: {'learning_rate': 0.06649140593688425, 'lambda_l1': 5.959648855786138, 'lambda_l2': 7.146569113634982e-07, 'num_leaves': 64, 'feature_fraction': 0.5002097032360144, 'bagging_fraction': 0.9970986968853885, 'bagging_freq': 5, 'min_child_samples': 33}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:27:46,045]\u001b[0m Trial 47 finished with value: 0.7750093386829 and parameters: {'learning_rate': 0.04851681722234991, 'lambda_l1': 2.4219012180162244e-08, 'lambda_l2': 2.2392044775303255, 'num_leaves': 2, 'feature_fraction': 0.6207624650918748, 'bagging_fraction': 0.5465440619067614, 'bagging_freq': 7, 'min_child_samples': 39}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:27:54,108]\u001b[0m Trial 48 finished with value: 0.7842925083010515 and parameters: {'learning_rate': 0.035279612282902176, 'lambda_l1': 3.143246300071803e-06, 'lambda_l2': 2.0759749618003647e-08, 'num_leaves': 129, 'feature_fraction': 0.7988077618572018, 'bagging_fraction': 0.9745489104186589, 'bagging_freq': 6, 'min_child_samples': 90}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 23:28:01,423]\u001b[0m Trial 49 finished with value: 0.7882636967349198 and parameters: {'learning_rate': 0.028561734914549258, 'lambda_l1': 0.3770467462898395, 'lambda_l2': 2.0827428395172013e-06, 'num_leaves': 40, 'feature_fraction': 0.46593632446721733, 'bagging_fraction': 0.7069388708607574, 'bagging_freq': 4, 'min_child_samples': 78}. Best is trial 11 with value: 0.7986787493082456.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(run, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "ff791152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.033393159236481285,\n",
       " 'lambda_l1': 3.346640904962391e-08,\n",
       " 'lambda_l2': 3.908099023297473e-08,\n",
       " 'num_leaves': 16,\n",
       " 'feature_fraction': 0.43480396855094344,\n",
       " 'bagging_fraction': 0.9883525790842624,\n",
       " 'bagging_freq': 5,\n",
       " 'min_child_samples': 25}"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "a231e6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7986787493082456"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cc4dc5",
   "metadata": {},
   "source": [
    "-------lgbm1--------\n",
    "{'learning_rate': 0.04394129972546718,\n",
    " 'lambda_l1': 3.332009828221393e-08,\n",
    " 'lambda_l2': 2.8764308768784934,\n",
    " 'num_leaves': 96,\n",
    " 'feature_fraction': 0.5517245233128265,\n",
    " 'bagging_fraction': 0.5205133833553873,\n",
    " 'bagging_freq': 5,\n",
    " 'min_child_samples': 27}\n",
    "0.7955257332595463\n",
    "\n",
    "-------lgbm1--------\n",
    "\n",
    "-------lgbm2--------\n",
    "{'learning_rate': 0.033393159236481285,\n",
    " 'lambda_l1': 3.346640904962391e-08,\n",
    " 'lambda_l2': 3.908099023297473e-08,\n",
    " 'num_leaves': 16,\n",
    " 'feature_fraction': 0.43480396855094344,\n",
    " 'bagging_fraction': 0.9883525790842624,\n",
    " 'bagging_freq': 5,\n",
    " 'min_child_samples': 25}\n",
    " 0.7986787493082456\n",
    " \n",
    "-------lgbm2--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "960955f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.77 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "def run(trial):\n",
    "    \n",
    "    fold = 0\n",
    "    \n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[features]\n",
    "    xvalid = xvalid[features]\n",
    "    xtest = xtest[features]\n",
    "    \n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        'boosting_type': trial.suggest_categorical(\"boosting_type\", [\"gbdt\"]),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-3, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-3, 10.0),\n",
    "        'bagging_fraction': trial.suggest_categorical('bagging_fraction', [.4, .5, .45, 0.6, 0.7]),\n",
    "        'feature_fraction': trial.suggest_categorical('feature_fraction', [.3, .4, .5, 0.6, 0.7, 0.80]),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [.018, .0186, .0192, 0.0196, .0193, .0199]),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 20, step=1),\n",
    "        'num_leaves' : trial.suggest_int('num_leaves', 650, 850, step=5),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 40, 80, step=5),      \n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 300, 600, step=20),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 250, 350),\n",
    "        'min_gain_to_split': trial.suggest_categorical('min_gain_to_split', [0.02084372652774491, 0.01084372652774491, 0.03084372652774491]),\n",
    "        }\n",
    "    \n",
    "    model = LGBMClassifier(**param, random_state=RANDOM_SEED, n_estimators=10000)\n",
    "    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=False)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    \n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "8ae3cadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:39:55,213]\u001b[0m A new study created in memory with name: no-name-a24035ad-e85b-435f-8307-24c0189a5316\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 22:40:07,673]\u001b[0m Trial 0 finished with value: 0.7683790467625901 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.05228118140761344, 'lambda_l2': 0.0019957367168903207, 'bagging_fraction': 0.5, 'feature_fraction': 0.4, 'learning_rate': 0.0196, 'max_depth': 18, 'num_leaves': 710, 'min_child_samples': 60, 'min_data_in_leaf': 360, 'max_bin': 339, 'min_gain_to_split': 0.02084372652774491}. Best is trial 0 with value: 0.7683790467625901.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7683790467625901\n",
      "0 0.7683790467625901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:40:16,599]\u001b[0m Trial 1 finished with value: 0.7790516048699502 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 2.440130395485377, 'lambda_l2': 0.0024931094844332495, 'bagging_fraction': 0.7, 'feature_fraction': 0.8, 'learning_rate': 0.018, 'max_depth': 11, 'num_leaves': 770, 'min_child_samples': 55, 'min_data_in_leaf': 320, 'max_bin': 254, 'min_gain_to_split': 0.03084372652774491}. Best is trial 1 with value: 0.7790516048699502.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7790516048699502\n",
      "0 0.7790516048699502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:40:25,273]\u001b[0m Trial 2 finished with value: 0.7841219908688433 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.0017648636827915717, 'lambda_l2': 1.4257020514359644, 'bagging_fraction': 0.7, 'feature_fraction': 0.7, 'learning_rate': 0.0192, 'max_depth': 8, 'num_leaves': 650, 'min_child_samples': 60, 'min_data_in_leaf': 580, 'max_bin': 336, 'min_gain_to_split': 0.02084372652774491}. Best is trial 2 with value: 0.7841219908688433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7841219908688433\n",
      "0 0.7841219908688433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:40:34,742]\u001b[0m Trial 3 finished with value: 0.7809596361372441 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.00937889701950134, 'lambda_l2': 4.699715008485733, 'bagging_fraction': 0.4, 'feature_fraction': 0.7, 'learning_rate': 0.0196, 'max_depth': 15, 'num_leaves': 740, 'min_child_samples': 45, 'min_data_in_leaf': 400, 'max_bin': 315, 'min_gain_to_split': 0.01084372652774491}. Best is trial 2 with value: 0.7841219908688433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7809596361372441\n",
      "0 0.7809596361372441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:40:45,204]\u001b[0m Trial 4 finished with value: 0.7840841173215274 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 1.754895114034005, 'lambda_l2': 0.2293923518422634, 'bagging_fraction': 0.6, 'feature_fraction': 0.5, 'learning_rate': 0.0186, 'max_depth': 17, 'num_leaves': 665, 'min_child_samples': 55, 'min_data_in_leaf': 560, 'max_bin': 267, 'min_gain_to_split': 0.02084372652774491}. Best is trial 2 with value: 0.7841219908688433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7840841173215274\n",
      "0 0.7840841173215274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:40:52,348]\u001b[0m Trial 5 finished with value: 0.7841164568345325 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.9299681030926875, 'lambda_l2': 0.013820057382563328, 'bagging_fraction': 0.7, 'feature_fraction': 0.5, 'learning_rate': 0.018, 'max_depth': 10, 'num_leaves': 815, 'min_child_samples': 50, 'min_data_in_leaf': 300, 'max_bin': 326, 'min_gain_to_split': 0.03084372652774491}. Best is trial 2 with value: 0.7841219908688433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7841164568345325\n",
      "0 0.7841164568345325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:41:00,315]\u001b[0m Trial 6 finished with value: 0.772113309352518 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.06090272350211456, 'lambda_l2': 0.06287805989336108, 'bagging_fraction': 0.5, 'feature_fraction': 0.3, 'learning_rate': 0.0196, 'max_depth': 13, 'num_leaves': 735, 'min_child_samples': 45, 'min_data_in_leaf': 560, 'max_bin': 299, 'min_gain_to_split': 0.02084372652774491}. Best is trial 2 with value: 0.7841219908688433.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.772113309352518\n",
      "0 0.772113309352518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:41:11,405]\u001b[0m Trial 7 finished with value: 0.787664983397897 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 8.665773409803938, 'lambda_l2': 0.0018143591153172377, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.018, 'max_depth': 19, 'num_leaves': 695, 'min_child_samples': 80, 'min_data_in_leaf': 580, 'max_bin': 334, 'min_gain_to_split': 0.01084372652774491}. Best is trial 7 with value: 0.787664983397897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.787664983397897\n",
      "0 0.787664983397897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:41:19,563]\u001b[0m Trial 8 finished with value: 0.7825838752075263 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.002853557467404325, 'lambda_l2': 0.050993887173672474, 'bagging_fraction': 0.7, 'feature_fraction': 0.6, 'learning_rate': 0.0196, 'max_depth': 12, 'num_leaves': 725, 'min_child_samples': 80, 'min_data_in_leaf': 460, 'max_bin': 275, 'min_gain_to_split': 0.02084372652774491}. Best is trial 7 with value: 0.787664983397897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7825838752075263\n",
      "0 0.7825838752075263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:41:27,979]\u001b[0m Trial 9 finished with value: 0.7782649937742114 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.9896030412045809, 'lambda_l2': 0.031000483185021396, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.0199, 'max_depth': 17, 'num_leaves': 650, 'min_child_samples': 60, 'min_data_in_leaf': 340, 'max_bin': 333, 'min_gain_to_split': 0.02084372652774491}. Best is trial 7 with value: 0.787664983397897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7782649937742114\n",
      "0 0.7782649937742114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:41:40,349]\u001b[0m Trial 10 finished with value: 0.7835609781405645 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 8.204462390238717, 'lambda_l2': 0.0010416715665077642, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.0193, 'max_depth': 20, 'num_leaves': 850, 'min_child_samples': 80, 'min_data_in_leaf': 480, 'max_bin': 308, 'min_gain_to_split': 0.01084372652774491}. Best is trial 7 with value: 0.787664983397897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7835609781405645\n",
      "0 0.7835609781405645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:41:45,869]\u001b[0m Trial 11 finished with value: 0.7870432692307692 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.0010350367506527269, 'lambda_l2': 1.2480611056620603, 'bagging_fraction': 0.45, 'feature_fraction': 0.7, 'learning_rate': 0.0192, 'max_depth': 6, 'num_leaves': 685, 'min_child_samples': 70, 'min_data_in_leaf': 580, 'max_bin': 347, 'min_gain_to_split': 0.01084372652774491}. Best is trial 7 with value: 0.787664983397897.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7870432692307692\n",
      "0 0.7870432692307692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:41:52,683]\u001b[0m Trial 12 finished with value: 0.7902654607083565 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.23013006702257555, 'lambda_l2': 0.3432171170758205, 'bagging_fraction': 0.45, 'feature_fraction': 0.7, 'learning_rate': 0.0192, 'max_depth': 6, 'num_leaves': 690, 'min_child_samples': 70, 'min_data_in_leaf': 520, 'max_bin': 346, 'min_gain_to_split': 0.01084372652774491}. Best is trial 12 with value: 0.7902654607083565.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7902654607083565\n",
      "0 0.7902654607083565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:41:59,162]\u001b[0m Trial 13 finished with value: 0.7843912562257884 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.20285908894753155, 'lambda_l2': 0.21797623934088484, 'bagging_fraction': 0.45, 'feature_fraction': 0.3, 'learning_rate': 0.018, 'max_depth': 5, 'num_leaves': 700, 'min_child_samples': 70, 'min_data_in_leaf': 520, 'max_bin': 350, 'min_gain_to_split': 0.01084372652774491}. Best is trial 12 with value: 0.7902654607083565.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7843912562257884\n",
      "0 0.7843912562257884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:42:07,072]\u001b[0m Trial 14 finished with value: 0.7826079136690647 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.21766819397746173, 'lambda_l2': 0.011027866265964666, 'bagging_fraction': 0.45, 'feature_fraction': 0.8, 'learning_rate': 0.0192, 'max_depth': 8, 'num_leaves': 780, 'min_child_samples': 70, 'min_data_in_leaf': 520, 'max_bin': 291, 'min_gain_to_split': 0.01084372652774491}. Best is trial 12 with value: 0.7902654607083565.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7826079136690647\n",
      "0 0.7826079136690647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:42:14,354]\u001b[0m Trial 15 finished with value: 0.7699546900940787 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.012933102714821013, 'lambda_l2': 0.33122868739192357, 'bagging_fraction': 0.4, 'feature_fraction': 0.4, 'learning_rate': 0.0186, 'max_depth': 14, 'num_leaves': 680, 'min_child_samples': 75, 'min_data_in_leaf': 520, 'max_bin': 321, 'min_gain_to_split': 0.01084372652774491}. Best is trial 12 with value: 0.7902654607083565.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7699546900940787\n",
      "0 0.7699546900940787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:42:22,816]\u001b[0m Trial 16 finished with value: 0.7842350926950747 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 9.988821534499305, 'lambda_l2': 1.1101618127916724, 'bagging_fraction': 0.6, 'feature_fraction': 0.7, 'learning_rate': 0.0193, 'max_depth': 20, 'num_leaves': 700, 'min_child_samples': 75, 'min_data_in_leaf': 600, 'max_bin': 350, 'min_gain_to_split': 0.01084372652774491}. Best is trial 12 with value: 0.7902654607083565.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7842350926950747\n",
      "0 0.7842350926950747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:42:29,909]\u001b[0m Trial 17 finished with value: 0.7894571458218043 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.35780692713623835, 'lambda_l2': 9.120086988126342, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.0199, 'max_depth': 8, 'num_leaves': 755, 'min_child_samples': 65, 'min_data_in_leaf': 500, 'max_bin': 327, 'min_gain_to_split': 0.01084372652774491}. Best is trial 12 with value: 0.7902654607083565.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7894571458218043\n",
      "0 0.7894571458218043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:42:36,938]\u001b[0m Trial 18 finished with value: 0.7912598574986166 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.30386611936344904, 'lambda_l2': 8.808513789345445, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.0199, 'max_depth': 8, 'num_leaves': 780, 'min_child_samples': 65, 'min_data_in_leaf': 420, 'max_bin': 314, 'min_gain_to_split': 0.03084372652774491}. Best is trial 18 with value: 0.7912598574986166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7912598574986166\n",
      "0 0.7912598574986166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:42:45,910]\u001b[0m Trial 19 finished with value: 0.7870197495849475 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.033421334113922375, 'lambda_l2': 3.055884038959245, 'bagging_fraction': 0.45, 'feature_fraction': 0.7, 'learning_rate': 0.0199, 'max_depth': 6, 'num_leaves': 800, 'min_child_samples': 65, 'min_data_in_leaf': 420, 'max_bin': 288, 'min_gain_to_split': 0.03084372652774491}. Best is trial 18 with value: 0.7912598574986166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7870197495849475\n",
      "0 0.7870197495849475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:42:52,393]\u001b[0m Trial 20 finished with value: 0.7814044341449917 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.5035642646064593, 'lambda_l2': 0.49621489977158206, 'bagging_fraction': 0.5, 'feature_fraction': 0.4, 'learning_rate': 0.0199, 'max_depth': 9, 'num_leaves': 830, 'min_child_samples': 65, 'min_data_in_leaf': 420, 'max_bin': 305, 'min_gain_to_split': 0.03084372652774491}. Best is trial 18 with value: 0.7912598574986166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7814044341449917\n",
      "0 0.7814044341449917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:43:02,522]\u001b[0m Trial 21 finished with value: 0.789203617874931 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.22391177362577297, 'lambda_l2': 5.671313057390494, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.0199, 'max_depth': 7, 'num_leaves': 760, 'min_child_samples': 65, 'min_data_in_leaf': 480, 'max_bin': 321, 'min_gain_to_split': 0.03084372652774491}. Best is trial 18 with value: 0.7912598574986166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.789203617874931\n",
      "0 0.789203617874931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:43:14,781]\u001b[0m Trial 22 finished with value: 0.7888776286662978 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.11439160981849088, 'lambda_l2': 9.857714217964451, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.0199, 'max_depth': 5, 'num_leaves': 755, 'min_child_samples': 65, 'min_data_in_leaf': 500, 'max_bin': 327, 'min_gain_to_split': 0.03084372652774491}. Best is trial 18 with value: 0.7912598574986166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7888776286662978\n",
      "0 0.7888776286662978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:43:22,793]\u001b[0m Trial 23 finished with value: 0.7890422661870504 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.4542053727229557, 'lambda_l2': 2.462998602871497, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.0192, 'max_depth': 9, 'num_leaves': 790, 'min_child_samples': 75, 'min_data_in_leaf': 440, 'max_bin': 312, 'min_gain_to_split': 0.01084372652774491}. Best is trial 18 with value: 0.7912598574986166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7890422661870504\n",
      "0 0.7890422661870504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:43:30,471]\u001b[0m Trial 24 finished with value: 0.789891048699502 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.4476244531525466, 'lambda_l2': 0.7051651386751919, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.0199, 'max_depth': 7, 'num_leaves': 720, 'min_child_samples': 70, 'min_data_in_leaf': 380, 'max_bin': 340, 'min_gain_to_split': 0.01084372652774491}. Best is trial 18 with value: 0.7912598574986166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.789891048699502\n",
      "0 0.789891048699502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:43:37,668]\u001b[0m Trial 25 finished with value: 0.7894280921416712 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 3.1696783574980008, 'lambda_l2': 0.6629369632581905, 'bagging_fraction': 0.6, 'feature_fraction': 0.5, 'learning_rate': 0.0199, 'max_depth': 7, 'num_leaves': 725, 'min_child_samples': 70, 'min_data_in_leaf': 360, 'max_bin': 343, 'min_gain_to_split': 0.03084372652774491}. Best is trial 18 with value: 0.7912598574986166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7894280921416712\n",
      "0 0.7894280921416712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:43:49,288]\u001b[0m Trial 26 finished with value: 0.7769924252905367 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.10172413416212574, 'lambda_l2': 0.12501982140780998, 'bagging_fraction': 0.4, 'feature_fraction': 0.3, 'learning_rate': 0.0192, 'max_depth': 10, 'num_leaves': 725, 'min_child_samples': 40, 'min_data_in_leaf': 380, 'max_bin': 339, 'min_gain_to_split': 0.01084372652774491}. Best is trial 18 with value: 0.7912598574986166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7769924252905367\n",
      "0 0.7769924252905367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:44:01,307]\u001b[0m Trial 27 finished with value: 0.7872042750415053 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.9104488686060035, 'lambda_l2': 0.13154908218928973, 'bagging_fraction': 0.45, 'feature_fraction': 0.8, 'learning_rate': 0.0199, 'max_depth': 6, 'num_leaves': 675, 'min_child_samples': 75, 'min_data_in_leaf': 400, 'max_bin': 296, 'min_gain_to_split': 0.03084372652774491}. Best is trial 18 with value: 0.7912598574986166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7872042750415053\n",
      "0 0.7872042750415053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:44:09,105]\u001b[0m Trial 28 finished with value: 0.7857685390149419 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.02122673999867607, 'lambda_l2': 0.608561723467771, 'bagging_fraction': 0.45, 'feature_fraction': 0.7, 'learning_rate': 0.0193, 'max_depth': 7, 'num_leaves': 710, 'min_child_samples': 70, 'min_data_in_leaf': 440, 'max_bin': 318, 'min_gain_to_split': 0.01084372652774491}. Best is trial 18 with value: 0.7912598574986166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7857685390149419\n",
      "0 0.7857685390149419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:44:17,446]\u001b[0m Trial 29 finished with value: 0.7833520683453239 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.08988850688961206, 'lambda_l2': 2.568606866666229, 'bagging_fraction': 0.5, 'feature_fraction': 0.4, 'learning_rate': 0.0186, 'max_depth': 5, 'num_leaves': 710, 'min_child_samples': 55, 'min_data_in_leaf': 380, 'max_bin': 341, 'min_gain_to_split': 0.03084372652774491}. Best is trial 18 with value: 0.7912598574986166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7833520683453239\n",
      "0 0.7833520683453239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:44:24,412]\u001b[0m Trial 30 finished with value: 0.7831699640287769 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.03929125509952504, 'lambda_l2': 1.4260910394909703, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.0192, 'max_depth': 11, 'num_leaves': 740, 'min_child_samples': 60, 'min_data_in_leaf': 360, 'max_bin': 280, 'min_gain_to_split': 0.01084372652774491}. Best is trial 18 with value: 0.7912598574986166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7831699640287769\n",
      "0 0.7831699640287769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:44:30,905]\u001b[0m Trial 31 finished with value: 0.789914049529607 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.4144902932899123, 'lambda_l2': 9.236706708045565, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.0199, 'max_depth': 8, 'num_leaves': 770, 'min_child_samples': 65, 'min_data_in_leaf': 480, 'max_bin': 334, 'min_gain_to_split': 0.01084372652774491}. Best is trial 18 with value: 0.7912598574986166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.789914049529607\n",
      "0 0.789914049529607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:44:40,067]\u001b[0m Trial 32 finished with value: 0.7921714167127836 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.5767901463149834, 'lambda_l2': 5.748955790886348, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.0199, 'max_depth': 9, 'num_leaves': 780, 'min_child_samples': 65, 'min_data_in_leaf': 460, 'max_bin': 330, 'min_gain_to_split': 0.01084372652774491}. Best is trial 32 with value: 0.7921714167127836.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7921714167127836\n",
      "0 0.7921714167127836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:44:47,945]\u001b[0m Trial 33 finished with value: 0.7913567030990591 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 2.2348527488394208, 'lambda_l2': 5.119668240347544, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.0199, 'max_depth': 9, 'num_leaves': 775, 'min_child_samples': 60, 'min_data_in_leaf': 460, 'max_bin': 333, 'min_gain_to_split': 0.01084372652774491}. Best is trial 32 with value: 0.7921714167127836.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7913567030990591\n",
      "0 0.7913567030990591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:44:58,743]\u001b[0m Trial 34 finished with value: 0.7866956627006086 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 2.854900480574471, 'lambda_l2': 4.898163866639181, 'bagging_fraction': 0.4, 'feature_fraction': 0.8, 'learning_rate': 0.0199, 'max_depth': 10, 'num_leaves': 805, 'min_child_samples': 60, 'min_data_in_leaf': 460, 'max_bin': 330, 'min_gain_to_split': 0.01084372652774491}. Best is trial 32 with value: 0.7921714167127836.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7866956627006086\n",
      "0 0.7866956627006086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:45:05,613]\u001b[0m Trial 35 finished with value: 0.7867522136137244 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 1.6918765379442229, 'lambda_l2': 3.906234803603601, 'bagging_fraction': 0.7, 'feature_fraction': 0.7, 'learning_rate': 0.0199, 'max_depth': 9, 'num_leaves': 770, 'min_child_samples': 55, 'min_data_in_leaf': 540, 'max_bin': 311, 'min_gain_to_split': 0.01084372652774491}. Best is trial 32 with value: 0.7921714167127836.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7867522136137244\n",
      "0 0.7867522136137244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:45:14,292]\u001b[0m Trial 36 finished with value: 0.7891849405091312 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 5.061395962695815, 'lambda_l2': 1.8798737171779614, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.0192, 'max_depth': 11, 'num_leaves': 785, 'min_child_samples': 60, 'min_data_in_leaf': 420, 'max_bin': 323, 'min_gain_to_split': 0.03084372652774491}. Best is trial 32 with value: 0.7921714167127836.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7891849405091312\n",
      "0 0.7891849405091312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:45:23,075]\u001b[0m Trial 37 finished with value: 0.785195766463752 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 1.6235384512291153, 'lambda_l2': 5.572202040230979, 'bagging_fraction': 0.6, 'feature_fraction': 0.5, 'learning_rate': 0.0196, 'max_depth': 13, 'num_leaves': 815, 'min_child_samples': 50, 'min_data_in_leaf': 460, 'max_bin': 255, 'min_gain_to_split': 0.02084372652774491}. Best is trial 32 with value: 0.7921714167127836.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.785195766463752\n",
      "0 0.785195766463752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:45:31,950]\u001b[0m Trial 38 finished with value: 0.7828977587161041 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.8771367539769646, 'lambda_l2': 0.004962090502946946, 'bagging_fraction': 0.5, 'feature_fraction': 0.7, 'learning_rate': 0.0186, 'max_depth': 11, 'num_leaves': 775, 'min_child_samples': 50, 'min_data_in_leaf': 500, 'max_bin': 317, 'min_gain_to_split': 0.01084372652774491}. Best is trial 32 with value: 0.7921714167127836.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7828977587161041\n",
      "0 0.7828977587161041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:45:38,931]\u001b[0m Trial 39 finished with value: 0.7890925913115661 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.14303436610593184, 'lambda_l2': 3.3794669317224684, 'bagging_fraction': 0.7, 'feature_fraction': 0.6, 'learning_rate': 0.018, 'max_depth': 9, 'num_leaves': 745, 'min_child_samples': 55, 'min_data_in_leaf': 440, 'max_bin': 346, 'min_gain_to_split': 0.02084372652774491}. Best is trial 32 with value: 0.7921714167127836.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7890925913115661\n",
      "0 0.7890925913115661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:45:49,104]\u001b[0m Trial 40 finished with value: 0.7795342764250137 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.6787636992320669, 'lambda_l2': 5.773705533629432, 'bagging_fraction': 0.45, 'feature_fraction': 0.3, 'learning_rate': 0.0199, 'max_depth': 12, 'num_leaves': 800, 'min_child_samples': 60, 'min_data_in_leaf': 540, 'max_bin': 336, 'min_gain_to_split': 0.01084372652774491}. Best is trial 32 with value: 0.7921714167127836.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7795342764250137\n",
      "0 0.7795342764250137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:45:57,294]\u001b[0m Trial 41 finished with value: 0.7898092487548424 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.3027851191764807, 'lambda_l2': 8.757668200090878, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.0199, 'max_depth': 8, 'num_leaves': 765, 'min_child_samples': 65, 'min_data_in_leaf': 460, 'max_bin': 331, 'min_gain_to_split': 0.01084372652774491}. Best is trial 32 with value: 0.7921714167127836.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7898092487548424\n",
      "0 0.7898092487548424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:46:09,687]\u001b[0m Trial 42 finished with value: 0.7944249792473712 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 2.013079655498328, 'lambda_l2': 6.704712390093808, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.0199, 'max_depth': 10, 'num_leaves': 790, 'min_child_samples': 65, 'min_data_in_leaf': 480, 'max_bin': 336, 'min_gain_to_split': 0.01084372652774491}. Best is trial 42 with value: 0.7944249792473712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7944249792473712\n",
      "0 0.7944249792473712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:46:17,068]\u001b[0m Trial 43 finished with value: 0.7877720323741008 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 4.551807088500135, 'lambda_l2': 1.929735674097032, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.0199, 'max_depth': 10, 'num_leaves': 790, 'min_child_samples': 65, 'min_data_in_leaf': 480, 'max_bin': 344, 'min_gain_to_split': 0.01084372652774491}. Best is trial 42 with value: 0.7944249792473712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7877720323741008\n",
      "0 0.7877720323741008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:46:25,863]\u001b[0m Trial 44 finished with value: 0.7862230215827338 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 1.2879291649399596, 'lambda_l2': 6.075084782291663, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.0196, 'max_depth': 10, 'num_leaves': 820, 'min_child_samples': 60, 'min_data_in_leaf': 500, 'max_bin': 304, 'min_gain_to_split': 0.01084372652774491}. Best is trial 42 with value: 0.7944249792473712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7862230215827338\n",
      "0 0.7862230215827338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:46:34,419]\u001b[0m Trial 45 finished with value: 0.7894030160486994 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 2.6882825797509504, 'lambda_l2': 0.9320041858092057, 'bagging_fraction': 0.45, 'feature_fraction': 0.6, 'learning_rate': 0.0199, 'max_depth': 6, 'num_leaves': 780, 'min_child_samples': 70, 'min_data_in_leaf': 400, 'max_bin': 329, 'min_gain_to_split': 0.01084372652774491}. Best is trial 42 with value: 0.7944249792473712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7894030160486994\n",
      "0 0.7894030160486994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:46:42,038]\u001b[0m Trial 46 finished with value: 0.788645890979524 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 4.946562962048438, 'lambda_l2': 0.025135498640203795, 'bagging_fraction': 0.45, 'feature_fraction': 0.5, 'learning_rate': 0.0192, 'max_depth': 8, 'num_leaves': 830, 'min_child_samples': 60, 'min_data_in_leaf': 540, 'max_bin': 324, 'min_gain_to_split': 0.02084372652774491}. Best is trial 42 with value: 0.7944249792473712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.788645890979524\n",
      "0 0.788645890979524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:46:51,383]\u001b[0m Trial 47 finished with value: 0.7833157512451577 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.06222705965565016, 'lambda_l2': 1.8404422484468925, 'bagging_fraction': 0.7, 'feature_fraction': 0.6, 'learning_rate': 0.0193, 'max_depth': 12, 'num_leaves': 790, 'min_child_samples': 55, 'min_data_in_leaf': 300, 'max_bin': 336, 'min_gain_to_split': 0.01084372652774491}. Best is trial 42 with value: 0.7944249792473712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7833157512451577\n",
      "0 0.7833157512451577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:47:01,675]\u001b[0m Trial 48 finished with value: 0.7780727725511898 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 0.6293269161634566, 'lambda_l2': 0.3664284273762438, 'bagging_fraction': 0.45, 'feature_fraction': 0.7, 'learning_rate': 0.018, 'max_depth': 15, 'num_leaves': 805, 'min_child_samples': 70, 'min_data_in_leaf': 440, 'max_bin': 315, 'min_gain_to_split': 0.03084372652774491}. Best is trial 42 with value: 0.7944249792473712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7780727725511898\n",
      "0 0.7780727725511898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 22:47:11,396]\u001b[0m Trial 49 finished with value: 0.7858684975096846 and parameters: {'boosting_type': 'gbdt', 'lambda_l1': 1.2733440988165476, 'lambda_l2': 3.885566230343337, 'bagging_fraction': 0.6, 'feature_fraction': 0.8, 'learning_rate': 0.0199, 'max_depth': 9, 'num_leaves': 765, 'min_child_samples': 65, 'min_data_in_leaf': 480, 'max_bin': 337, 'min_gain_to_split': 0.01084372652774491}. Best is trial 42 with value: 0.7944249792473712.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7858684975096846\n",
      "0 0.7858684975096846\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(run, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "9023217d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'gbdt',\n",
       " 'lambda_l1': 2.013079655498328,\n",
       " 'lambda_l2': 6.704712390093808,\n",
       " 'bagging_fraction': 0.45,\n",
       " 'feature_fraction': 0.6,\n",
       " 'learning_rate': 0.0199,\n",
       " 'max_depth': 10,\n",
       " 'num_leaves': 790,\n",
       " 'min_child_samples': 65,\n",
       " 'min_data_in_leaf': 480,\n",
       " 'max_bin': 336,\n",
       " 'min_gain_to_split': 0.01084372652774491}"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "3952b3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7944249792473712"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d62981",
   "metadata": {},
   "source": [
    "-------lgbm1--------\n",
    "{'boosting_type': 'gbdt',\n",
    " 'lambda_l1': 0.5806043684908021,\n",
    " 'lambda_l2': 7.106418698435042,\n",
    " 'bagging_fraction': 0.45,\n",
    " 'feature_fraction': 0.5,\n",
    " 'learning_rate': 0.018,\n",
    " 'max_depth': 8,\n",
    " 'num_leaves': 775,\n",
    " 'min_child_samples': 75,\n",
    " 'min_data_in_leaf': 520,\n",
    " 'max_bin': 331,\n",
    " 'min_gain_to_split': 0.01084372652774491}\n",
    " 0.7929055409518538\n",
    "-------lgbm1--------\n",
    "-------lgbm2--------\n",
    "'boosting_type': 'gbdt',\n",
    " 'lambda_l1': 0.004120454129529359,\n",
    " 'lambda_l2': 0.3054014755871697,\n",
    " 'bagging_fraction': 0.6,\n",
    " 'feature_fraction': 0.6,\n",
    " 'learning_rate': 0.0199,\n",
    " 'max_depth': 7,\n",
    " 'num_leaves': 685,\n",
    " 'min_child_samples': 45,\n",
    " 'min_data_in_leaf': 500,\n",
    " 'max_bin': 288,\n",
    " 'min_gain_to_split': 0.02084372652774491\n",
    "0.7912446389042612\n",
    "-------lgbm2--------\n",
    "-------lgbm3--------\n",
    "'boosting_type': 'gbdt',\n",
    " 'lambda_l1': 2.013079655498328,\n",
    " 'lambda_l2': 6.704712390093808,\n",
    " 'bagging_fraction': 0.45,\n",
    " 'feature_fraction': 0.6,\n",
    " 'learning_rate': 0.0199,\n",
    " 'max_depth': 10,\n",
    " 'num_leaves': 790,\n",
    " 'min_child_samples': 65,\n",
    " 'min_data_in_leaf': 480,\n",
    " 'max_bin': 336,\n",
    " 'min_gain_to_split': 0.01084372652774491\n",
    "study.best_value\n",
    "-------lgbm3--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcb9248",
   "metadata": {},
   "source": [
    "## XGB-clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "286d913b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "def run(trial):\n",
    "    \n",
    "    fold = 0\n",
    "    \n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[features]\n",
    "    xvalid = xvalid[features]\n",
    "    xtest = xtest[features]\n",
    "    \n",
    "    param = {\n",
    "        \"metric\": \"auc\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\" : trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True),\n",
    "        \"reg_lambda\" : trial.suggest_loguniform(\"reg_lambda\", 1e-8, 100.0),\n",
    "        \"reg_alpha\" : trial.suggest_loguniform(\"reg_alpha\", 1e-8, 100.0),\n",
    "        \"subsample\" : trial.suggest_float(\"subsample\", 0.1, 1.0),\n",
    "        \"colsample_bytree\" : trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "        \"max_depth\" : trial.suggest_int(\"max_depth\", 1, 7),\n",
    "        \"min_child_weight\" : trial.suggest_int('min_child_weight', 1, 300),\n",
    "        \"n_estimators\":5000\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(**param, random_state=RANDOM_SEED)\n",
    "    model.fit(xtrain, ytrain,early_stopping_rounds=300,\n",
    "              eval_set=[(xvalid, yvalid)], verbose=False)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    \n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "c7b609d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 18:35:22,810]\u001b[0m A new study created in memory with name: no-name-ccece788-5e8f-47ff-984e-30688587c2da\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:35:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:35:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 18:37:23,459]\u001b[0m Trial 0 finished with value: 0.7752431516325402 and parameters: {'learning_rate': 0.09668052401418388, 'reg_lambda': 0.6462073184143035, 'reg_alpha': 22.120735382469068, 'subsample': 0.44796261053964315, 'colsample_bytree': 0.55192664979347, 'max_depth': 6, 'min_child_weight': 94}. Best is trial 0 with value: 0.7752431516325402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7752431516325402\n",
      "0 0.7752431516325402\n",
      "[18:37:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:37:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 18:38:27,196]\u001b[0m Trial 1 finished with value: 0.7588608536247925 and parameters: {'learning_rate': 0.24946374772051844, 'reg_lambda': 2.035752832138293e-08, 'reg_alpha': 32.22877474861862, 'subsample': 0.31437623466040654, 'colsample_bytree': 0.22388950409442837, 'max_depth': 4, 'min_child_weight': 256}. Best is trial 0 with value: 0.7752431516325402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7588608536247925\n",
      "0 0.7588608536247925\n",
      "[18:38:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:38:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 18:39:30,871]\u001b[0m Trial 2 finished with value: 0.7588729593248478 and parameters: {'learning_rate': 0.19545996912472344, 'reg_lambda': 0.03882793281413016, 'reg_alpha': 2.6283716745802477e-06, 'subsample': 0.20238051075006808, 'colsample_bytree': 0.4594524175131883, 'max_depth': 5, 'min_child_weight': 251}. Best is trial 0 with value: 0.7752431516325402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7588729593248478\n",
      "0 0.7588729593248478\n",
      "[18:39:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:39:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 18:41:39,259]\u001b[0m Trial 3 finished with value: 0.7704670206142779 and parameters: {'learning_rate': 0.09064338158557785, 'reg_lambda': 2.1848076623000325e-08, 'reg_alpha': 0.00015564622596007504, 'subsample': 0.5179797185726167, 'colsample_bytree': 0.19247499820048936, 'max_depth': 6, 'min_child_weight': 260}. Best is trial 0 with value: 0.7752431516325402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7704670206142779\n",
      "0 0.7704670206142779\n",
      "[18:41:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:41:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 18:46:40,427]\u001b[0m Trial 4 finished with value: 0.7720710258716104 and parameters: {'learning_rate': 0.024383990468708077, 'reg_lambda': 3.942047836071884e-05, 'reg_alpha': 0.014841735251123008, 'subsample': 0.3650875305955946, 'colsample_bytree': 0.23651080307018638, 'max_depth': 7, 'min_child_weight': 97}. Best is trial 0 with value: 0.7752431516325402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7720710258716104\n",
      "0 0.7720710258716104\n",
      "[18:46:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:46:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 18:47:30,602]\u001b[0m Trial 5 finished with value: 0.7761010998893193 and parameters: {'learning_rate': 0.16564258933246667, 'reg_lambda': 5.723734020550121, 'reg_alpha': 0.017922814807050838, 'subsample': 0.5788210789462006, 'colsample_bytree': 0.65375651630399, 'max_depth': 4, 'min_child_weight': 189}. Best is trial 5 with value: 0.7761010998893193.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7761010998893193\n",
      "0 0.7761010998893193\n",
      "[18:47:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:47:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 18:48:14,301]\u001b[0m Trial 6 finished with value: 0.7619979593248478 and parameters: {'learning_rate': 0.14374962937542743, 'reg_lambda': 15.244072698779918, 'reg_alpha': 0.0006293605048561572, 'subsample': 0.5198910382786428, 'colsample_bytree': 0.4152563122215662, 'max_depth': 1, 'min_child_weight': 166}. Best is trial 5 with value: 0.7761010998893193.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7619979593248478\n",
      "0 0.7619979593248478\n",
      "[18:48:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:48:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 18:49:13,679]\u001b[0m Trial 7 finished with value: 0.7784055063641394 and parameters: {'learning_rate': 0.11877801969878464, 'reg_lambda': 5.513261676761484, 'reg_alpha': 1.5044136137762456, 'subsample': 0.7589471245418602, 'colsample_bytree': 0.5239281712987259, 'max_depth': 3, 'min_child_weight': 175}. Best is trial 7 with value: 0.7784055063641394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7784055063641394\n",
      "0 0.7784055063641394\n",
      "[18:49:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:49:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 18:50:28,106]\u001b[0m Trial 8 finished with value: 0.7718513074156059 and parameters: {'learning_rate': 0.19325580804165557, 'reg_lambda': 0.2675181149154592, 'reg_alpha': 2.473175181068541e-05, 'subsample': 0.7656632115397043, 'colsample_bytree': 0.22674164483386977, 'max_depth': 6, 'min_child_weight': 206}. Best is trial 7 with value: 0.7784055063641394.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7718513074156059\n",
      "0 0.7718513074156059\n",
      "[18:50:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:50:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 18:53:51,434]\u001b[0m Trial 9 finished with value: 0.784625069175429 and parameters: {'learning_rate': 0.01098685543556639, 'reg_lambda': 0.0015620122636105737, 'reg_alpha': 0.1719093206502173, 'subsample': 0.4997703785123122, 'colsample_bytree': 0.9017632656309243, 'max_depth': 6, 'min_child_weight': 34}. Best is trial 9 with value: 0.784625069175429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.784625069175429\n",
      "0 0.784625069175429\n",
      "[18:53:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:53:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 18:56:45,613]\u001b[0m Trial 10 finished with value: 0.7829638212506917 and parameters: {'learning_rate': 0.01007958779551505, 'reg_lambda': 0.0001865843551650463, 'reg_alpha': 1.8779082593753425e-08, 'subsample': 0.9669558522604776, 'colsample_bytree': 0.967079504130207, 'max_depth': 2, 'min_child_weight': 3}. Best is trial 9 with value: 0.784625069175429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7829638212506917\n",
      "0 0.7829638212506917\n",
      "[18:56:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:56:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 18:59:58,395]\u001b[0m Trial 11 finished with value: 0.7737240592141671 and parameters: {'learning_rate': 0.01116949670725907, 'reg_lambda': 0.00020756485314975357, 'reg_alpha': 1.7645380567334508e-08, 'subsample': 0.9697026728031609, 'colsample_bytree': 0.9921095336476412, 'max_depth': 1, 'min_child_weight': 1}. Best is trial 9 with value: 0.784625069175429.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7737240592141671\n",
      "0 0.7737240592141671\n",
      "[18:59:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"boosting_type\", \"metric\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:59:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-402-7e59247beb2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"maximize\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    398\u001b[0m             )\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         _optimize(\n\u001b[0m\u001b[0;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             _optimize_sequential(\n\u001b[0m\u001b[0;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(trial)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1174\u001b[0m         )\n\u001b[0;32m   1175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m   1177\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m--> 189\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1500\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(run, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "5baebfb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01098685543556639,\n",
       " 'reg_lambda': 0.0015620122636105737,\n",
       " 'reg_alpha': 0.1719093206502173,\n",
       " 'subsample': 0.4997703785123122,\n",
       " 'colsample_bytree': 0.9017632656309243,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 34}"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826456e5",
   "metadata": {},
   "source": [
    "## CatBoost CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "9030a919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "def run(trial):\n",
    "    \n",
    "    fold = 0\n",
    "    \n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[features]\n",
    "    xvalid = xvalid[features]\n",
    "    xtest = xtest[features]\n",
    "    \n",
    "    param = {\n",
    "        'iterations' : trial.suggest_int('iterations', 50, 300),                         \n",
    "        'depth' : trial.suggest_int('depth', 4, 10),                                       \n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.01, 0.3),               \n",
    "        'random_strength' :trial.suggest_int('random_strength', 0, 100),                       \n",
    "        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
    "        'learning_rate' :trial.suggest_loguniform('learning_rate', 1e-3, 1e-1),\n",
    "        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter'])\n",
    "    }\n",
    "    \n",
    "    model = CatBoostClassifier(loss_function=\"Logloss\", eval_metric=\"AUC\",\n",
    "                               random_state=RANDOM_SEED, \n",
    "                               l2_leaf_reg=50,\n",
    "                                border_count=64,**param)\n",
    "    model.fit(xtrain, ytrain, verbose=False)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    \n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "f49625a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 20:29:13,516]\u001b[0m A new study created in memory with name: no-name-9754c668-a182-40e8-9147-fe4f720b7ed7\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:29:18,717]\u001b[0m Trial 0 finished with value: 0.7566117874930824 and parameters: {'iterations': 147, 'depth': 8, 'learning_rate': 0.016082576963111838, 'random_strength': 64, 'bagging_temperature': 0.053930669381946995, 'od_type': 'IncToDec'}. Best is trial 0 with value: 0.7566117874930824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7566117874930824\n",
      "0 0.7566117874930824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:29:23,803]\u001b[0m Trial 1 finished with value: 0.7788695005534035 and parameters: {'iterations': 185, 'depth': 6, 'learning_rate': 0.2045239919002807, 'random_strength': 68, 'bagging_temperature': 10.216660135999916, 'od_type': 'Iter'}. Best is trial 1 with value: 0.7788695005534035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7788695005534035\n",
      "0 0.7788695005534035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:29:34,538]\u001b[0m Trial 2 finished with value: 0.7861123408965136 and parameters: {'iterations': 266, 'depth': 5, 'learning_rate': 0.1533163416079515, 'random_strength': 96, 'bagging_temperature': 0.9517328269611176, 'od_type': 'Iter'}. Best is trial 2 with value: 0.7861123408965136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7861123408965136\n",
      "0 0.7861123408965136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:29:38,209]\u001b[0m Trial 3 finished with value: 0.7744417542888765 and parameters: {'iterations': 134, 'depth': 6, 'learning_rate': 0.08555762913895743, 'random_strength': 31, 'bagging_temperature': 0.1049759157794722, 'od_type': 'Iter'}. Best is trial 2 with value: 0.7861123408965136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7744417542888765\n",
      "0 0.7744417542888765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:29:51,853]\u001b[0m Trial 4 finished with value: 0.7829238724405092 and parameters: {'iterations': 296, 'depth': 8, 'learning_rate': 0.12100677834111039, 'random_strength': 47, 'bagging_temperature': 19.73717285775429, 'od_type': 'Iter'}. Best is trial 2 with value: 0.7861123408965136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7829238724405092\n",
      "0 0.7829238724405092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:29:53,773]\u001b[0m Trial 5 finished with value: 0.7683415190924183 and parameters: {'iterations': 61, 'depth': 6, 'learning_rate': 0.1527327284637028, 'random_strength': 47, 'bagging_temperature': 93.1945474784015, 'od_type': 'IncToDec'}. Best is trial 2 with value: 0.7861123408965136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7683415190924183\n",
      "0 0.7683415190924183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:29:57,909]\u001b[0m Trial 6 finished with value: 0.7603780437188711 and parameters: {'iterations': 123, 'depth': 7, 'learning_rate': 0.011912443333754073, 'random_strength': 50, 'bagging_temperature': 0.33699857031807445, 'od_type': 'IncToDec'}. Best is trial 2 with value: 0.7861123408965136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7603780437188711\n",
      "0 0.7603780437188711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:30:02,786]\u001b[0m Trial 7 finished with value: 0.760273934698395 and parameters: {'iterations': 198, 'depth': 4, 'learning_rate': 0.020368373016507117, 'random_strength': 57, 'bagging_temperature': 0.4108897068579252, 'od_type': 'Iter'}. Best is trial 2 with value: 0.7861123408965136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.760273934698395\n",
      "0 0.760273934698395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:30:14,328]\u001b[0m Trial 8 finished with value: 0.7831825885445489 and parameters: {'iterations': 279, 'depth': 4, 'learning_rate': 0.16123940869046954, 'random_strength': 82, 'bagging_temperature': 11.023248516945545, 'od_type': 'Iter'}. Best is trial 2 with value: 0.7861123408965136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7831825885445489\n",
      "0 0.7831825885445489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:30:19,447]\u001b[0m Trial 9 finished with value: 0.7734260860542336 and parameters: {'iterations': 99, 'depth': 10, 'learning_rate': 0.29767593820536414, 'random_strength': 25, 'bagging_temperature': 0.10965770837979033, 'od_type': 'IncToDec'}. Best is trial 2 with value: 0.7861123408965136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7734260860542336\n",
      "0 0.7734260860542336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:30:30,347]\u001b[0m Trial 10 finished with value: 0.7769052642501383 and parameters: {'iterations': 242, 'depth': 5, 'learning_rate': 0.04173538920031402, 'random_strength': 100, 'bagging_temperature': 0.01048464683247728, 'od_type': 'Iter'}. Best is trial 2 with value: 0.7861123408965136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7769052642501383\n",
      "0 0.7769052642501383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:30:40,939]\u001b[0m Trial 11 finished with value: 0.7811322288323187 and parameters: {'iterations': 288, 'depth': 4, 'learning_rate': 0.05117591817311378, 'random_strength': 100, 'bagging_temperature': 2.910115889932153, 'od_type': 'Iter'}. Best is trial 2 with value: 0.7861123408965136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7811322288323187\n",
      "0 0.7811322288323187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:30:49,895]\u001b[0m Trial 12 finished with value: 0.7837475788599889 and parameters: {'iterations': 246, 'depth': 4, 'learning_rate': 0.08751221415484461, 'random_strength': 81, 'bagging_temperature': 2.1865535218086483, 'od_type': 'Iter'}. Best is trial 2 with value: 0.7861123408965136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7837475788599889\n",
      "0 0.7837475788599889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:30:58,892]\u001b[0m Trial 13 finished with value: 0.7842105354178195 and parameters: {'iterations': 234, 'depth': 5, 'learning_rate': 0.07800414978370385, 'random_strength': 83, 'bagging_temperature': 2.2527990419996655, 'od_type': 'Iter'}. Best is trial 2 with value: 0.7861123408965136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7842105354178195\n",
      "0 0.7842105354178195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:31:07,492]\u001b[0m Trial 14 finished with value: 0.7806723851687881 and parameters: {'iterations': 226, 'depth': 5, 'learning_rate': 0.0371630907784813, 'random_strength': 7, 'bagging_temperature': 0.9670950487717677, 'od_type': 'Iter'}. Best is trial 2 with value: 0.7861123408965136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7806723851687881\n",
      "0 0.7806723851687881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:31:15,793]\u001b[0m Trial 15 finished with value: 0.7849057484781405 and parameters: {'iterations': 214, 'depth': 5, 'learning_rate': 0.0788687875279611, 'random_strength': 84, 'bagging_temperature': 2.7783621525516438, 'od_type': 'Iter'}. Best is trial 2 with value: 0.7861123408965136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7849057484781405\n",
      "0 0.7849057484781405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:31:24,603]\u001b[0m Trial 16 finished with value: 0.7704235265633647 and parameters: {'iterations': 206, 'depth': 7, 'learning_rate': 0.23866707995762573, 'random_strength': 94, 'bagging_temperature': 0.5314110481692325, 'od_type': 'Iter'}. Best is trial 2 with value: 0.7861123408965136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7704235265633647\n",
      "0 0.7704235265633647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:31:33,028]\u001b[0m Trial 17 finished with value: 0.7647234712230215 and parameters: {'iterations': 167, 'depth': 10, 'learning_rate': 0.031077982381917266, 'random_strength': 74, 'bagging_temperature': 4.490981896516533, 'od_type': 'Iter'}. Best is trial 2 with value: 0.7861123408965136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7647234712230215\n",
      "0 0.7647234712230215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:31:43,227]\u001b[0m Trial 18 finished with value: 0.7791290813503043 and parameters: {'iterations': 265, 'depth': 5, 'learning_rate': 0.069005768935867, 'random_strength': 89, 'bagging_temperature': 76.39266467731703, 'od_type': 'IncToDec'}. Best is trial 2 with value: 0.7861123408965136.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7791290813503043\n",
      "0 0.7791290813503043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:31:51,966]\u001b[0m Trial 19 finished with value: 0.7862017501383508 and parameters: {'iterations': 217, 'depth': 6, 'learning_rate': 0.1213430003408006, 'random_strength': 73, 'bagging_temperature': 28.242476358725117, 'od_type': 'Iter'}. Best is trial 19 with value: 0.7862017501383508.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7862017501383508\n",
      "0 0.7862017501383508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:32:03,711]\u001b[0m Trial 20 finished with value: 0.7786650871610404 and parameters: {'iterations': 260, 'depth': 7, 'learning_rate': 0.12172727305504992, 'random_strength': 70, 'bagging_temperature': 28.79139236094219, 'od_type': 'Iter'}. Best is trial 19 with value: 0.7862017501383508.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7786650871610404\n",
      "0 0.7786650871610404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:32:13,424]\u001b[0m Trial 21 finished with value: 0.785808833702269 and parameters: {'iterations': 212, 'depth': 6, 'learning_rate': 0.11337771582154532, 'random_strength': 88, 'bagging_temperature': 6.568658883899012, 'od_type': 'Iter'}. Best is trial 19 with value: 0.7862017501383508.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.785808833702269\n",
      "0 0.785808833702269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:32:18,553]\u001b[0m Trial 22 finished with value: 0.7779603624792474 and parameters: {'iterations': 172, 'depth': 6, 'learning_rate': 0.11940229167741082, 'random_strength': 93, 'bagging_temperature': 35.579988951608534, 'od_type': 'Iter'}. Best is trial 19 with value: 0.7862017501383508.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7779603624792474\n",
      "0 0.7779603624792474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:32:31,764]\u001b[0m Trial 23 finished with value: 0.7869268815716657 and parameters: {'iterations': 260, 'depth': 8, 'learning_rate': 0.17572035142788606, 'random_strength': 78, 'bagging_temperature': 12.79633128785124, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7869268815716657\n",
      "0 0.7869268815716657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:32:46,945]\u001b[0m Trial 24 finished with value: 0.7820576231322633 and parameters: {'iterations': 264, 'depth': 9, 'learning_rate': 0.18118084389945116, 'random_strength': 74, 'bagging_temperature': 1.119658775971422, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7820576231322633\n",
      "0 0.7820576231322633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:33:00,250]\u001b[0m Trial 25 finished with value: 0.768523450470393 and parameters: {'iterations': 256, 'depth': 8, 'learning_rate': 0.270941397497614, 'random_strength': 61, 'bagging_temperature': 18.403815147469633, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.768523450470393\n",
      "0 0.768523450470393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:33:17,206]\u001b[0m Trial 26 finished with value: 0.77237998063088 and parameters: {'iterations': 278, 'depth': 9, 'learning_rate': 0.20766169364991113, 'random_strength': 78, 'bagging_temperature': 39.20781457245999, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.77237998063088\n",
      "0 0.77237998063088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:33:28,468]\u001b[0m Trial 27 finished with value: 0.7801023796347537 and parameters: {'iterations': 227, 'depth': 7, 'learning_rate': 0.14890582942452094, 'random_strength': 57, 'bagging_temperature': 7.873598866178855, 'od_type': 'IncToDec'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7801023796347537\n",
      "0 0.7801023796347537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:33:45,313]\u001b[0m Trial 28 finished with value: 0.7763362963475374 and parameters: {'iterations': 298, 'depth': 9, 'learning_rate': 0.060270303608500206, 'random_strength': 94, 'bagging_temperature': 1.1341916484257528, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7763362963475374\n",
      "0 0.7763362963475374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:33:51,330]\u001b[0m Trial 29 finished with value: 0.7753441477587161 and parameters: {'iterations': 191, 'depth': 8, 'learning_rate': 0.09329297341486929, 'random_strength': 65, 'bagging_temperature': 0.23877521648679392, 'od_type': 'IncToDec'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7753441477587161\n",
      "0 0.7753441477587161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:34:02,262]\u001b[0m Trial 30 finished with value: 0.7775906198118429 and parameters: {'iterations': 248, 'depth': 7, 'learning_rate': 0.2325826462436922, 'random_strength': 35, 'bagging_temperature': 0.03079280576044172, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7775906198118429\n",
      "0 0.7775906198118429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:34:11,442]\u001b[0m Trial 31 finished with value: 0.78387313226342 and parameters: {'iterations': 220, 'depth': 6, 'learning_rate': 0.11374766095770715, 'random_strength': 89, 'bagging_temperature': 6.111199535315264, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.78387313226342\n",
      "0 0.78387313226342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:34:15,690]\u001b[0m Trial 32 finished with value: 0.7768174114554509 and parameters: {'iterations': 155, 'depth': 6, 'learning_rate': 0.14013915789723924, 'random_strength': 88, 'bagging_temperature': 11.649616166488011, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7768174114554509\n",
      "0 0.7768174114554509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:34:20,621]\u001b[0m Trial 33 finished with value: 0.7740993359158826 and parameters: {'iterations': 184, 'depth': 6, 'learning_rate': 0.10465989762693059, 'random_strength': 72, 'bagging_temperature': 4.7941317473002245, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7740993359158826\n",
      "0 0.7740993359158826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:34:31,144]\u001b[0m Trial 34 finished with value: 0.7830594562811288 and parameters: {'iterations': 275, 'depth': 5, 'learning_rate': 0.19263366075246563, 'random_strength': 77, 'bagging_temperature': 17.761687838843816, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7830594562811288\n",
      "0 0.7830594562811288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:34:40,283]\u001b[0m Trial 35 finished with value: 0.7778432830658549 and parameters: {'iterations': 208, 'depth': 7, 'learning_rate': 0.137884160061866, 'random_strength': 67, 'bagging_temperature': 48.004482230652236, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7778432830658549\n",
      "0 0.7778432830658549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:34:51,403]\u001b[0m Trial 36 finished with value: 0.7852428057553956 and parameters: {'iterations': 235, 'depth': 8, 'learning_rate': 0.17819422376132135, 'random_strength': 96, 'bagging_temperature': 14.048187914692098, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7852428057553956\n",
      "0 0.7852428057553956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:34:53,014]\u001b[0m Trial 37 finished with value: 0.7675295724958494 and parameters: {'iterations': 53, 'depth': 6, 'learning_rate': 0.0968237469831316, 'random_strength': 87, 'bagging_temperature': 24.807989374134863, 'od_type': 'IncToDec'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7675295724958494\n",
      "0 0.7675295724958494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:34:58,264]\u001b[0m Trial 38 finished with value: 0.7794286109573878 and parameters: {'iterations': 197, 'depth': 6, 'learning_rate': 0.23655105540564397, 'random_strength': 52, 'bagging_temperature': 0.7195907926736084, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7794286109573878\n",
      "0 0.7794286109573878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:35:07,829]\u001b[0m Trial 39 finished with value: 0.7848327684006642 and parameters: {'iterations': 249, 'depth': 5, 'learning_rate': 0.16131509968939728, 'random_strength': 78, 'bagging_temperature': 0.24503652555008157, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7848327684006642\n",
      "0 0.7848327684006642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:35:12,011]\u001b[0m Trial 40 finished with value: 0.7607813364692861 and parameters: {'iterations': 136, 'depth': 7, 'learning_rate': 0.010543515748027884, 'random_strength': 62, 'bagging_temperature': 57.693149817766276, 'od_type': 'IncToDec'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7607813364692861\n",
      "0 0.7607813364692861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:35:22,747]\u001b[0m Trial 41 finished with value: 0.7848640702822357 and parameters: {'iterations': 228, 'depth': 8, 'learning_rate': 0.1797336184746816, 'random_strength': 100, 'bagging_temperature': 13.005559683555463, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7848640702822357\n",
      "0 0.7848640702822357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:35:34,013]\u001b[0m Trial 42 finished with value: 0.7802173837852796 and parameters: {'iterations': 237, 'depth': 8, 'learning_rate': 0.13801711446559836, 'random_strength': 94, 'bagging_temperature': 7.333117693087884, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7802173837852796\n",
      "0 0.7802173837852796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:35:47,483]\u001b[0m Trial 43 finished with value: 0.775138869673492 and parameters: {'iterations': 286, 'depth': 8, 'learning_rate': 0.21185413993200422, 'random_strength': 97, 'bagging_temperature': 1.5255041698180385, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.775138869673492\n",
      "0 0.775138869673492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:35:58,647]\u001b[0m Trial 44 finished with value: 0.7814630603209738 and parameters: {'iterations': 213, 'depth': 9, 'learning_rate': 0.1696714002321269, 'random_strength': 40, 'bagging_temperature': 4.052756628784164, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7814630603209738\n",
      "0 0.7814630603209738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:36:01,019]\u001b[0m Trial 45 finished with value: 0.7591794064748202 and parameters: {'iterations': 80, 'depth': 6, 'learning_rate': 0.021820687914084747, 'random_strength': 83, 'bagging_temperature': 12.987181701515755, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7591794064748202\n",
      "0 0.7591794064748202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:36:14,005]\u001b[0m Trial 46 finished with value: 0.771429164360819 and parameters: {'iterations': 273, 'depth': 8, 'learning_rate': 0.29680697515716165, 'random_strength': 91, 'bagging_temperature': 20.577660842154373, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.771429164360819\n",
      "0 0.771429164360819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:36:23,974]\u001b[0m Trial 47 finished with value: 0.7867387244050914 and parameters: {'iterations': 238, 'depth': 4, 'learning_rate': 0.12332344696494303, 'random_strength': 20, 'bagging_temperature': 74.61375444473813, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7867387244050914\n",
      "0 0.7867387244050914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:36:33,735]\u001b[0m Trial 48 finished with value: 0.7827566408411732 and parameters: {'iterations': 255, 'depth': 4, 'learning_rate': 0.06395251926477732, 'random_strength': 15, 'bagging_temperature': 88.4070035702315, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7827566408411732\n",
      "0 0.7827566408411732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\optuna\\trial\\_trial.py:772: RuntimeWarning: Inconsistent parameter values for distribution with name \"learning_rate\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more then once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'low': 0.01, 'high': 0.3}\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-02-03 20:36:41,753]\u001b[0m Trial 49 finished with value: 0.782461434698395 and parameters: {'iterations': 202, 'depth': 4, 'learning_rate': 0.08065317628310259, 'random_strength': 23, 'bagging_temperature': 56.6701028257206, 'od_type': 'Iter'}. Best is trial 23 with value: 0.7869268815716657.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.782461434698395\n",
      "0 0.782461434698395\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(run, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "0b32aa70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 260,\n",
       " 'depth': 8,\n",
       " 'learning_rate': 0.17572035142788606,\n",
       " 'random_strength': 78,\n",
       " 'bagging_temperature': 12.79633128785124,\n",
       " 'od_type': 'Iter'}"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "634f26d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7869268815716657"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e7dcfa",
   "metadata": {},
   "source": [
    "## LGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "ba37d8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.99 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "def run(trial):\n",
    "    fold = 0\n",
    "    \n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[features]\n",
    "    xvalid = xvalid[features]\n",
    "    xtest = xtest[features]\n",
    "    \n",
    "    param = {\n",
    "        \"task\": \"train\",\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\" : trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"n_estimators\":5000\n",
    "    }\n",
    "\n",
    "    lgb_train = lgb.Dataset(xtrain, ytrain)\n",
    "    lgb_val = lgb.Dataset(xvalid, yvalid)\n",
    "    \n",
    "    model = lgb.train(params=param,\n",
    "                      train_set=lgb_train,\n",
    "                      valid_sets=lgb_val,\n",
    "                      early_stopping_rounds=300,\n",
    "                      verbose_eval=False)\n",
    "   \n",
    "    preds_valid = model.predict(xvalid,num_iteration=model.best_iteration)\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "3294dac5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 20:48:38,215]\u001b[0m A new study created in memory with name: no-name-77091a5e-186a-4d6e-bc22-570b2a7aaeb6\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:48:42,411]\u001b[0m Trial 0 finished with value: 0.7597064367736581 and parameters: {'learning_rate': 0.18412918974853412, 'lambda_l1': 1.1030867205789016e-08, 'lambda_l2': 1.2780032841046625e-05, 'num_leaves': 176, 'feature_fraction': 0.585685675064665, 'bagging_fraction': 0.6434823877931792, 'bagging_freq': 4, 'min_child_samples': 47}. Best is trial 0 with value: 0.7597064367736581.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:48:45,845]\u001b[0m Trial 1 finished with value: 0.7822996506640841 and parameters: {'learning_rate': 0.13510884885226923, 'lambda_l1': 9.255901161069887e-07, 'lambda_l2': 6.974099160925693e-05, 'num_leaves': 11, 'feature_fraction': 0.5552484745172787, 'bagging_fraction': 0.9568162211276423, 'bagging_freq': 1, 'min_child_samples': 37}. Best is trial 1 with value: 0.7822996506640841.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:48:54,349]\u001b[0m Trial 2 finished with value: 0.7867951023796347 and parameters: {'learning_rate': 0.010966228288330509, 'lambda_l1': 3.879485703654771, 'lambda_l2': 0.2381124584030539, 'num_leaves': 114, 'feature_fraction': 0.6018273896232029, 'bagging_fraction': 0.7540383892726186, 'bagging_freq': 7, 'min_child_samples': 34}. Best is trial 2 with value: 0.7867951023796347.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:49:00,178]\u001b[0m Trial 3 finished with value: 0.7827609643054787 and parameters: {'learning_rate': 0.014617927068747096, 'lambda_l1': 3.1166028656004285, 'lambda_l2': 2.47316236123986, 'num_leaves': 92, 'feature_fraction': 0.5231021942129004, 'bagging_fraction': 0.5153674587750156, 'bagging_freq': 3, 'min_child_samples': 35}. Best is trial 2 with value: 0.7867951023796347.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:49:07,574]\u001b[0m Trial 4 finished with value: 0.7835111718317653 and parameters: {'learning_rate': 0.010192493558223307, 'lambda_l1': 2.498396698537415, 'lambda_l2': 2.877826745892425e-07, 'num_leaves': 22, 'feature_fraction': 0.982117398083047, 'bagging_fraction': 0.5186464652889096, 'bagging_freq': 2, 'min_child_samples': 55}. Best is trial 2 with value: 0.7867951023796347.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:49:13,004]\u001b[0m Trial 5 finished with value: 0.7845239865799667 and parameters: {'learning_rate': 0.015735666225025677, 'lambda_l1': 0.0003386312629237174, 'lambda_l2': 0.002861681653300304, 'num_leaves': 133, 'feature_fraction': 0.5750523905229206, 'bagging_fraction': 0.5595937487849025, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 2 with value: 0.7867951023796347.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:49:17,716]\u001b[0m Trial 6 finished with value: 0.7741309836745988 and parameters: {'learning_rate': 0.022086079835869632, 'lambda_l1': 3.2800833389840144e-08, 'lambda_l2': 0.1829205201399678, 'num_leaves': 93, 'feature_fraction': 0.9956652233001813, 'bagging_fraction': 0.7492638034608459, 'bagging_freq': 6, 'min_child_samples': 100}. Best is trial 2 with value: 0.7867951023796347.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:49:23,058]\u001b[0m Trial 7 finished with value: 0.7625784276425014 and parameters: {'learning_rate': 0.04414587862742827, 'lambda_l1': 0.059072188239491924, 'lambda_l2': 1.0058747428745602, 'num_leaves': 235, 'feature_fraction': 0.7538218647500761, 'bagging_fraction': 0.41804762364532405, 'bagging_freq': 7, 'min_child_samples': 64}. Best is trial 2 with value: 0.7867951023796347.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:49:28,082]\u001b[0m Trial 8 finished with value: 0.7885278604039845 and parameters: {'learning_rate': 0.056182775174670053, 'lambda_l1': 5.13363971010253, 'lambda_l2': 1.6411558828427315e-05, 'num_leaves': 97, 'feature_fraction': 0.4883168720237154, 'bagging_fraction': 0.983759232893938, 'bagging_freq': 5, 'min_child_samples': 57}. Best is trial 8 with value: 0.7885278604039845.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:49:34,298]\u001b[0m Trial 9 finished with value: 0.776915294687327 and parameters: {'learning_rate': 0.045553075439751414, 'lambda_l1': 3.6023901503635156e-07, 'lambda_l2': 0.004781895762065417, 'num_leaves': 195, 'feature_fraction': 0.8785646071617095, 'bagging_fraction': 0.7321350453186053, 'bagging_freq': 2, 'min_child_samples': 99}. Best is trial 8 with value: 0.7885278604039845.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:49:39,217]\u001b[0m Trial 10 finished with value: 0.7902784311012728 and parameters: {'learning_rate': 0.09266997555541794, 'lambda_l1': 0.0015560701338796564, 'lambda_l2': 1.3634176566586327e-08, 'num_leaves': 55, 'feature_fraction': 0.40341319606061765, 'bagging_fraction': 0.9646079596589896, 'bagging_freq': 5, 'min_child_samples': 77}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:49:43,492]\u001b[0m Trial 11 finished with value: 0.7846146063918097 and parameters: {'learning_rate': 0.09009089321293524, 'lambda_l1': 0.0023124042261390737, 'lambda_l2': 1.0599949557255633e-08, 'num_leaves': 48, 'feature_fraction': 0.404744498684143, 'bagging_fraction': 0.9822222833555609, 'bagging_freq': 5, 'min_child_samples': 73}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:49:46,941]\u001b[0m Trial 12 finished with value: 0.7885827684006641 and parameters: {'learning_rate': 0.07677317228937387, 'lambda_l1': 0.05517809193919155, 'lambda_l2': 9.873153795150547e-07, 'num_leaves': 69, 'feature_fraction': 0.4149491047270566, 'bagging_fraction': 0.8561344562705469, 'bagging_freq': 5, 'min_child_samples': 81}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:49:50,410]\u001b[0m Trial 13 finished with value: 0.7882661178749308 and parameters: {'learning_rate': 0.06967164357708935, 'lambda_l1': 0.030076481363161284, 'lambda_l2': 1.335742819182237e-07, 'num_leaves': 58, 'feature_fraction': 0.4075581193305498, 'bagging_fraction': 0.8721695361104708, 'bagging_freq': 4, 'min_child_samples': 81}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:49:53,491]\u001b[0m Trial 14 finished with value: 0.7837813018815717 and parameters: {'learning_rate': 0.1122751480595531, 'lambda_l1': 1.469523176796991e-05, 'lambda_l2': 8.517726559822994e-07, 'num_leaves': 55, 'feature_fraction': 0.6670634517925305, 'bagging_fraction': 0.8650492394384708, 'bagging_freq': 6, 'min_child_samples': 82}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:49:57,462]\u001b[0m Trial 15 finished with value: 0.7765185736026563 and parameters: {'learning_rate': 0.21530115638701708, 'lambda_l1': 0.032195174773576016, 'lambda_l2': 1.290766936818381e-08, 'num_leaves': 149, 'feature_fraction': 0.45920708786543846, 'bagging_fraction': 0.8599139880711583, 'bagging_freq': 6, 'min_child_samples': 78}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:50:04,448]\u001b[0m Trial 16 finished with value: 0.7865918995572773 and parameters: {'learning_rate': 0.030187450004483918, 'lambda_l1': 0.0019369160914486329, 'lambda_l2': 1.8660990218099314e-06, 'num_leaves': 67, 'feature_fraction': 0.721084569350319, 'bagging_fraction': 0.8134223086484205, 'bagging_freq': 3, 'min_child_samples': 89}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:50:09,001]\u001b[0m Trial 17 finished with value: 0.785385047731046 and parameters: {'learning_rate': 0.08233635077195864, 'lambda_l1': 3.09294834338134e-05, 'lambda_l2': 7.303325800416748e-08, 'num_leaves': 31, 'feature_fraction': 0.8024732914920997, 'bagging_fraction': 0.9111725863617103, 'bagging_freq': 5, 'min_child_samples': 67}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:50:13,446]\u001b[0m Trial 18 finished with value: 0.7808493013281683 and parameters: {'learning_rate': 0.14256787997062212, 'lambda_l1': 0.2922342768279733, 'lambda_l2': 4.922669730900417e-06, 'num_leaves': 77, 'feature_fraction': 0.6634239930907944, 'bagging_fraction': 0.8213507670728333, 'bagging_freq': 4, 'min_child_samples': 90}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:50:19,738]\u001b[0m Trial 19 finished with value: 0.7901163011898173 and parameters: {'learning_rate': 0.037033891229212676, 'lambda_l1': 0.004403564539705765, 'lambda_l2': 0.0005802916172102611, 'num_leaves': 154, 'feature_fraction': 0.46117277147460267, 'bagging_fraction': 0.66222279438523, 'bagging_freq': 3, 'min_child_samples': 66}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:50:25,596]\u001b[0m Trial 20 finished with value: 0.7799357533204205 and parameters: {'learning_rate': 0.02560745382202091, 'lambda_l1': 0.002302453567557823, 'lambda_l2': 0.0011512460184543135, 'num_leaves': 166, 'feature_fraction': 0.48925811993363155, 'bagging_fraction': 0.6514645070081231, 'bagging_freq': 3, 'min_child_samples': 45}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:50:32,259]\u001b[0m Trial 21 finished with value: 0.7880860888212506 and parameters: {'learning_rate': 0.035284329763549005, 'lambda_l1': 0.00012809009979930297, 'lambda_l2': 0.00031825920121615267, 'num_leaves': 209, 'feature_fraction': 0.44424784087485647, 'bagging_fraction': 0.6401744171189697, 'bagging_freq': 3, 'min_child_samples': 67}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:50:37,652]\u001b[0m Trial 22 finished with value: 0.7864549322080796 and parameters: {'learning_rate': 0.07544995373955117, 'lambda_l1': 0.1736222897155434, 'lambda_l2': 0.030310071611106656, 'num_leaves': 119, 'feature_fraction': 0.4032369756662357, 'bagging_fraction': 0.9266819873056968, 'bagging_freq': 4, 'min_child_samples': 89}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:50:44,026]\u001b[0m Trial 23 finished with value: 0.782256934836746 and parameters: {'learning_rate': 0.051648029444989994, 'lambda_l1': 0.005147160039400718, 'lambda_l2': 5.107577720995323e-05, 'num_leaves': 142, 'feature_fraction': 0.5076858122170521, 'bagging_fraction': 0.8042213384243586, 'bagging_freq': 2, 'min_child_samples': 73}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:50:47,933]\u001b[0m Trial 24 finished with value: 0.7768287389319314 and parameters: {'learning_rate': 0.1085880548747787, 'lambda_l1': 0.0003810516675811711, 'lambda_l2': 6.633305360671085e-08, 'num_leaves': 4, 'feature_fraction': 0.4719849623884287, 'bagging_fraction': 0.5951565896928757, 'bagging_freq': 6, 'min_child_samples': 59}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:50:52,658]\u001b[0m Trial 25 finished with value: 0.7875511033480909 and parameters: {'learning_rate': 0.06144364966518722, 'lambda_l1': 0.011242049501958978, 'lambda_l2': 0.0002737920062752543, 'num_leaves': 36, 'feature_fraction': 0.4434757242937686, 'bagging_fraction': 0.6861994322055842, 'bagging_freq': 5, 'min_child_samples': 72}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:50:59,684]\u001b[0m Trial 26 finished with value: 0.785071077753182 and parameters: {'learning_rate': 0.03279407740466422, 'lambda_l1': 0.1953379310731571, 'lambda_l2': 3.7906852158908664e-07, 'num_leaves': 77, 'feature_fraction': 0.6221107125551192, 'bagging_fraction': 0.9131037814711634, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:51:05,452]\u001b[0m Trial 27 finished with value: 0.7870630706972883 and parameters: {'learning_rate': 0.0389642404571328, 'lambda_l1': 0.574138078450331, 'lambda_l2': 3.1461281163221674e-08, 'num_leaves': 154, 'feature_fraction': 0.4426532731035343, 'bagging_fraction': 0.7061893529436527, 'bagging_freq': 4, 'min_child_samples': 85}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:51:10,364]\u001b[0m Trial 28 finished with value: 0.7801848713337023 and parameters: {'learning_rate': 0.09846625770742673, 'lambda_l1': 3.4562920994811e-05, 'lambda_l2': 2.2461113691732416e-06, 'num_leaves': 106, 'feature_fraction': 0.5450255307121286, 'bagging_fraction': 0.9482862408859335, 'bagging_freq': 5, 'min_child_samples': 95}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:51:15,567]\u001b[0m Trial 29 finished with value: 0.7665916401494189 and parameters: {'learning_rate': 0.17081420105878933, 'lambda_l1': 0.0005501858492210473, 'lambda_l2': 1.420016597411894e-05, 'num_leaves': 183, 'feature_fraction': 0.5310516666681978, 'bagging_fraction': 0.7813605699938451, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:51:21,543]\u001b[0m Trial 30 finished with value: 0.75665874031544 and parameters: {'learning_rate': 0.2395727669362543, 'lambda_l1': 0.009652426114273225, 'lambda_l2': 5.437494059110717e-05, 'num_leaves': 240, 'feature_fraction': 0.40171291945813675, 'bagging_fraction': 0.8597132019400913, 'bagging_freq': 3, 'min_child_samples': 62}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:51:28,074]\u001b[0m Trial 31 finished with value: 0.7867082872163808 and parameters: {'learning_rate': 0.0580892046420075, 'lambda_l1': 7.69406071782864, 'lambda_l2': 1.2268311694072081e-05, 'num_leaves': 92, 'feature_fraction': 0.4914860752341049, 'bagging_fraction': 0.9678199013863591, 'bagging_freq': 5, 'min_child_samples': 56}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:51:32,795]\u001b[0m Trial 32 finished with value: 0.7864155886828998 and parameters: {'learning_rate': 0.06320110258741705, 'lambda_l1': 0.052834034875315475, 'lambda_l2': 1.3220281711346974e-05, 'num_leaves': 104, 'feature_fraction': 0.4703874967396322, 'bagging_fraction': 0.9740195793764472, 'bagging_freq': 6, 'min_child_samples': 45}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:51:37,447]\u001b[0m Trial 33 finished with value: 0.7844055236579968 and parameters: {'learning_rate': 0.13528766332452283, 'lambda_l1': 1.2833516600597605, 'lambda_l2': 0.00021375493711270783, 'num_leaves': 129, 'feature_fraction': 0.5699054854013847, 'bagging_fraction': 0.9934315620163643, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:51:42,459]\u001b[0m Trial 34 finished with value: 0.7867839478417267 and parameters: {'learning_rate': 0.04699543810841791, 'lambda_l1': 0.9299895619458869, 'lambda_l2': 0.026497845022838692, 'num_leaves': 80, 'feature_fraction': 0.6201211611475956, 'bagging_fraction': 0.8999340855564336, 'bagging_freq': 7, 'min_child_samples': 73}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:51:50,206]\u001b[0m Trial 35 finished with value: 0.7878277185943552 and parameters: {'learning_rate': 0.02165310180019464, 'lambda_l1': 2.4621758626005208e-06, 'lambda_l2': 3.5435404394005077e-07, 'num_leaves': 44, 'feature_fraction': 0.5189604990043415, 'bagging_fraction': 0.9407655523621319, 'bagging_freq': 4, 'min_child_samples': 77}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:51:52,956]\u001b[0m Trial 36 finished with value: 0.7812667750415052 and parameters: {'learning_rate': 0.0774793570466315, 'lambda_l1': 0.0010111825044953958, 'lambda_l2': 0.0009460312569742606, 'num_leaves': 20, 'feature_fraction': 0.4406892222412717, 'bagging_fraction': 0.6057587460666726, 'bagging_freq': 6, 'min_child_samples': 53}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:52:01,382]\u001b[0m Trial 37 finished with value: 0.7868318518262313 and parameters: {'learning_rate': 0.05444744174027159, 'lambda_l1': 8.662521832540529, 'lambda_l2': 8.676597198823511e-05, 'num_leaves': 122, 'feature_fraction': 0.5959361830581975, 'bagging_fraction': 0.9954012974619716, 'bagging_freq': 5, 'min_child_samples': 68}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:52:04,371]\u001b[0m Trial 38 finished with value: 0.7831389215550636 and parameters: {'learning_rate': 0.12308785557671786, 'lambda_l1': 0.011169113224700088, 'lambda_l2': 4.326253627202368e-06, 'num_leaves': 66, 'feature_fraction': 0.548104095103449, 'bagging_fraction': 0.40508161208553073, 'bagging_freq': 4, 'min_child_samples': 39}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:52:08,972]\u001b[0m Trial 39 finished with value: 0.7807697495849474 and parameters: {'learning_rate': 0.16120253383679212, 'lambda_l1': 0.11277742937385415, 'lambda_l2': 6.850696768519903e-07, 'num_leaves': 94, 'feature_fraction': 0.9120450773207973, 'bagging_fraction': 0.88686095213242, 'bagging_freq': 7, 'min_child_samples': 62}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:52:16,245]\u001b[0m Trial 40 finished with value: 0.7846112340896514 and parameters: {'learning_rate': 0.04097269778288491, 'lambda_l1': 0.00017636597255851394, 'lambda_l2': 0.018394895605950787, 'num_leaves': 164, 'feature_fraction': 0.42568571058763777, 'bagging_fraction': 0.46615689617271466, 'bagging_freq': 2, 'min_child_samples': 58}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:52:20,930]\u001b[0m Trial 41 finished with value: 0.7878453583287216 and parameters: {'learning_rate': 0.06910357586059707, 'lambda_l1': 0.022673639203906006, 'lambda_l2': 5.9138334226471607e-08, 'num_leaves': 59, 'feature_fraction': 0.4221720974740983, 'bagging_fraction': 0.8439720117924445, 'bagging_freq': 4, 'min_child_samples': 81}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:52:24,701]\u001b[0m Trial 42 finished with value: 0.7820618601272827 and parameters: {'learning_rate': 0.09915888277725703, 'lambda_l1': 0.004272736693139152, 'lambda_l2': 1.642780861153546e-07, 'num_leaves': 40, 'feature_fraction': 0.4799834151255273, 'bagging_fraction': 0.78424685131546, 'bagging_freq': 3, 'min_child_samples': 84}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:52:28,828]\u001b[0m Trial 43 finished with value: 0.7888779745434422 and parameters: {'learning_rate': 0.0851359826842344, 'lambda_l1': 0.02133416970720175, 'lambda_l2': 1.5979996778798006e-07, 'num_leaves': 82, 'feature_fraction': 0.49567041515849086, 'bagging_fraction': 0.7331035967299281, 'bagging_freq': 4, 'min_child_samples': 77}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:52:33,823]\u001b[0m Trial 44 finished with value: 0.7827110715273936 and parameters: {'learning_rate': 0.09209349042626193, 'lambda_l1': 2.696382414412184, 'lambda_l2': 2.0379638822747065e-08, 'num_leaves': 92, 'feature_fraction': 0.4939638249541746, 'bagging_fraction': 0.7371128109144133, 'bagging_freq': 5, 'min_child_samples': 77}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:52:38,347]\u001b[0m Trial 45 finished with value: 0.7751582387935806 and parameters: {'learning_rate': 0.08281177230123571, 'lambda_l1': 0.001238746011493135, 'lambda_l2': 1.327612551312649e-06, 'num_leaves': 107, 'feature_fraction': 0.5095060773176917, 'bagging_fraction': 0.694217890918429, 'bagging_freq': 6, 'min_child_samples': 67}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:52:45,151]\u001b[0m Trial 46 finished with value: 0.789345773381295 and parameters: {'learning_rate': 0.014185637692494996, 'lambda_l1': 0.08055741959697392, 'lambda_l2': 1.57592941139288e-07, 'num_leaves': 139, 'feature_fraction': 0.46112352829108055, 'bagging_fraction': 0.5407023591020581, 'bagging_freq': 5, 'min_child_samples': 94}. Best is trial 10 with value: 0.7902784311012728.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:52:53,967]\u001b[0m Trial 47 finished with value: 0.7924220047039292 and parameters: {'learning_rate': 0.01243326765467829, 'lambda_l1': 0.44583405781585317, 'lambda_l2': 1.945205216342612e-07, 'num_leaves': 135, 'feature_fraction': 0.45977662840830263, 'bagging_fraction': 0.5398639147101038, 'bagging_freq': 4, 'min_child_samples': 95}. Best is trial 47 with value: 0.7924220047039292.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:53:03,141]\u001b[0m Trial 48 finished with value: 0.7894863724405092 and parameters: {'learning_rate': 0.012241546682651793, 'lambda_l1': 0.4417675932392804, 'lambda_l2': 3.3646207040494586e-08, 'num_leaves': 193, 'feature_fraction': 0.45938248069524235, 'bagging_fraction': 0.5305610670117422, 'bagging_freq': 3, 'min_child_samples': 95}. Best is trial 47 with value: 0.7924220047039292.\u001b[0m\n",
      "C:\\Users\\Sarkhel\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\u001b[32m[I 2022-02-03 20:53:11,744]\u001b[0m Trial 49 finished with value: 0.7900020752628666 and parameters: {'learning_rate': 0.01284586251115451, 'lambda_l1': 0.4812791121338767, 'lambda_l2': 2.980355122258329e-08, 'num_leaves': 214, 'feature_fraction': 0.46059108085824096, 'bagging_fraction': 0.5229383076937753, 'bagging_freq': 2, 'min_child_samples': 95}. Best is trial 47 with value: 0.7924220047039292.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(run, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "16276589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01243326765467829,\n",
       " 'lambda_l1': 0.44583405781585317,\n",
       " 'lambda_l2': 1.945205216342612e-07,\n",
       " 'num_leaves': 135,\n",
       " 'feature_fraction': 0.45977662840830263,\n",
       " 'bagging_fraction': 0.5398639147101038,\n",
       " 'bagging_freq': 4,\n",
       " 'min_child_samples': 95}"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "059c7141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7924220047039292"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0fdb9f",
   "metadata": {},
   "source": [
    "## CatBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "d01af12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "final_test_predictions = []\n",
    "def run(trial):\n",
    "    \n",
    "    fold = 0\n",
    "    \n",
    "    \n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True)\n",
    "    iterations = trial.suggest_int(\"iterations\", 10, 2000)\n",
    "    l2_leaf_reg = trial.suggest_float(\"l2_leaf_reg\", 0.1, 15)\n",
    "    depth = trial.suggest_int(\"depth\", 1, 7)\n",
    "    \n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[features]\n",
    "    xvalid = xvalid[features]\n",
    "    xtest = xtest[features]\n",
    "    \n",
    "    model = CatBoostRegressor(\n",
    "        random_state=RANDOM_SEED,\n",
    "        learning_rate=learning_rate,\n",
    "        l2_leaf_reg=l2_leaf_reg,\n",
    "        depth=depth\n",
    "       \n",
    "    )\n",
    "    \n",
    "    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=False)\n",
    "    preds_valid = model.predict(xvalid)\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    print(\"ROC-AUC is: \", roc)\n",
    "    print(fold, roc)\n",
    "    \n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "b37262ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:19:31,336]\u001b[0m A new study created in memory with name: no-name-f2556b31-d52e-4b58-a1ab-d44799cb05f2\u001b[0m\n",
      "\u001b[32m[I 2022-02-03 21:19:55,586]\u001b[0m Trial 0 finished with value: 0.781883646928611 and parameters: {'learning_rate': 0.012067143008193212, 'iterations': 1666, 'l2_leaf_reg': 12.90198528594646, 'depth': 5}. Best is trial 0 with value: 0.781883646928611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.781883646928611\n",
      "0 0.781883646928611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:20:14,565]\u001b[0m Trial 1 finished with value: 0.7744203099059214 and parameters: {'learning_rate': 0.01179087299773442, 'iterations': 866, 'l2_leaf_reg': 5.490995311385601, 'depth': 3}. Best is trial 0 with value: 0.781883646928611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7744203099059214\n",
      "0 0.7744203099059214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:20:28,705]\u001b[0m Trial 2 finished with value: 0.7821726272827892 and parameters: {'learning_rate': 0.07571501580991345, 'iterations': 825, 'l2_leaf_reg': 3.8260945001605444, 'depth': 7}. Best is trial 2 with value: 0.7821726272827892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7821726272827892\n",
      "0 0.7821726272827892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:20:54,834]\u001b[0m Trial 3 finished with value: 0.7712766325401217 and parameters: {'learning_rate': 0.12563154939136703, 'iterations': 1946, 'l2_leaf_reg': 7.707981549054373, 'depth': 6}. Best is trial 2 with value: 0.7821726272827892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7712766325401217\n",
      "0 0.7712766325401217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:21:10,649]\u001b[0m Trial 4 finished with value: 0.7583785279468732 and parameters: {'learning_rate': 0.07806409962839889, 'iterations': 1968, 'l2_leaf_reg': 13.49406337879155, 'depth': 1}. Best is trial 2 with value: 0.7821726272827892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7583785279468732\n",
      "0 0.7583785279468732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:21:24,630]\u001b[0m Trial 5 finished with value: 0.7742425290536802 and parameters: {'learning_rate': 0.23996759835017045, 'iterations': 1569, 'l2_leaf_reg': 6.409613402190051, 'depth': 5}. Best is trial 2 with value: 0.7821726272827892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7742425290536802\n",
      "0 0.7742425290536802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:21:49,713]\u001b[0m Trial 6 finished with value: 0.7872530437188711 and parameters: {'learning_rate': 0.023897097025582358, 'iterations': 27, 'l2_leaf_reg': 2.328838945916324, 'depth': 6}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7872530437188711\n",
      "0 0.7872530437188711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:22:09,272]\u001b[0m Trial 7 finished with value: 0.7727754911455451 and parameters: {'learning_rate': 0.1787044877179105, 'iterations': 1878, 'l2_leaf_reg': 4.282859184380127, 'depth': 5}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7727754911455451\n",
      "0 0.7727754911455451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:22:32,938]\u001b[0m Trial 8 finished with value: 0.7750280160486994 and parameters: {'learning_rate': 0.06062736977028487, 'iterations': 403, 'l2_leaf_reg': 0.8215150713042703, 'depth': 6}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7750280160486994\n",
      "0 0.7750280160486994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:22:53,467]\u001b[0m Trial 9 finished with value: 0.7789213821250691 and parameters: {'learning_rate': 0.01054112836736516, 'iterations': 272, 'l2_leaf_reg': 2.5462976513782096, 'depth': 4}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7789213821250691\n",
      "0 0.7789213821250691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:23:10,712]\u001b[0m Trial 10 finished with value: 0.7751876383508578 and parameters: {'learning_rate': 0.026716700614470353, 'iterations': 41, 'l2_leaf_reg': 10.167976650780545, 'depth': 2}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7751876383508578\n",
      "0 0.7751876383508578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:23:39,122]\u001b[0m Trial 11 finished with value: 0.7811012728278915 and parameters: {'learning_rate': 0.027040550098290456, 'iterations': 877, 'l2_leaf_reg': 0.5641586372888359, 'depth': 7}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7811012728278915\n",
      "0 0.7811012728278915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:24:06,046]\u001b[0m Trial 12 finished with value: 0.7849316892639734 and parameters: {'learning_rate': 0.026277890795183077, 'iterations': 1234, 'l2_leaf_reg': 3.3877784271441884, 'depth': 7}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7849316892639734\n",
      "0 0.7849316892639734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:24:33,846]\u001b[0m Trial 13 finished with value: 0.783039741283896 and parameters: {'learning_rate': 0.029420406303387877, 'iterations': 1264, 'l2_leaf_reg': 8.873794521119414, 'depth': 7}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.783039741283896\n",
      "0 0.783039741283896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:24:58,976]\u001b[0m Trial 14 finished with value: 0.7866301189817378 and parameters: {'learning_rate': 0.018801126659355225, 'iterations': 1245, 'l2_leaf_reg': 2.3977751298736276, 'depth': 6}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7866301189817378\n",
      "0 0.7866301189817378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:25:19,603]\u001b[0m Trial 15 finished with value: 0.7846115799667958 and parameters: {'learning_rate': 0.017145424724211513, 'iterations': 563, 'l2_leaf_reg': 1.8532179213159967, 'depth': 4}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7846115799667958\n",
      "0 0.7846115799667958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:25:44,729]\u001b[0m Trial 16 finished with value: 0.7800501521859436 and parameters: {'learning_rate': 0.04228022892955629, 'iterations': 1315, 'l2_leaf_reg': 5.241139600023707, 'depth': 6}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7800501521859436\n",
      "0 0.7800501521859436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:26:10,015]\u001b[0m Trial 17 finished with value: 0.7841359988931931 and parameters: {'learning_rate': 0.018031738760679195, 'iterations': 623, 'l2_leaf_reg': 0.19041645513116556, 'depth': 6}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7841359988931931\n",
      "0 0.7841359988931931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:26:28,859]\u001b[0m Trial 18 finished with value: 0.7789184421693416 and parameters: {'learning_rate': 0.018005431810837098, 'iterations': 32, 'l2_leaf_reg': 11.004491961077175, 'depth': 3}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7789184421693416\n",
      "0 0.7789184421693416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:26:51,741]\u001b[0m Trial 19 finished with value: 0.7845048768677366 and parameters: {'learning_rate': 0.045634973069866504, 'iterations': 1082, 'l2_leaf_reg': 2.1609143968649263, 'depth': 5}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7845048768677366\n",
      "0 0.7845048768677366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:27:17,159]\u001b[0m Trial 20 finished with value: 0.7810791366906473 and parameters: {'learning_rate': 0.03894234776322832, 'iterations': 1502, 'l2_leaf_reg': 7.455199555300881, 'depth': 6}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7810791366906473\n",
      "0 0.7810791366906473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:27:45,118]\u001b[0m Trial 21 finished with value: 0.7816939333148866 and parameters: {'learning_rate': 0.022391183076922182, 'iterations': 1161, 'l2_leaf_reg': 3.4176102723089774, 'depth': 7}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7816939333148866\n",
      "0 0.7816939333148866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:28:12,084]\u001b[0m Trial 22 finished with value: 0.7832666366906477 and parameters: {'learning_rate': 0.03371528750820529, 'iterations': 1374, 'l2_leaf_reg': 2.6863681682676317, 'depth': 7}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7832666366906477\n",
      "0 0.7832666366906477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:28:36,995]\u001b[0m Trial 23 finished with value: 0.7848938157166574 and parameters: {'learning_rate': 0.015284791718373892, 'iterations': 1028, 'l2_leaf_reg': 4.894811345467009, 'depth': 6}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7848938157166574\n",
      "0 0.7848938157166574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:28:59,689]\u001b[0m Trial 24 finished with value: 0.7847705105146652 and parameters: {'learning_rate': 0.022204491039319756, 'iterations': 1726, 'l2_leaf_reg': 1.4703844866265432, 'depth': 5}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7847705105146652\n",
      "0 0.7847705105146652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:29:27,601]\u001b[0m Trial 25 finished with value: 0.7831473090758162 and parameters: {'learning_rate': 0.02236815717403105, 'iterations': 1444, 'l2_leaf_reg': 3.2854625876496377, 'depth': 7}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7831473090758162\n",
      "0 0.7831473090758162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:29:52,861]\u001b[0m Trial 26 finished with value: 0.7857702684006641 and parameters: {'learning_rate': 0.013595941717252725, 'iterations': 1184, 'l2_leaf_reg': 6.626357765072934, 'depth': 6}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7857702684006641\n",
      "0 0.7857702684006641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:30:13,612]\u001b[0m Trial 27 finished with value: 0.7818170655783067 and parameters: {'learning_rate': 0.013828811099805811, 'iterations': 698, 'l2_leaf_reg': 6.660335617354934, 'depth': 4}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7818170655783067\n",
      "0 0.7818170655783067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:30:36,363]\u001b[0m Trial 28 finished with value: 0.7831898519645821 and parameters: {'learning_rate': 0.014687579494733524, 'iterations': 250, 'l2_leaf_reg': 9.246751276636404, 'depth': 5}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7831898519645821\n",
      "0 0.7831898519645821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:30:54,942]\u001b[0m Trial 29 finished with value: 0.7723917404537907 and parameters: {'learning_rate': 0.010365312139763525, 'iterations': 1605, 'l2_leaf_reg': 11.87780355133798, 'depth': 3}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7723917404537907\n",
      "0 0.7723917404537907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:31:17,621]\u001b[0m Trial 30 finished with value: 0.7844305132816823 and parameters: {'learning_rate': 0.013203134860657119, 'iterations': 966, 'l2_leaf_reg': 6.1753690020740315, 'depth': 5}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7844305132816823\n",
      "0 0.7844305132816823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:31:42,537]\u001b[0m Trial 31 finished with value: 0.7854164360819037 and parameters: {'learning_rate': 0.020563086236760442, 'iterations': 1222, 'l2_leaf_reg': 4.210621549382703, 'depth': 6}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7854164360819037\n",
      "0 0.7854164360819037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:32:07,409]\u001b[0m Trial 32 finished with value: 0.7855400871610404 and parameters: {'learning_rate': 0.020915310183165767, 'iterations': 1156, 'l2_leaf_reg': 4.438625973327031, 'depth': 6}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7855400871610404\n",
      "0 0.7855400871610404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:32:32,190]\u001b[0m Trial 33 finished with value: 0.7839767224681794 and parameters: {'learning_rate': 0.012123446556290635, 'iterations': 1127, 'l2_leaf_reg': 4.86173319875445, 'depth': 6}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7839767224681794\n",
      "0 0.7839767224681794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:32:57,084]\u001b[0m Trial 34 finished with value: 0.7826635998893194 and parameters: {'learning_rate': 0.03338073690284892, 'iterations': 797, 'l2_leaf_reg': 7.507191395795279, 'depth': 6}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7826635998893194\n",
      "0 0.7826635998893194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:33:19,594]\u001b[0m Trial 35 finished with value: 0.783926743220808 and parameters: {'learning_rate': 0.016531346560182073, 'iterations': 936, 'l2_leaf_reg': 14.504241820300207, 'depth': 5}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.783926743220808\n",
      "0 0.783926743220808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:33:44,426]\u001b[0m Trial 36 finished with value: 0.7839189609850582 and parameters: {'learning_rate': 0.060187191739879575, 'iterations': 1410, 'l2_leaf_reg': 5.771795984943184, 'depth': 6}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7839189609850582\n",
      "0 0.7839189609850582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:34:12,241]\u001b[0m Trial 37 finished with value: 0.7839808729939126 and parameters: {'learning_rate': 0.019834686434749598, 'iterations': 1773, 'l2_leaf_reg': 1.604723072557924, 'depth': 7}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7839808729939126\n",
      "0 0.7839808729939126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:34:35,226]\u001b[0m Trial 38 finished with value: 0.782484262589928 and parameters: {'learning_rate': 0.09277456345135168, 'iterations': 794, 'l2_leaf_reg': 4.097286338052111, 'depth': 5}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.782484262589928\n",
      "0 0.782484262589928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:34:50,494]\u001b[0m Trial 39 finished with value: 0.7540020579690094 and parameters: {'learning_rate': 0.011910628657827287, 'iterations': 440, 'l2_leaf_reg': 8.588313444823893, 'depth': 1}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7540020579690094\n",
      "0 0.7540020579690094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:35:11,397]\u001b[0m Trial 40 finished with value: 0.779296831765357 and parameters: {'learning_rate': 0.053554177807175356, 'iterations': 1515, 'l2_leaf_reg': 2.7924355079725864, 'depth': 4}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.779296831765357\n",
      "0 0.779296831765357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:35:36,339]\u001b[0m Trial 41 finished with value: 0.7846290467625898 and parameters: {'learning_rate': 0.02049676654150182, 'iterations': 1164, 'l2_leaf_reg': 4.401993687991977, 'depth': 6}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7846290467625898\n",
      "0 0.7846290467625898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:36:01,421]\u001b[0m Trial 42 finished with value: 0.7839239762036525 and parameters: {'learning_rate': 0.03260177679524737, 'iterations': 1250, 'l2_leaf_reg': 1.1456285435680404, 'depth': 6}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7839239762036525\n",
      "0 0.7839239762036525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:36:26,289]\u001b[0m Trial 43 finished with value: 0.7848336330935252 and parameters: {'learning_rate': 0.023645198421108304, 'iterations': 1043, 'l2_leaf_reg': 3.8964998370264574, 'depth': 6}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7848336330935252\n",
      "0 0.7848336330935252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:36:53,966]\u001b[0m Trial 44 finished with value: 0.7856575124515772 and parameters: {'learning_rate': 0.0184510966858175, 'iterations': 1351, 'l2_leaf_reg': 7.019896673449287, 'depth': 7}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7856575124515772\n",
      "0 0.7856575124515772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:37:21,633]\u001b[0m Trial 45 finished with value: 0.7817662216380741 and parameters: {'learning_rate': 0.013463197228028216, 'iterations': 1347, 'l2_leaf_reg': 6.821994129684659, 'depth': 7}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7817662216380741\n",
      "0 0.7817662216380741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:37:49,294]\u001b[0m Trial 46 finished with value: 0.7847859020475928 and parameters: {'learning_rate': 0.015672601106327854, 'iterations': 877, 'l2_leaf_reg': 5.7054959126215605, 'depth': 7}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7847859020475928\n",
      "0 0.7847859020475928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:38:16,973]\u001b[0m Trial 47 finished with value: 0.7856927919203098 and parameters: {'learning_rate': 0.026065246357802434, 'iterations': 1635, 'l2_leaf_reg': 7.779995450537538, 'depth': 7}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7856927919203098\n",
      "0 0.7856927919203098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:38:44,705]\u001b[0m Trial 48 finished with value: 0.7854408204205866 and parameters: {'learning_rate': 0.026868257467843448, 'iterations': 1648, 'l2_leaf_reg': 9.23860372371242, 'depth': 7}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7854408204205866\n",
      "0 0.7854408204205866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-03 21:39:01,957]\u001b[0m Trial 49 finished with value: 0.7725213579136689 and parameters: {'learning_rate': 0.01791714375677783, 'iterations': 1850, 'l2_leaf_reg': 8.205384919511634, 'depth': 2}. Best is trial 6 with value: 0.7872530437188711.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC is:  0.7725213579136689\n",
      "0 0.7725213579136689\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(run, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "b560a2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.023897097025582358,\n",
       " 'iterations': 27,\n",
       " 'l2_leaf_reg': 2.328838945916324,\n",
       " 'depth': 6}"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "3ef37221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7872530437188711"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce39fb0",
   "metadata": {},
   "source": [
    "# L1 MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "430d7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(trial):\n",
    "    fold = 0\n",
    "    fold = 0\n",
    "    \n",
    "    xtrain =  train[train.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = train[train.kfold == fold].reset_index(drop=True)\n",
    "    xtest = test.copy()\n",
    "\n",
    "    ytrain = xtrain.cancelled\n",
    "    yvalid = xvalid.cancelled\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    xtest = xtest[useful_features]\n",
    "    \n",
    "    param = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"learning_rate\" : trial.suggest_float(\"learning_rate\", 1e-2, 0.25, log=True),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**param, random_state=RANDOM_SEED, n_estimators=10000)\n",
    "    model.fit(xtrain, ytrain, early_stopping_rounds=300, eval_set=[(xvalid, yvalid)], verbose=False)\n",
    "    preds_valid = model.predict_proba(xvalid)[:, 1]\n",
    "    roc = roc_auc_score(yvalid, preds_valid)\n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7f21aaaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 11:44:46,686]\u001b[0m A new study created in memory with name: no-name-b8e63c12-6c24-4430-a9cb-4421c84945c2\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:44:50,842]\u001b[0m Trial 0 finished with value: 0.7957666366906475 and parameters: {'learning_rate': 0.053379430813035124, 'lambda_l1': 6.418897085204742e-07, 'lambda_l2': 0.4158071340628894, 'num_leaves': 163, 'feature_fraction': 0.6435372688805586, 'bagging_fraction': 0.6196357775911578, 'bagging_freq': 2, 'min_child_samples': 48}. Best is trial 0 with value: 0.7957666366906475.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:44:55,035]\u001b[0m Trial 1 finished with value: 0.7972501902324295 and parameters: {'learning_rate': 0.04290869272261494, 'lambda_l1': 0.16787489832904565, 'lambda_l2': 3.397134234296255e-05, 'num_leaves': 131, 'feature_fraction': 0.5797161431870829, 'bagging_fraction': 0.8973462657391674, 'bagging_freq': 6, 'min_child_samples': 62}. Best is trial 1 with value: 0.7972501902324295.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:45:01,227]\u001b[0m Trial 2 finished with value: 0.7971932934421693 and parameters: {'learning_rate': 0.014417264271951533, 'lambda_l1': 0.03181927542222446, 'lambda_l2': 0.45945967615734, 'num_leaves': 236, 'feature_fraction': 0.4354427987307731, 'bagging_fraction': 0.9055650337179224, 'bagging_freq': 1, 'min_child_samples': 72}. Best is trial 1 with value: 0.7972501902324295.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:45:06,326]\u001b[0m Trial 3 finished with value: 0.7844374308245712 and parameters: {'learning_rate': 0.04742794015027149, 'lambda_l1': 3.103029765371054e-08, 'lambda_l2': 0.019404084679460275, 'num_leaves': 204, 'feature_fraction': 0.7394295615444451, 'bagging_fraction': 0.4230841552042203, 'bagging_freq': 7, 'min_child_samples': 86}. Best is trial 1 with value: 0.7972501902324295.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:45:09,425]\u001b[0m Trial 4 finished with value: 0.7900065716657443 and parameters: {'learning_rate': 0.07223220096573718, 'lambda_l1': 0.0003006122509195708, 'lambda_l2': 0.0004860071966578405, 'num_leaves': 90, 'feature_fraction': 0.511965105417549, 'bagging_fraction': 0.5309763750516813, 'bagging_freq': 3, 'min_child_samples': 20}. Best is trial 1 with value: 0.7972501902324295.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:45:15,032]\u001b[0m Trial 5 finished with value: 0.7919171105423354 and parameters: {'learning_rate': 0.07714144660310879, 'lambda_l1': 0.009411279096797433, 'lambda_l2': 8.10915967632587, 'num_leaves': 140, 'feature_fraction': 0.9297135668537488, 'bagging_fraction': 0.8869871701105139, 'bagging_freq': 2, 'min_child_samples': 22}. Best is trial 1 with value: 0.7972501902324295.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:45:18,955]\u001b[0m Trial 6 finished with value: 0.7938632747648036 and parameters: {'learning_rate': 0.10934155958713013, 'lambda_l1': 6.189748980239559e-05, 'lambda_l2': 0.6316340614922864, 'num_leaves': 119, 'feature_fraction': 0.720281096916263, 'bagging_fraction': 0.6860149308982402, 'bagging_freq': 3, 'min_child_samples': 40}. Best is trial 1 with value: 0.7972501902324295.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:45:24,418]\u001b[0m Trial 7 finished with value: 0.7948590550636414 and parameters: {'learning_rate': 0.011454278375845606, 'lambda_l1': 0.9313547835513935, 'lambda_l2': 0.006802529597180618, 'num_leaves': 179, 'feature_fraction': 0.5953112871785866, 'bagging_fraction': 0.9942841520664256, 'bagging_freq': 2, 'min_child_samples': 94}. Best is trial 1 with value: 0.7972501902324295.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:45:28,528]\u001b[0m Trial 8 finished with value: 0.7960557035141118 and parameters: {'learning_rate': 0.054828963869200754, 'lambda_l1': 9.457727306150339, 'lambda_l2': 3.3317624376051724, 'num_leaves': 118, 'feature_fraction': 0.9985830160767225, 'bagging_fraction': 0.43489027425224014, 'bagging_freq': 6, 'min_child_samples': 63}. Best is trial 1 with value: 0.7972501902324295.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:45:33,257]\u001b[0m Trial 9 finished with value: 0.8032475269784172 and parameters: {'learning_rate': 0.01393661332341988, 'lambda_l1': 0.08659179008415999, 'lambda_l2': 0.0006382635608284498, 'num_leaves': 155, 'feature_fraction': 0.6848869087952731, 'bagging_fraction': 0.635236716686201, 'bagging_freq': 3, 'min_child_samples': 45}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:45:36,893]\u001b[0m Trial 10 finished with value: 0.7900408999723298 and parameters: {'learning_rate': 0.22476705444047074, 'lambda_l1': 0.004042225189149379, 'lambda_l2': 1.8285820601396858e-08, 'num_leaves': 20, 'feature_fraction': 0.8394703033756025, 'bagging_fraction': 0.7606800529578178, 'bagging_freq': 5, 'min_child_samples': 9}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:45:40,200]\u001b[0m Trial 11 finished with value: 0.7955744154676259 and parameters: {'learning_rate': 0.023416689855989336, 'lambda_l1': 0.3382810016662507, 'lambda_l2': 2.4980959308011353e-06, 'num_leaves': 62, 'feature_fraction': 0.5553777337783309, 'bagging_fraction': 0.7900168612659203, 'bagging_freq': 5, 'min_child_samples': 37}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:45:44,885]\u001b[0m Trial 12 finished with value: 0.7908792197011623 and parameters: {'learning_rate': 0.02302665655580889, 'lambda_l1': 0.15712148900250086, 'lambda_l2': 1.5769756947721592e-05, 'num_leaves': 206, 'feature_fraction': 0.7989807952962702, 'bagging_fraction': 0.6036205000454444, 'bagging_freq': 4, 'min_child_samples': 63}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:45:48,670]\u001b[0m Trial 13 finished with value: 0.794682744189264 and parameters: {'learning_rate': 0.02820269683288182, 'lambda_l1': 7.978963708497382, 'lambda_l2': 1.6983839834508794e-05, 'num_leaves': 57, 'feature_fraction': 0.6527938528101138, 'bagging_fraction': 0.8260624437397819, 'bagging_freq': 7, 'min_child_samples': 76}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:45:52,570]\u001b[0m Trial 14 finished with value: 0.793061185666851 and parameters: {'learning_rate': 0.03264011127259719, 'lambda_l1': 2.1027217310310094e-05, 'lambda_l2': 7.779989807686707e-07, 'num_leaves': 145, 'feature_fraction': 0.4564593944475023, 'bagging_fraction': 0.9999812230414953, 'bagging_freq': 5, 'min_child_samples': 54}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:45:56,233]\u001b[0m Trial 15 finished with value: 0.7986029157443275 and parameters: {'learning_rate': 0.016237103489550434, 'lambda_l1': 0.0023294500727555115, 'lambda_l2': 0.000588322064555777, 'num_leaves': 94, 'feature_fraction': 0.6144354332079456, 'bagging_fraction': 0.6948790131356911, 'bagging_freq': 4, 'min_child_samples': 31}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:46:00,164]\u001b[0m Trial 16 finished with value: 0.7970718905644716 and parameters: {'learning_rate': 0.01645836678783116, 'lambda_l1': 0.0016550718343100114, 'lambda_l2': 0.0017336555637426038, 'num_leaves': 84, 'feature_fraction': 0.7969637021558196, 'bagging_fraction': 0.6927276661317989, 'bagging_freq': 4, 'min_child_samples': 32}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:46:03,556]\u001b[0m Trial 17 finished with value: 0.7960467107083564 and parameters: {'learning_rate': 0.011677405543979067, 'lambda_l1': 1.27918822007693e-05, 'lambda_l2': 0.03157230356748213, 'num_leaves': 11, 'feature_fraction': 0.6684344799954446, 'bagging_fraction': 0.5324588190949641, 'bagging_freq': 3, 'min_child_samples': 27}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:46:09,658]\u001b[0m Trial 18 finished with value: 0.7975210120365246 and parameters: {'learning_rate': 0.018046380195014783, 'lambda_l1': 0.0004871106837752471, 'lambda_l2': 0.00019532160279560354, 'num_leaves': 102, 'feature_fraction': 0.5086872047493817, 'bagging_fraction': 0.6210019608088846, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:46:13,728]\u001b[0m Trial 19 finished with value: 0.801538029192031 and parameters: {'learning_rate': 0.011025446684759799, 'lambda_l1': 0.03348232751528051, 'lambda_l2': 3.235252683698039e-07, 'num_leaves': 43, 'feature_fraction': 0.7428302097169585, 'bagging_fraction': 0.5466684490072304, 'bagging_freq': 1, 'min_child_samples': 47}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 11:46:17,361]\u001b[0m Trial 20 finished with value: 0.7958819002490315 and parameters: {'learning_rate': 0.010402502811160178, 'lambda_l1': 0.04641368632561649, 'lambda_l2': 1.4510105892423081e-08, 'num_leaves': 38, 'feature_fraction': 0.8792351772248292, 'bagging_fraction': 0.5020553286973695, 'bagging_freq': 1, 'min_child_samples': 47}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:46:20,716]\u001b[0m Trial 21 finished with value: 0.7977500691754289 and parameters: {'learning_rate': 0.016697199986168147, 'lambda_l1': 0.01606211446700274, 'lambda_l2': 5.148018700413077e-07, 'num_leaves': 65, 'feature_fraction': 0.7283919574265415, 'bagging_fraction': 0.587723200695882, 'bagging_freq': 1, 'min_child_samples': 41}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:46:23,730]\u001b[0m Trial 22 finished with value: 0.7943844251521859 and parameters: {'learning_rate': 0.021335525089433215, 'lambda_l1': 1.2801728580311573, 'lambda_l2': 0.00011488441541639743, 'num_leaves': 39, 'feature_fraction': 0.7784315259072956, 'bagging_fraction': 0.7227403239067235, 'bagging_freq': 3, 'min_child_samples': 53}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:46:28,092]\u001b[0m Trial 23 finished with value: 0.7979882055893747 and parameters: {'learning_rate': 0.013878459547926077, 'lambda_l1': 0.0018342651395991567, 'lambda_l2': 0.0015566649454541199, 'num_leaves': 167, 'feature_fraction': 0.6399622799893604, 'bagging_fraction': 0.6764257411502561, 'bagging_freq': 2, 'min_child_samples': 34}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:46:31,145]\u001b[0m Trial 24 finished with value: 0.7938054268123963 and parameters: {'learning_rate': 0.033061587216518355, 'lambda_l1': 0.04648020282670199, 'lambda_l2': 7.85337383406966e-08, 'num_leaves': 100, 'feature_fraction': 0.676462526059405, 'bagging_fraction': 0.5542101527912136, 'bagging_freq': 4, 'min_child_samples': 18}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:46:34,774]\u001b[0m Trial 25 finished with value: 0.7957376694798006 and parameters: {'learning_rate': 0.010166826997908749, 'lambda_l1': 0.00035256426591942454, 'lambda_l2': 4.386947635443825e-06, 'num_leaves': 78, 'feature_fraction': 0.6081811527229108, 'bagging_fraction': 0.4920009421718705, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:46:37,998]\u001b[0m Trial 26 finished with value: 0.7955642120918649 and parameters: {'learning_rate': 0.0132851171445708, 'lambda_l1': 1.1828124820290304, 'lambda_l2': 0.0009329971152654933, 'num_leaves': 40, 'feature_fraction': 0.7671662058889331, 'bagging_fraction': 0.6430190242875428, 'bagging_freq': 1, 'min_child_samples': 48}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:46:43,471]\u001b[0m Trial 27 finished with value: 0.7956853555617045 and parameters: {'learning_rate': 0.018124063189443616, 'lambda_l1': 0.005746461558915112, 'lambda_l2': 6.390221804746096e-05, 'num_leaves': 256, 'feature_fraction': 0.6955259937068203, 'bagging_fraction': 0.7462896295982552, 'bagging_freq': 2, 'min_child_samples': 58}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:46:47,299]\u001b[0m Trial 28 finished with value: 0.7645552884615384 and parameters: {'learning_rate': 0.24540446277937591, 'lambda_l1': 7.535272926288742e-05, 'lambda_l2': 0.011945412815921446, 'num_leaves': 113, 'feature_fraction': 0.8537532953204046, 'bagging_fraction': 0.5731589908291591, 'bagging_freq': 4, 'min_child_samples': 44}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:46:51,353]\u001b[0m Trial 29 finished with value: 0.7934379323464307 and parameters: {'learning_rate': 0.027527018550034213, 'lambda_l1': 1.335745850508036e-06, 'lambda_l2': 0.004153104566772978, 'num_leaves': 162, 'feature_fraction': 0.5405433882894366, 'bagging_fraction': 0.6467909404334539, 'bagging_freq': 5, 'min_child_samples': 73}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:46:55,804]\u001b[0m Trial 30 finished with value: 0.7799556412562259 and parameters: {'learning_rate': 0.15709346680649214, 'lambda_l1': 2.8965885437618456e-06, 'lambda_l2': 0.13346506864653698, 'num_leaves': 190, 'feature_fraction': 0.6187009271142856, 'bagging_fraction': 0.6555026566125779, 'bagging_freq': 6, 'min_child_samples': 49}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:46:59,820]\u001b[0m Trial 31 finished with value: 0.7981787838959602 and parameters: {'learning_rate': 0.01361145325620365, 'lambda_l1': 0.001563082757295803, 'lambda_l2': 0.0017839254830855137, 'num_leaves': 160, 'feature_fraction': 0.6452238746434339, 'bagging_fraction': 0.67506361522484, 'bagging_freq': 2, 'min_child_samples': 32}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:47:03,778]\u001b[0m Trial 32 finished with value: 0.7970963613724407 and parameters: {'learning_rate': 0.013322123826494014, 'lambda_l1': 0.0011894609060615232, 'lambda_l2': 0.00028015846448842447, 'num_leaves': 155, 'feature_fraction': 0.6917315416598627, 'bagging_fraction': 0.47143416893941636, 'bagging_freq': 2, 'min_child_samples': 29}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:47:08,570]\u001b[0m Trial 33 finished with value: 0.7956831073602657 and parameters: {'learning_rate': 0.015938538271377464, 'lambda_l1': 0.12460138061857562, 'lambda_l2': 0.1355303695305546, 'num_leaves': 132, 'feature_fraction': 0.6354395591247417, 'bagging_fraction': 0.7322053840333922, 'bagging_freq': 1, 'min_child_samples': 38}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:47:12,773]\u001b[0m Trial 34 finished with value: 0.7951757920586607 and parameters: {'learning_rate': 0.01991742215674967, 'lambda_l1': 0.016005767381690395, 'lambda_l2': 2.9088724351715033e-05, 'num_leaves': 218, 'feature_fraction': 0.5701107244908018, 'bagging_fraction': 0.6277696820633403, 'bagging_freq': 3, 'min_child_samples': 23}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:47:18,034]\u001b[0m Trial 35 finished with value: 0.7996843871057 and parameters: {'learning_rate': 0.01289229170176305, 'lambda_l1': 3.462486915101343e-08, 'lambda_l2': 0.04621686423121456, 'num_leaves': 182, 'feature_fraction': 0.7398186685074875, 'bagging_fraction': 0.8441299352618731, 'bagging_freq': 1, 'min_child_samples': 16}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:47:24,154]\u001b[0m Trial 36 finished with value: 0.79831281128943 and parameters: {'learning_rate': 0.012058499502254048, 'lambda_l1': 3.1637982363449584e-07, 'lambda_l2': 0.03555870930288707, 'num_leaves': 184, 'feature_fraction': 0.7579775750191569, 'bagging_fraction': 0.8428300277407024, 'bagging_freq': 1, 'min_child_samples': 6}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:47:30,000]\u001b[0m Trial 37 finished with value: 0.7959601549529607 and parameters: {'learning_rate': 0.015504295156489172, 'lambda_l1': 4.6045904745188693e-08, 'lambda_l2': 1.5510768417201222, 'num_leaves': 230, 'feature_fraction': 0.7101292391413764, 'bagging_fraction': 0.9259469432093828, 'bagging_freq': 1, 'min_child_samples': 15}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:47:34,315]\u001b[0m Trial 38 finished with value: 0.7913434732982845 and parameters: {'learning_rate': 0.03671541256687483, 'lambda_l1': 1.2456623119040675e-08, 'lambda_l2': 0.0758216317718798, 'num_leaves': 147, 'feature_fraction': 0.8095506493065174, 'bagging_fraction': 0.7748494344424458, 'bagging_freq': 2, 'min_child_samples': 25}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:47:39,371]\u001b[0m Trial 39 finished with value: 0.7966606426397344 and parameters: {'learning_rate': 0.010059461556630369, 'lambda_l1': 1.358524927696858e-07, 'lambda_l2': 0.0044847294691693134, 'num_leaves': 200, 'feature_fraction': 0.7381781517037233, 'bagging_fraction': 0.8456216486527914, 'bagging_freq': 3, 'min_child_samples': 18}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:47:44,545]\u001b[0m Trial 40 finished with value: 0.7892625034587714 and parameters: {'learning_rate': 0.06870008482449456, 'lambda_l1': 0.0001354037291241199, 'lambda_l2': 1.5028382064746604e-07, 'num_leaves': 177, 'feature_fraction': 0.8908700709207042, 'bagging_fraction': 0.9496729444359053, 'bagging_freq': 1, 'min_child_samples': 42}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-04 11:47:51,172]\u001b[0m Trial 41 finished with value: 0.7970408480907581 and parameters: {'learning_rate': 0.01233371044336176, 'lambda_l1': 1.4134595949836013e-07, 'lambda_l2': 0.023387529062469634, 'num_leaves': 181, 'feature_fraction': 0.7467134949692495, 'bagging_fraction': 0.8677887601708701, 'bagging_freq': 1, 'min_child_samples': 12}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:47:56,821]\u001b[0m Trial 42 finished with value: 0.7966856322634199 and parameters: {'learning_rate': 0.011750187557065266, 'lambda_l1': 2.5573884120387534e-07, 'lambda_l2': 0.20214581353410108, 'num_leaves': 190, 'feature_fraction': 0.7612963988679631, 'bagging_fraction': 0.801380466956451, 'bagging_freq': 1, 'min_child_samples': 5}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:48:01,909]\u001b[0m Trial 43 finished with value: 0.7977515391532928 and parameters: {'learning_rate': 0.025508544318433815, 'lambda_l1': 1.4594193211360259e-08, 'lambda_l2': 0.0006707680751086381, 'num_leaves': 126, 'feature_fraction': 0.8377324679231071, 'bagging_fraction': 0.7140178650935198, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:48:07,508]\u001b[0m Trial 44 finished with value: 0.7952025110680686 and parameters: {'learning_rate': 0.019455251295524115, 'lambda_l1': 5.923922900330734e-07, 'lambda_l2': 1.0787298031368822, 'num_leaves': 217, 'feature_fraction': 0.7244931406323661, 'bagging_fraction': 0.8112748760736352, 'bagging_freq': 1, 'min_child_samples': 8}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:48:12,574]\u001b[0m Trial 45 finished with value: 0.7964319313779746 and parameters: {'learning_rate': 0.015334020362537911, 'lambda_l1': 3.69260089343565e-08, 'lambda_l2': 6.125077309928742e-06, 'num_leaves': 172, 'feature_fraction': 0.6791118989389874, 'bagging_fraction': 0.8746899946210513, 'bagging_freq': 1, 'min_child_samples': 68}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:48:17,708]\u001b[0m Trial 46 finished with value: 0.7947539948810183 and parameters: {'learning_rate': 0.011477098395186318, 'lambda_l1': 0.5046939009227508, 'lambda_l2': 0.04811783571884914, 'num_leaves': 191, 'feature_fraction': 0.5850403127498354, 'bagging_fraction': 0.8388630989465521, 'bagging_freq': 2, 'min_child_samples': 21}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:48:21,637]\u001b[0m Trial 47 finished with value: 0.7930770095462092 and parameters: {'learning_rate': 0.05057837304509244, 'lambda_l1': 0.09885117662796347, 'lambda_l2': 0.01230995636539127, 'num_leaves': 150, 'feature_fraction': 0.8148996783285507, 'bagging_fraction': 0.9115843001374921, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:48:24,187]\u001b[0m Trial 48 finished with value: 0.7955354178195904 and parameters: {'learning_rate': 0.021733549378867803, 'lambda_l1': 4.193645506755721e-06, 'lambda_l2': 8.501348325499924, 'num_leaves': 3, 'feature_fraction': 0.7818042774664907, 'bagging_fraction': 0.7621930290899438, 'bagging_freq': 3, 'min_child_samples': 36}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n",
      "\u001b[32m[I 2022-02-04 11:48:29,282]\u001b[0m Trial 49 finished with value: 0.7999757021306033 and parameters: {'learning_rate': 0.04256569515717023, 'lambda_l1': 0.005805393156703653, 'lambda_l2': 0.00012810466837324033, 'num_leaves': 132, 'feature_fraction': 0.7080411550697537, 'bagging_fraction': 0.9636317407956231, 'bagging_freq': 2, 'min_child_samples': 58}. Best is trial 9 with value: 0.8032475269784172.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(run, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ba51aefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01393661332341988,\n",
       " 'lambda_l1': 0.08659179008415999,\n",
       " 'lambda_l2': 0.0006382635608284498,\n",
       " 'num_leaves': 155,\n",
       " 'feature_fraction': 0.6848869087952731,\n",
       " 'bagging_fraction': 0.635236716686201,\n",
       " 'bagging_freq': 3,\n",
       " 'min_child_samples': 45}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4ef3b7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8032475269784172"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deba0d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1577e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd67455a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd6c276a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fandango', 'Beerfest', 'Land Ho!', 'The Sure Thing', 'Duets']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import pickle\n",
    "\n",
    "def recommend(movie, df):\n",
    "    movie_index = df[df['original_title'] == movie].index[0]\n",
    "    distances = similarity[movie_index]\n",
    "    # sorting array\n",
    "    movies_list = sorted(list(enumerate(distances)), reverse=True, key=lambda x: x[1])[1:6]\n",
    "\n",
    "    recommended_movies = []\n",
    "\n",
    "    for movies in movies_list:\n",
    "        recommended_movies.append(df.iloc[movies[0]].original_title)\n",
    "\n",
    "    return recommended_movies\n",
    "\n",
    "movie_dict = pickle.load(open('D:\\\\Project\\\\Movie Recommendation System\\\\movies.pkl', 'rb'))\n",
    "movies = pd.DataFrame(movie_dict)\n",
    "\n",
    "similarity = pickle.load(open('D:\\\\Project\\\\Movie Recommendation System\\\\similarity.pkl', 'rb'))\n",
    "\n",
    "\n",
    "selected_movie_name = 'Avatar'\n",
    "recommend(selected_movie_name, movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d72e109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
